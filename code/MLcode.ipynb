{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e51c2d6",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports-and-setup-functions\" data-toc-modified-id=\"Imports-and-setup-functions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports and setup functions</a></span></li><li><span><a href=\"#DataLoader-Module\" data-toc-modified-id=\"DataLoader-Module-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>DataLoader Module</a></span><ul class=\"toc-item\"><li><span><a href=\"#Image-regions\" data-toc-modified-id=\"Image-regions-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Image regions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Find-interesting-regions-to-test-on\" data-toc-modified-id=\"Find-interesting-regions-to-test-on-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Find interesting regions to test on</a></span></li><li><span><a href=\"#Cut-all-data-into-64x64-regions\" data-toc-modified-id=\"Cut-all-data-into-64x64-regions-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Cut all data into 64x64 regions</a></span></li><li><span><a href=\"#Save-to-.npy-files\" data-toc-modified-id=\"Save-to-.npy-files-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Save to .npy files</a></span></li></ul></li><li><span><a href=\"#Train-val-test-split\" data-toc-modified-id=\"Train-val-test-split-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Train-val-test split</a></span></li><li><span><a href=\"#Inputs-and-ends\" data-toc-modified-id=\"Inputs-and-ends-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Inputs and ends</a></span></li><li><span><a href=\"#Tensors,-DataLoader\" data-toc-modified-id=\"Tensors,-DataLoader-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Tensors, DataLoader</a></span></li><li><span><a href=\"#Create-DataLoader-for-training-data\" data-toc-modified-id=\"Create-DataLoader-for-training-data-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Create DataLoader for training data</a></span></li></ul></li><li><span><a href=\"#Model-Module\" data-toc-modified-id=\"Model-Module-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Model Module</a></span><ul class=\"toc-item\"><li><span><a href=\"#AR1:-linear-mapping\" data-toc-modified-id=\"AR1:-linear-mapping-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>AR1: linear mapping</a></span></li><li><span><a href=\"#de-Bézenac-et-al,-2019:-CNN-with-warp-mapping\" data-toc-modified-id=\"de-Bézenac-et-al,-2019:-CNN-with-warp-mapping-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>de Bézenac et al, 2019: CNN with warp mapping</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loss-Function\" data-toc-modified-id=\"Loss-Function-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Loss Function</a></span></li><li><span><a href=\"#Warp\" data-toc-modified-id=\"Warp-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Warp</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Model</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-3.2.4\"><span class=\"toc-item-num\">3.2.4&nbsp;&nbsp;</span>Training</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb70983",
   "metadata": {},
   "source": [
    "# Imports and setup functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6754139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Function, Variable\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2088495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datadir(x):\n",
    "    return \"/projectnb/labci/Lucia/data/\" + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "248f8717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename):\n",
    "    torch.save(state, filename)  \n",
    "    print(\"State saved: \" + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f15e4f",
   "metadata": {},
   "source": [
    "# DataLoader Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a8f21d",
   "metadata": {},
   "source": [
    "## Train-val-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715c5887",
   "metadata": {},
   "source": [
    "The authors trained on SST data from 2006-2015 and tested on data from 2016-2017. For the IBI reanalysis SST data, we only have from June 5, 2021 to June 23, 2023 (749 days). From these, we will use 80% for training, 10% for validation, and 10% for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7d16162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_days(files):\n",
    "    \"\"\"Helper method to take a list of filenames and return total the number \n",
    "    of days represented by the files in the list. \n",
    "    \n",
    "    This method assumes a particular file naming convention that has been used \n",
    "    for this project. \n",
    "    \n",
    "    File naming convention: sst_geo_yyyymmdd.nc_region_XX.npy\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    files : list : data file names\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    delta : int : the number of days represented by the inputted files\n",
    "    \"\"\"\n",
    "    \n",
    "    files.sort()\n",
    "    \n",
    "    first = datetime.datetime.strptime(files[0][8:16], \"%Y%m%d\").date()\n",
    "    last = datetime.datetime.strptime(files[len(files)-1][8:16], \"%Y%m%d\").date()\n",
    "    \n",
    "    delta = int((last - first) / datetime.timedelta(days=1))\n",
    "    \n",
    "    return delta\n",
    "\n",
    "def train_val_test_cutoffs(topdir, split):\n",
    "    \"\"\"Helper method to create lists of filenames for the train, val, and test\n",
    "    data splits. Uses the dates in the filenames to determine file order and \n",
    "    split cutoffs.\n",
    "    \n",
    "    This method assumes a particular file naming convention that has been used \n",
    "    for this project. \n",
    "    \n",
    "    File naming convention: sst_geo_yyyymmdd.nc_region_XX.npy\n",
    "       \n",
    "    Parameters\n",
    "    ----------\n",
    "    topdir : string : the path to the directory holding the data\n",
    "    split : list : the fractions for each split, eg. [0.8, 0.1, 0.1]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    cutoffs : list : date cutoffs for each split\n",
    "    \"\"\"\n",
    "    \n",
    "    all_files = os.listdir(topdir)\n",
    "    all_files.sort()\n",
    "    nfiles = len(all_files)\n",
    "    ndays = all_days(all_files)\n",
    "    \n",
    "    start_date = datetime.datetime.strptime(all_files[0][8:16], \"%Y%m%d\").date()\n",
    "    end_date = datetime.datetime.strptime(all_files[nfiles-1][8:16], \"%Y%m%d\").date()\n",
    "    \n",
    "    cutoffs = []\n",
    "    \n",
    "    for i in range(3):\n",
    "        delta = math.floor(ndays*split[i])\n",
    "        end = start_date + datetime.timedelta(days=delta)\n",
    "        cutoffs.append(end)\n",
    "        \n",
    "        start_date = end\n",
    "        \n",
    "    # Because of rounding, some files may have been missed\n",
    "    # Add these to the test split\n",
    "    if cutoffs[2] < end_date:\n",
    "        cutoffs[2] = end_date\n",
    "    \n",
    "    return cutoffs\n",
    "\n",
    "def train_val_test_split_files(topdir, split):\n",
    "    \"\"\"Method to split the data in a directory into training, validation, and\n",
    "    test sets. Uses the helper method train_val_test_cutoffs().\n",
    "    \n",
    "    This method assumes a particular file naming convention that has been used \n",
    "    for this project. \n",
    "    \n",
    "    File naming convention: sst_geo_yyyymmdd.nc_region_XX.npy\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    topdir : string : the path to the directory holding the data\n",
    "    split : list : the fractions for each split, eg. [0.8, 0.1, 0.1]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    train : list : list of filenames for the train set\n",
    "    val : list : list of filenames for the validation set\n",
    "    test : list : list of filenames for the test set\n",
    "    \"\"\"\n",
    "    \n",
    "    assert len(split) == 3, \"Please include a % split for train, validation, and test sets.\"\n",
    "    \n",
    "    cutoffs = train_val_test_cutoffs(topdir, split)\n",
    "    \n",
    "    all_files = os.listdir(topdir)\n",
    "    all_files.sort()\n",
    "    \n",
    "    train, val, test = [], [], []\n",
    "    \n",
    "    for f in all_files:\n",
    "        file_date = datetime.datetime.strptime(f[8:16], \"%Y%m%d\").date()\n",
    "        \n",
    "        if file_date <= cutoffs[0]:\n",
    "            train.append(f)\n",
    "        elif (file_date > cutoffs[0]) & (file_date <= cutoffs[1]):\n",
    "            val.append(f)\n",
    "        else:\n",
    "            test.append(f)\n",
    "            \n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38bda7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_file(filename):\n",
    "    \"\"\"Helper method to load a single .npy file.\"\"\"\n",
    "    return np.load(datadir(\"sst_npy/\" + filename))\n",
    "\n",
    "\n",
    "def load_data_from_files(files):\n",
    "    \"\"\"Method to load data from a list of .npy files.\"\"\"\n",
    "    data = []\n",
    "    for f in files:\n",
    "        data.append(load_data_from_file(f))\n",
    "        \n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2117c9",
   "metadata": {},
   "source": [
    "## Inputs and ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5a6a4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_by_region(files, region):\n",
    "    \"\"\"Helper method to search a list of files for only those corresponding to\n",
    "    a desired region. \n",
    "    \n",
    "    This method assumes a particular file naming convention that has been used \n",
    "    for this project. \n",
    "    \n",
    "    File naming convention: sst_geo_yyyymmdd.nc_region_XX.npy\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    files : list : list of filenames in which to search\n",
    "    region : int : desired region\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    region_files : list : sorted list of matching files\n",
    "    \"\"\"\n",
    "    \n",
    "    region_files = []\n",
    "    for fname in files:\n",
    "        if \"region_\" + str(region) + \".npy\" in fname:\n",
    "            region_files.append(fname)\n",
    "            \n",
    "    region_files.sort()\n",
    "    \n",
    "    return region_files\n",
    "\n",
    "def get_pairs_by_region(files, region, ndays=1):\n",
    "    \"\"\"Method to separate data into inputs (X) and ends (y), for example to\n",
    "    use 4 previous days (ndays=4) to predict the next day. The \"pairs\" are \n",
    "    pairs of (X,y) inputs and ends. This method works on one region at a time.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    files : list : list of files from which to get pairs\n",
    "    region : int : desired region\n",
    "    ndays : int : number of days to use as inputs\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    inps : np.ndarray : filenames for inputs\n",
    "    ends : list : filenames for ends\n",
    "    \"\"\"\n",
    "    \n",
    "    region_files = search_by_region(files, region)\n",
    "    \n",
    "    n = len(region_files)\n",
    "    \n",
    "    inps = []\n",
    "    ends = region_files[ndays:]\n",
    "    \n",
    "    for i in range(n - ndays):\n",
    "        inps.append(region_files[i:i+ndays])\n",
    "    \n",
    "    return np.array(inps), np.array(ends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43858887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_regions(files):\n",
    "    \"\"\"Helper method to take a list of filenames and return a list of the \n",
    "    unique region numbers. \n",
    "    \n",
    "    This method assumes a particular file naming convention that has been used \n",
    "    for this project. \n",
    "    \n",
    "    File naming convention: sst_geo_yyyymmdd.nc_region_XX.npy\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    files : list : data file names\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    regions : list : list of unique region numbers in the directory\n",
    "    \"\"\"\n",
    "    \n",
    "    files.sort()\n",
    "    regions = []\n",
    "    \n",
    "    for f in files:\n",
    "        if \"region_\" in f:\n",
    "            \n",
    "            start_ind = f.find(\"region_\") + len(\"region_\")\n",
    "            end_ind = f.find(\".npy\")\n",
    "            \n",
    "            reg = f[start_ind:end_ind]\n",
    "            \n",
    "            if int(reg) not in regions:\n",
    "                regions.append(int(reg))\n",
    "            \n",
    "        else:\n",
    "            print(\"Files in this directory do not match the naming convention.\")\n",
    "    \n",
    "    regions.sort()\n",
    "    \n",
    "    return regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8510e497",
   "metadata": {},
   "source": [
    "## Tensors, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa7d662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(batchsize, files, ndays, dtype=torch.FloatTensor):\n",
    "    \"\"\"Method to create a PyTorch DataLoader object from a list of files and\n",
    "    additional parameters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dtype : torch.dtype : the data type for the DataLoader\n",
    "    batchsize : int : the desired batchsize for loading data\n",
    "    files : str : a list of files holding data to put into the DataLoader\n",
    "    ndays : int : the number of days to use as inputs to predict the next day\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    training : torch.utils.data.DataLoader : the DataLoader object\n",
    "    \"\"\"\n",
    "    \n",
    "    regions = all_regions(files)\n",
    "\n",
    "    data = []\n",
    "    ends = []\n",
    "\n",
    "    for reg in regions:\n",
    "        reg_pairs = get_pairs_by_region(files, reg, ndays)\n",
    "        \n",
    "        for i in range(len(reg_pairs[0])):\n",
    "            dat = load_data_from_files(reg_pairs[0][i])\n",
    "            end = load_data_from_file(reg_pairs[1][i])\n",
    "        \n",
    "            data.append(dat)\n",
    "            ends.append(end)\n",
    "        \n",
    "    final_data = torch.from_numpy(np.array(data)).type(dtype)\n",
    "    final_ends = torch.from_numpy(np.array(ends)).type(dtype)\n",
    "    \n",
    "    training = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(final_data, final_ends),\n",
    "                                           batch_size=batchsize, shuffle=False)\n",
    "    \n",
    "    return training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727f10c7",
   "metadata": {},
   "source": [
    "## Create DataLoader for training, validation, and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d36e3b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28752\n",
      "3552\n",
      "3648\n"
     ]
    }
   ],
   "source": [
    "split = train_val_test_split_files(datadir(\"sst_npy/\"), [0.8, 0.1, 0.1]) \n",
    "\n",
    "train_split = split[0]\n",
    "val_split   = split[1]\n",
    "test_split  = split[2]\n",
    "\n",
    "print(len(train_split))\n",
    "print(len(val_split))\n",
    "print(len(test_split))\n",
    "\n",
    "\n",
    "# Testing plots with small dataset for now\n",
    "training_loader = create_dataloader(batchsize=12, files=train_split, ndays=4)\n",
    "\n",
    "val_loader = create_dataloader(batchsize=12, files=val_split, ndays=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d278c9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380\n",
      "280\n"
     ]
    }
   ],
   "source": [
    "print(len(training_loader))\n",
    "print(len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "251b1547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_first, train_next = next(iter(training_loader)) \n",
    "plt.imshow(train_first[0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8a9baa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_first, val_next = next(iter(val_loader))\n",
    "plt.imshow(val_first[0][0])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06015e1",
   "metadata": {},
   "source": [
    "# Model Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ade1fba",
   "metadata": {},
   "source": [
    "## de Bézenac et al, 2019: CNN with warp mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e569ea",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2632738",
   "metadata": {},
   "source": [
    "The authors used a Charbonnier penality to measure the discrepancy between the predicted next image and the target: \n",
    "\n",
    "$\\rho(x) = (x + \\epsilon)^\\frac{1}{\\alpha}$\n",
    "\n",
    "Note that with $\\epsilon=0$ and $\\alpha=\\frac{1}{2}$, we recover the $\\textit{l}_2$ norm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a26ac1",
   "metadata": {},
   "source": [
    "The gradient wrt $x$:\n",
    "\n",
    "$\\frac{d \\rho(x)}{dx} = \\frac{1}{\\alpha}(x+\\epsilon)^{\\frac{1}{\\alpha}-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc041ab",
   "metadata": {},
   "source": [
    "Additional penalty terms were added to the loss function, specifically to regulate the divergence of the displacement $\\omega$ between the prediction and the target, its magnitude, and its smoothness:\n",
    "\n",
    "$L_t = \\underset{x \\in \\Omega}\\Sigma \\rho(\\hat{I}_{t+1}(x) - I_{t+1}(x)) + \\lambda_{div}(\\nabla.\\omega_t(x))^2 + \\lambda_{magn}||\\omega_t(x)||^2 + \\lambda_{grad}||\\nabla \\omega_t(x)||^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29f28761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_regloss(F):\n",
    "    gradient = reduce(np.add, np.gradient(F))\n",
    "    \n",
    "    divergence = np.array([np.mean(gradient.sum(0)**2)])                         # 1st reg term above\n",
    "    magnitude  = np.array([np.mean(np.linalg.norm(F, axis=0, ord=2)**2)])        # 2nd reg term above\n",
    "    smoothness = np.array([np.mean(np.linalg.norm(gradient, axis=0, ord=2)**2)]) # 3rd reg term above\n",
    "    \n",
    "    return torch.from_numpy(divergence).type(torch.FloatTensor), torch.from_numpy(magnitude).type(torch.FloatTensor), torch.from_numpy(smoothness).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "741a61d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def charbonnier(x, alpha, eps):\n",
    "    \n",
    "    res = torch.mean(torch.pow(torch.pow(x, 2) + eps, (1. / alpha)))\n",
    "\n",
    "    return res\n",
    "\n",
    "def grad_charbonnier(x, alpha, eps):\n",
    "    \n",
    "    res = (1. / alpha)*torch.pow(x + eps, (1. / alpha) - 1)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "108d33db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctl, y_pred, y, w, alpha=0.5, eps=0):\n",
    "        lambda_div, lambda_magn, lambda_grad = 1, -0.1, 0.4\n",
    "        ctl.save_for_backward(y_pred, y) # saves Tensor ctl for future call to backward()\n",
    "        \n",
    "        divergence, magnitude, smoothness = compute_regloss(w[0,:,:,:].numpy())\n",
    "        \n",
    "        distsq = torch.pow(y_pred - y, 2)\n",
    "        loss = charbonnier(distsq) + lambda_div*divergence + lambda_magn*magnitude + lambda_grad*smoothness\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctl, alpha=0.5, eps=0):\n",
    "        y_pred, y = ctl.saved_tensors\n",
    "        distsq = torch.pow(y_pred - y, 2)\n",
    "\n",
    "        grad = grad_charbonnier(distsq, alpha, eps)\n",
    "        \n",
    "        return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b406bf74",
   "metadata": {},
   "source": [
    "### Warp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e686d5",
   "metadata": {},
   "source": [
    "The future image is calculated based on a \"warp\" of the motion field estimate, $\\hat{\\omega}$, which can be thought of in this application as the wind vector field:\n",
    "\n",
    "$\\hat{I}_{t+1}(x) = \\underset{y \\in \\Omega} \\Sigma k(x - \\hat{\\omega}(x), y) I_t (y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5484aec7",
   "metadata": {},
   "source": [
    "where $k(u, v)$ is a radial basis function kernel, or equivalent a 2D Gaussian probability distribution:\n",
    "\n",
    "$k(x - \\hat{\\omega}(x), y) = \\frac{1}{4 \\pi D\\Delta t}e^{\\frac{-1}{4D \\Delta t} ||x - \\hat{\\omega}(x) - y||^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad59f08",
   "metadata": {},
   "source": [
    "for diffusion coefficient D and time step value $\\Delta t$ between $t$ and $t+1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "917ddf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel(distsq, D, dt):\n",
    "    \"\"\"Method to implement the k() function or radial basis function kernel \n",
    "    described above.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    distsq : float or torch.FloatTensor : the value of the squared norm of \n",
    "                 the distance\n",
    "    D : float : the diffusion coefficient\n",
    "    dt : float : the timestep\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    res : float or torch.FloatTensor: the result of the function\n",
    "    \"\"\"\n",
    "    \n",
    "    res = torch.exp(-distsq/(4*D*dt))/(4*np.pi*D*dt)\n",
    "    return res\n",
    "\n",
    "def kernel_gradient(self, dist, D, dt):\n",
    "    \"\"\"Method to implement the gradient of the k() function with respect to \n",
    "    the distance.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dist : float : the distance\n",
    "    D : float : the diffusion coefficient\n",
    "    dt : float : the timestep\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    res : float : the gradient of the function with respect to the distance\n",
    "    \"\"\"\n",
    "    \n",
    "    res = dist*torch.exp(-(dist**2).sum(1)/(4*D*dt))/(8*np.pi*D**2*dt**2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56d65cd",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b915e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(*models):\n",
    "    for model in models:\n",
    "        for module in model.modules():\n",
    "            \n",
    "            if isinstance(module, nn.Conv2d) or isinstance(module, nn.ConvTranspose2d) or isinstance(module, nn.Linear):\n",
    "                \n",
    "                # He initialization, from He, K. et al, 2015\n",
    "                nn.init.kaiming_normal_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    module.bias.data.zero_()\n",
    "                    \n",
    "            elif isinstance(module, nn.BatchNorm2d):\n",
    "                module.weight.data.fill_(1)\n",
    "                module.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71dfa15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(_EncoderBlock, self).__init__()\n",
    "        self.cv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.lr1 = nn.LeakyReLU(0.1)\n",
    "        self.cv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.lr2 = nn.LeakyReLU(0.1)\n",
    "        self.maxp = nn.MaxPool2d(kernel_size=3, stride=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual=x\n",
    "        #print(\"residual\",residual.shape)\n",
    "        out=self.cv1(x)\n",
    "        #print(\"cv1\",out.shape)\n",
    "        out=self.bn1(out)\n",
    "        #print(\"bn1\",out.shape)\n",
    "        out=self.lr1(out)\n",
    "        #print(\"lr1\",out.shape)\n",
    "        out+=residual\n",
    "        out=self.cv2(out)\n",
    "        out=self.bn2(out)\n",
    "        out=self.lr2(out)\n",
    "        out=self.maxp(out)\n",
    "        return out\n",
    "\n",
    "class _DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels):\n",
    "        super(_DecoderBlock, self).__init__()\n",
    "        self.cv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.lr1 = nn.LeakyReLU(0.1)\n",
    "        self.cv2 = nn.Conv2d(in_channels, middle_channels, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(middle_channels) \n",
    "        self.lr2 = nn.LeakyReLU(0.1)\n",
    "        self.tcv = nn.ConvTranspose2d(middle_channels, out_channels, kernel_size=3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual=x\n",
    "        #print(\"residual\",residual.shape)\n",
    "        out=self.cv1(x)\n",
    "        #print(\"cv1\",out.shape)\n",
    "        out=self.bn1(out)\n",
    "        #print(\"bn1\",out.shape)\n",
    "        out=self.lr1(out)\n",
    "        #print(\"lr1\",out.shape)\n",
    "        out+=residual\n",
    "        out=self.cv2(out)\n",
    "        out=self.bn2(out)\n",
    "        out=self.lr2(out)\n",
    "        out=self.tcv(out)\n",
    "        return out\n",
    "\n",
    "class _CenterBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(_CenterBlock, self).__init__()\n",
    "        self.cv1 = nn.Conv2d(in_channels,in_channels , kernel_size=3,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)  \n",
    "        self.lr1 = nn.LeakyReLU(0.1)\n",
    "        self.cv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels) \n",
    "        self.lr2 = nn.LeakyReLU(0.1)\n",
    "        self.tcv = nn.ConvTranspose2d(out_channels, out_channels, kernel_size=3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual=x\n",
    "        out=self.cv1(x)\n",
    "        out=self.bn1(out)\n",
    "        out=self.lr1(out)\n",
    "        out+=residual\n",
    "        out=self.cv2(out)\n",
    "        out=self.bn2(out)\n",
    "        out=self.lr2(out)\n",
    "        out=self.tcv(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dc45117",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDNN(nn.Module):\n",
    "    \"\"\"Class to implement a physics-driven Convolution-Deconvolution Neural \n",
    "    Network (CDNN) as described in (de Bezenac et al, 2019). This model \n",
    "    takes as input historical image(s) of Sea Surface Temperature (SST)\n",
    "    data, X, and uses a convolutional neural network (CNN) to estimate the \n",
    "    wind vector field W that drives the motion of X. From there, the next \n",
    "    image is predicted using a \"warping\" of the most recent input image and W,\n",
    "    as if to see how the SST variable evolves with the wind. \n",
    "    \n",
    "    The \"warping\" in this paper is a radial basis function kernel, or a \n",
    "    Gaussian centered in X-W. Other models we will implement later may use a\n",
    "    different warping scheme. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name, hist=1):\n",
    "        \"\"\"Function to construct the model. \n",
    "           \n",
    "           Parameters\n",
    "           ----------\n",
    "           hist : int : the number of days of \"history\" to use for prediction, \n",
    "                        default = 1.\n",
    "        \"\"\"\n",
    "        \n",
    "        super(CDNN, self).__init__()\n",
    "        \n",
    "        self.enc1 = _EncoderBlock(hist, 64)  \n",
    "        self.enc2 = _EncoderBlock(64, 128)\n",
    "        self.enc3 = _EncoderBlock(128, 256)\n",
    "        self.enc4 = _EncoderBlock(256, 512)\n",
    "        self.dec4 = _CenterBlock(512, 386)\n",
    "        self.dec3 = _DecoderBlock(386+256, 256, 194)\n",
    "        self.dec2 = _DecoderBlock(194+128, 128, 98)\n",
    "        self.dec1 = _DecoderBlock(98+64, 64, 2)\n",
    "        \n",
    "        self.final = nn.Sequential(nn.Conv2d(2, 2, kernel_size=3),) \n",
    "        initialize_weights(self)\n",
    "\n",
    "        self.hist = hist\n",
    "        self.name = name\n",
    "\n",
    "    def wind(self, x):\n",
    "        \"\"\"Function to estimate the wind vector field from historical input images.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.FloatTensor : the historical input images\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        wind : torch.FloatTensor : the estimated wind vector field\n",
    "        \"\"\"\n",
    "        \n",
    "        enc1 = self.enc1(x)\n",
    "        #print(\"x\",x.shape)\n",
    "        #print(\"enc1\",enc1.shape)\n",
    "        enc2 = self.enc2(enc1)\n",
    "        #print(\"enc2\",enc2.shape)\n",
    "        enc3 = self.enc3(enc2)\n",
    "        #print(\"enc3\",enc3.shape)\n",
    "        enc4 = self.enc4(enc3)\n",
    "        #print(\"enc4\",enc4.shape)\n",
    "        dec4 = self.dec4(enc4)\n",
    "        #print(\"dec4\",dec4.shape)\n",
    "        \n",
    "        dec3 = self.dec3(torch.cat([dec4, F.interpolate(enc3, dec4.size()[2:], mode='bilinear')], 1))\n",
    "        dec2 = self.dec2(torch.cat([dec3, F.interpolate(enc2, dec3.size()[2:], mode='bilinear')], 1))\n",
    "        dec1 = self.dec1(torch.cat([dec2, F.interpolate(enc1, dec2.size()[2:], mode='bilinear')], 1))\n",
    "        final = self.final(dec1)\n",
    "        \n",
    "        wind = F.interpolate(final, x.size()[2:], mode='bilinear')\n",
    "\n",
    "        return wind\n",
    "    \n",
    "    @staticmethod\n",
    "    def warp(I, W, hist):\n",
    "        \"\"\"Function to compute the warping of the input data and an estimated \n",
    "        wind vector field, in order to produce an output predicted image. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        I : torch.FloatTensor : the most recent input image to warp\n",
    "        W : torch.FloatTensor : the estimated wind vector field\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        warped : torch.FloatTensor : the warped prediction image\n",
    "        \"\"\"\n",
    "        \n",
    "        D = 0.45\n",
    "        dt = 1\n",
    "        \n",
    "        interval=torch.arange(I.size()[-1]).type(torch.FloatTensor)\n",
    "        \n",
    "        x1 = interval[None,:,None,None,None]\n",
    "        x2 = interval[None,None,:,None,None]\n",
    "        y1 = interval[None,None,None,:,None]\n",
    "        y2 = interval[None,None,None,None,:]\n",
    "        \n",
    "        # x - wind - y\n",
    "        distsq = (x1-y1-W[:,0,:,:,None,None])**2+(x2-y2-W[:,1,:,:,None,None])**2         \n",
    "        mult = I[:, hist-1, None,None,:,:] * kernel(distsq, D, dt)\n",
    "        warped = mult.sum(4).sum(3)\n",
    "        \n",
    "        return warped\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Function to execute the forward pass of the model. All of the \n",
    "        computations are done in the methods above, so this function \n",
    "        simply returns their outputs.\n",
    "        \n",
    "        Note: the wind vector field W is returned for use in the \n",
    "        regularized loss function later. For simple difference loss \n",
    "        functions, returning y_pred is sufficient. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.FloatTensor : the historical input images\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        W : torch.FloatTensor : the estimated wind vector field\n",
    "        y_pred : torch.FloatTensor : the predicted next image\n",
    "        \"\"\"\n",
    "        \n",
    "        W = self.wind(x)\n",
    "        y_pred = self.warp(x, W, self.hist) \n",
    "        \n",
    "        return W, y_pred "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd072838",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6550149",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62d8b2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    learning_rate = 1e-3\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        #X = X.to(device) \n",
    "        #y = y.to(device)\n",
    "        outputs = model(X)\n",
    "        wind = outputs[0]\n",
    "        y_pred = outputs[1]\n",
    "            \n",
    "        #loss = loss_fn(y_pred, y, wind)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        print(\"Step:\", batch, \"Loss:\", loss)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    return losses\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    test_losses = []\n",
    "    num_loops = 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            #X = X.to(device) \n",
    "            #y = y.to(device)\n",
    "            outputs = model(X)\n",
    "            y_pred = outputs[1]\n",
    "            \n",
    "            step_loss = loss_fn(y_pred, y).item()\n",
    "            print(\"Item:\", num_loops, \"Loss:\", step_loss)\n",
    "            test_losses.append(step_loss)\n",
    "            num_loops += 1\n",
    "\n",
    "    avg = test_losses.mean()\n",
    "    #print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {avg:>8f} \\n\")\n",
    "    print(f\"Test Error: \\n Avg loss: {avg:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e9ca70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(loss, model_name, loss_name):\n",
    "    \n",
    "    plt.plot(loss)\n",
    "    plt.title(model_name + \" Model Loss, Trained on \" + loss_name)\n",
    "    \n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend([\"train\"], loc=\"upper left\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cbe793",
   "metadata": {},
   "source": [
    "### Training with MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5d588f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(31.0899, grad_fn=<MseLossBackward0>)\n",
      "Step: 1 Loss: tensor(22.3373, grad_fn=<MseLossBackward0>)\n",
      "Step: 2 Loss: tensor(46.6428, grad_fn=<MseLossBackward0>)\n",
      "Step: 3 Loss: tensor(47.9047, grad_fn=<MseLossBackward0>)\n",
      "Step: 4 Loss: tensor(9.1083, grad_fn=<MseLossBackward0>)\n",
      "Step: 5 Loss: tensor(5.5466, grad_fn=<MseLossBackward0>)\n",
      "Step: 6 Loss: tensor(11.4101, grad_fn=<MseLossBackward0>)\n",
      "Step: 7 Loss: tensor(5.9085, grad_fn=<MseLossBackward0>)\n",
      "Step: 8 Loss: tensor(1.3265, grad_fn=<MseLossBackward0>)\n",
      "Step: 9 Loss: tensor(0.6400, grad_fn=<MseLossBackward0>)\n",
      "Step: 10 Loss: tensor(5.9260, grad_fn=<MseLossBackward0>)\n",
      "Step: 11 Loss: tensor(2.9385, grad_fn=<MseLossBackward0>)\n",
      "Step: 12 Loss: tensor(4.0389, grad_fn=<MseLossBackward0>)\n",
      "Step: 13 Loss: tensor(0.2365, grad_fn=<MseLossBackward0>)\n",
      "Step: 14 Loss: tensor(1.2414, grad_fn=<MseLossBackward0>)\n",
      "Step: 15 Loss: tensor(0.4338, grad_fn=<MseLossBackward0>)\n",
      "Step: 16 Loss: tensor(0.2333, grad_fn=<MseLossBackward0>)\n",
      "Step: 17 Loss: tensor(0.0383, grad_fn=<MseLossBackward0>)\n",
      "Step: 18 Loss: tensor(0.5568, grad_fn=<MseLossBackward0>)\n",
      "Step: 19 Loss: tensor(0.0778, grad_fn=<MseLossBackward0>)\n",
      "Step: 20 Loss: tensor(0.6743, grad_fn=<MseLossBackward0>)\n",
      "Step: 21 Loss: tensor(0.3425, grad_fn=<MseLossBackward0>)\n",
      "Step: 22 Loss: tensor(0.3834, grad_fn=<MseLossBackward0>)\n",
      "Step: 23 Loss: tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "Step: 24 Loss: tensor(0.4367, grad_fn=<MseLossBackward0>)\n",
      "Step: 25 Loss: tensor(0.0536, grad_fn=<MseLossBackward0>)\n",
      "Step: 26 Loss: tensor(0.0309, grad_fn=<MseLossBackward0>)\n",
      "Step: 27 Loss: tensor(0.0635, grad_fn=<MseLossBackward0>)\n",
      "Step: 28 Loss: tensor(0.0499, grad_fn=<MseLossBackward0>)\n",
      "Step: 29 Loss: tensor(0.0443, grad_fn=<MseLossBackward0>)\n",
      "Step: 30 Loss: tensor(0.4681, grad_fn=<MseLossBackward0>)\n",
      "Step: 31 Loss: tensor(0.0715, grad_fn=<MseLossBackward0>)\n",
      "Step: 32 Loss: tensor(0.0828, grad_fn=<MseLossBackward0>)\n",
      "Step: 33 Loss: tensor(0.1616, grad_fn=<MseLossBackward0>)\n",
      "Step: 34 Loss: tensor(0.1587, grad_fn=<MseLossBackward0>)\n",
      "Step: 35 Loss: tensor(0.1154, grad_fn=<MseLossBackward0>)\n",
      "Step: 36 Loss: tensor(0.0752, grad_fn=<MseLossBackward0>)\n",
      "Step: 37 Loss: tensor(0.1033, grad_fn=<MseLossBackward0>)\n",
      "Step: 38 Loss: tensor(0.1368, grad_fn=<MseLossBackward0>)\n",
      "Step: 39 Loss: tensor(0.0532, grad_fn=<MseLossBackward0>)\n",
      "Step: 40 Loss: tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "Step: 41 Loss: tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "Step: 42 Loss: tensor(0.0351, grad_fn=<MseLossBackward0>)\n",
      "Step: 43 Loss: tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "Step: 44 Loss: tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "Step: 45 Loss: tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "Step: 46 Loss: tensor(0.0337, grad_fn=<MseLossBackward0>)\n",
      "Step: 47 Loss: tensor(0.0349, grad_fn=<MseLossBackward0>)\n",
      "Step: 48 Loss: tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "Step: 49 Loss: tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "Step: 50 Loss: tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "Step: 51 Loss: tensor(0.0550, grad_fn=<MseLossBackward0>)\n",
      "Step: 52 Loss: tensor(0.0759, grad_fn=<MseLossBackward0>)\n",
      "Step: 53 Loss: tensor(0.1306, grad_fn=<MseLossBackward0>)\n",
      "Step: 54 Loss: tensor(0.0625, grad_fn=<MseLossBackward0>)\n",
      "Step: 55 Loss: tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "Step: 56 Loss: tensor(0.0421, grad_fn=<MseLossBackward0>)\n",
      "Step: 57 Loss: tensor(0.0397, grad_fn=<MseLossBackward0>)\n",
      "Step: 58 Loss: tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "Step: 59 Loss: tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "Step: 60 Loss: tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "Step: 61 Loss: tensor(0.0518, grad_fn=<MseLossBackward0>)\n",
      "Step: 62 Loss: tensor(0.0342, grad_fn=<MseLossBackward0>)\n",
      "Step: 63 Loss: tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "Step: 64 Loss: tensor(0.0289, grad_fn=<MseLossBackward0>)\n",
      "Step: 65 Loss: tensor(0.0924, grad_fn=<MseLossBackward0>)\n",
      "Step: 66 Loss: tensor(0.3019, grad_fn=<MseLossBackward0>)\n",
      "Step: 67 Loss: tensor(0.0345, grad_fn=<MseLossBackward0>)\n",
      "Step: 68 Loss: tensor(0.0269, grad_fn=<MseLossBackward0>)\n",
      "Step: 69 Loss: tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "Step: 70 Loss: tensor(0.0709, grad_fn=<MseLossBackward0>)\n",
      "Step: 71 Loss: tensor(0.8876, grad_fn=<MseLossBackward0>)\n",
      "Step: 72 Loss: tensor(0.0785, grad_fn=<MseLossBackward0>)\n",
      "Step: 73 Loss: tensor(0.1601, grad_fn=<MseLossBackward0>)\n",
      "Step: 74 Loss: tensor(0.0302, grad_fn=<MseLossBackward0>)\n",
      "Step: 75 Loss: tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "Step: 76 Loss: tensor(0.0439, grad_fn=<MseLossBackward0>)\n",
      "Step: 77 Loss: tensor(0.0533, grad_fn=<MseLossBackward0>)\n",
      "Step: 78 Loss: tensor(0.0320, grad_fn=<MseLossBackward0>)\n",
      "Step: 79 Loss: tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
      "Step: 80 Loss: tensor(0.0582, grad_fn=<MseLossBackward0>)\n",
      "Step: 81 Loss: tensor(0.0305, grad_fn=<MseLossBackward0>)\n",
      "Step: 82 Loss: tensor(0.0425, grad_fn=<MseLossBackward0>)\n",
      "Step: 83 Loss: tensor(0.2285, grad_fn=<MseLossBackward0>)\n",
      "Step: 84 Loss: tensor(0.1762, grad_fn=<MseLossBackward0>)\n",
      "Step: 85 Loss: tensor(0.0582, grad_fn=<MseLossBackward0>)\n",
      "Step: 86 Loss: tensor(0.5308, grad_fn=<MseLossBackward0>)\n",
      "Step: 87 Loss: tensor(0.0399, grad_fn=<MseLossBackward0>)\n",
      "Step: 88 Loss: tensor(0.1723, grad_fn=<MseLossBackward0>)\n",
      "Step: 89 Loss: tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "Step: 90 Loss: tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "Step: 91 Loss: tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "Step: 92 Loss: tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "Step: 93 Loss: tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "Step: 94 Loss: tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "Step: 95 Loss: tensor(0.0337, grad_fn=<MseLossBackward0>)\n",
      "Step: 96 Loss: tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "Step: 97 Loss: tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "Step: 98 Loss: tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "Step: 99 Loss: tensor(0.2830, grad_fn=<MseLossBackward0>)\n",
      "Step: 100 Loss: tensor(0.2647, grad_fn=<MseLossBackward0>)\n",
      "Step: 101 Loss: tensor(0.0797, grad_fn=<MseLossBackward0>)\n",
      "Step: 102 Loss: tensor(0.1664, grad_fn=<MseLossBackward0>)\n",
      "Step: 103 Loss: tensor(0.1006, grad_fn=<MseLossBackward0>)\n",
      "Step: 104 Loss: tensor(0.0847, grad_fn=<MseLossBackward0>)\n",
      "Step: 105 Loss: tensor(0.0415, grad_fn=<MseLossBackward0>)\n",
      "Step: 106 Loss: tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "Step: 107 Loss: tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "Step: 108 Loss: tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "Step: 109 Loss: tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "Step: 110 Loss: tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "Step: 111 Loss: tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "Step: 112 Loss: tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "Step: 113 Loss: tensor(0.0330, grad_fn=<MseLossBackward0>)\n",
      "Step: 114 Loss: tensor(0.0399, grad_fn=<MseLossBackward0>)\n",
      "Step: 115 Loss: tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "Step: 116 Loss: tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "Step: 117 Loss: tensor(0.0500, grad_fn=<MseLossBackward0>)\n",
      "Step: 118 Loss: tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "Step: 119 Loss: tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "Step: 120 Loss: tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "Step: 121 Loss: tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "Step: 122 Loss: tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "Step: 123 Loss: tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "Step: 124 Loss: tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "Step: 125 Loss: tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "Step: 126 Loss: tensor(0.0503, grad_fn=<MseLossBackward0>)\n",
      "Step: 127 Loss: tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "Step: 128 Loss: tensor(0.0441, grad_fn=<MseLossBackward0>)\n",
      "Step: 129 Loss: tensor(0.0896, grad_fn=<MseLossBackward0>)\n",
      "Step: 130 Loss: tensor(0.0521, grad_fn=<MseLossBackward0>)\n",
      "Step: 131 Loss: tensor(0.0486, grad_fn=<MseLossBackward0>)\n",
      "Step: 132 Loss: tensor(0.0566, grad_fn=<MseLossBackward0>)\n",
      "Step: 133 Loss: tensor(0.0378, grad_fn=<MseLossBackward0>)\n",
      "Step: 134 Loss: tensor(0.0282, grad_fn=<MseLossBackward0>)\n",
      "Step: 135 Loss: tensor(0.0371, grad_fn=<MseLossBackward0>)\n",
      "Step: 136 Loss: tensor(0.0604, grad_fn=<MseLossBackward0>)\n",
      "Step: 137 Loss: tensor(0.0459, grad_fn=<MseLossBackward0>)\n",
      "Step: 138 Loss: tensor(0.0385, grad_fn=<MseLossBackward0>)\n",
      "Step: 139 Loss: tensor(0.0337, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 140 Loss: tensor(0.0317, grad_fn=<MseLossBackward0>)\n",
      "Step: 141 Loss: tensor(0.0369, grad_fn=<MseLossBackward0>)\n",
      "Step: 142 Loss: tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "Step: 143 Loss: tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "Step: 144 Loss: tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "Step: 145 Loss: tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "Step: 146 Loss: tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "Step: 147 Loss: tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "Step: 148 Loss: tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "Step: 149 Loss: tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "Step: 150 Loss: tensor(0.0751, grad_fn=<MseLossBackward0>)\n",
      "Step: 151 Loss: tensor(0.0576, grad_fn=<MseLossBackward0>)\n",
      "Step: 152 Loss: tensor(0.1565, grad_fn=<MseLossBackward0>)\n",
      "Step: 153 Loss: tensor(0.0523, grad_fn=<MseLossBackward0>)\n",
      "Step: 154 Loss: tensor(0.0489, grad_fn=<MseLossBackward0>)\n",
      "Step: 155 Loss: tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "Step: 156 Loss: tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "Step: 157 Loss: tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "Step: 158 Loss: tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "Step: 159 Loss: tensor(0.0551, grad_fn=<MseLossBackward0>)\n",
      "Step: 160 Loss: tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "Step: 161 Loss: tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "Step: 162 Loss: tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "Step: 163 Loss: tensor(0.0363, grad_fn=<MseLossBackward0>)\n",
      "Step: 164 Loss: tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "Step: 165 Loss: tensor(0.0296, grad_fn=<MseLossBackward0>)\n",
      "Step: 166 Loss: tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "Step: 167 Loss: tensor(0.0397, grad_fn=<MseLossBackward0>)\n",
      "Step: 168 Loss: tensor(0.0306, grad_fn=<MseLossBackward0>)\n",
      "Step: 169 Loss: tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "Step: 170 Loss: tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "Step: 171 Loss: tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "Step: 172 Loss: tensor(0.0285, grad_fn=<MseLossBackward0>)\n",
      "Step: 173 Loss: tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "Step: 174 Loss: tensor(0.0448, grad_fn=<MseLossBackward0>)\n",
      "Step: 175 Loss: tensor(0.0524, grad_fn=<MseLossBackward0>)\n",
      "Step: 176 Loss: tensor(0.0336, grad_fn=<MseLossBackward0>)\n",
      "Step: 177 Loss: tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "Step: 178 Loss: tensor(0.0560, grad_fn=<MseLossBackward0>)\n",
      "Step: 179 Loss: tensor(0.0606, grad_fn=<MseLossBackward0>)\n",
      "Step: 180 Loss: tensor(0.0345, grad_fn=<MseLossBackward0>)\n",
      "Step: 181 Loss: tensor(0.0639, grad_fn=<MseLossBackward0>)\n",
      "Step: 182 Loss: tensor(0.0436, grad_fn=<MseLossBackward0>)\n",
      "Step: 183 Loss: tensor(0.0291, grad_fn=<MseLossBackward0>)\n",
      "Step: 184 Loss: tensor(0.0325, grad_fn=<MseLossBackward0>)\n",
      "Step: 185 Loss: tensor(0.0276, grad_fn=<MseLossBackward0>)\n",
      "Step: 186 Loss: tensor(0.0548, grad_fn=<MseLossBackward0>)\n",
      "Step: 187 Loss: tensor(0.0401, grad_fn=<MseLossBackward0>)\n",
      "Step: 188 Loss: tensor(0.0410, grad_fn=<MseLossBackward0>)\n",
      "Step: 189 Loss: tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "Step: 190 Loss: tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "Step: 191 Loss: tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "Step: 192 Loss: tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "Step: 193 Loss: tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "Step: 194 Loss: tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "Step: 195 Loss: tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "Step: 196 Loss: tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "Step: 197 Loss: tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "Step: 198 Loss: tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "Step: 199 Loss: tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "Step: 200 Loss: tensor(0.0549, grad_fn=<MseLossBackward0>)\n",
      "Step: 201 Loss: tensor(0.1509, grad_fn=<MseLossBackward0>)\n",
      "Step: 202 Loss: tensor(0.1510, grad_fn=<MseLossBackward0>)\n",
      "Step: 203 Loss: tensor(0.0578, grad_fn=<MseLossBackward0>)\n",
      "Step: 204 Loss: tensor(0.0549, grad_fn=<MseLossBackward0>)\n",
      "Step: 205 Loss: tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "Step: 206 Loss: tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "Step: 207 Loss: tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "Step: 208 Loss: tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "Step: 209 Loss: tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "Step: 210 Loss: tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "Step: 211 Loss: tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "Step: 212 Loss: tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "Step: 213 Loss: tensor(0.0402, grad_fn=<MseLossBackward0>)\n",
      "Step: 214 Loss: tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "Step: 215 Loss: tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "Step: 216 Loss: tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "Step: 217 Loss: tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "Step: 218 Loss: tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "Step: 219 Loss: tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "Step: 220 Loss: tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "Step: 221 Loss: tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "Step: 222 Loss: tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "Step: 223 Loss: tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "Step: 224 Loss: tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "Step: 225 Loss: tensor(0.0375, grad_fn=<MseLossBackward0>)\n",
      "Step: 226 Loss: tensor(0.0317, grad_fn=<MseLossBackward0>)\n",
      "Step: 227 Loss: tensor(0.0297, grad_fn=<MseLossBackward0>)\n",
      "Step: 228 Loss: tensor(0.1018, grad_fn=<MseLossBackward0>)\n",
      "Step: 229 Loss: tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "Step: 230 Loss: tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "Step: 231 Loss: tensor(0.0960, grad_fn=<MseLossBackward0>)\n",
      "Step: 232 Loss: tensor(0.0686, grad_fn=<MseLossBackward0>)\n",
      "Step: 233 Loss: tensor(0.0540, grad_fn=<MseLossBackward0>)\n",
      "Step: 234 Loss: tensor(0.1410, grad_fn=<MseLossBackward0>)\n",
      "Step: 235 Loss: tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "Step: 236 Loss: tensor(0.0298, grad_fn=<MseLossBackward0>)\n",
      "Step: 237 Loss: tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "Step: 238 Loss: tensor(0.1428, grad_fn=<MseLossBackward0>)\n",
      "Step: 239 Loss: tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "Step: 240 Loss: tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "Step: 241 Loss: tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "Step: 242 Loss: tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "Step: 243 Loss: tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "Step: 244 Loss: tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "Step: 245 Loss: tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "Step: 246 Loss: tensor(0.1336, grad_fn=<MseLossBackward0>)\n",
      "Step: 247 Loss: tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "Step: 248 Loss: tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "Step: 249 Loss: tensor(0.0371, grad_fn=<MseLossBackward0>)\n",
      "Step: 250 Loss: tensor(0.0440, grad_fn=<MseLossBackward0>)\n",
      "Step: 251 Loss: tensor(0.1653, grad_fn=<MseLossBackward0>)\n",
      "Step: 252 Loss: tensor(0.1356, grad_fn=<MseLossBackward0>)\n",
      "Step: 253 Loss: tensor(0.0424, grad_fn=<MseLossBackward0>)\n",
      "Step: 254 Loss: tensor(0.0330, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "learning_rate = 1e-3\n",
    "epochs = 10\n",
    "\n",
    "model = CDNN(hist=4, name=\"BezCDNN\") \n",
    "loss_fn = nn.MSELoss(reduction=\"mean\") \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "print(\"Training...\")\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    epoch_loss = round(np.mean(train_loop(training_loader, model, loss_fn, optimizer)), 5)\n",
    "    print(\"Mean:\", epoch_loss)\n",
    "    train_losses.append(epoch_loss)\n",
    "    \n",
    "    #test_loop(test_dataloader, model, loss_fn)\n",
    "    \n",
    "# Save losses to file for plotting and analysis later\n",
    "fname = model.name + \"_\" + str(datetime.date.today()) + \"_trainMSE_trainLoss\"\n",
    "np.save(\"/projectnb/labci/Lucia/data/loss_outputs/\" + fname, train_losses)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c819c2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation...\")\n",
    "val_losses = test_loop(val_loader, model, nn.MSELoss(reduction=\"mean\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "218.182px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
