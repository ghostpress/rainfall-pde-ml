{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e51c2d6",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports-and-setup-functions\" data-toc-modified-id=\"Imports-and-setup-functions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports and setup functions</a></span></li><li><span><a href=\"#DataLoader-Module\" data-toc-modified-id=\"DataLoader-Module-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>DataLoader Module</a></span><ul class=\"toc-item\"><li><span><a href=\"#Image-regions\" data-toc-modified-id=\"Image-regions-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Image regions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Find-interesting-regions-to-test-on\" data-toc-modified-id=\"Find-interesting-regions-to-test-on-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Find interesting regions to test on</a></span></li><li><span><a href=\"#Cut-all-data-into-64x64-regions\" data-toc-modified-id=\"Cut-all-data-into-64x64-regions-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Cut all data into 64x64 regions</a></span></li><li><span><a href=\"#Save-to-.npy-files\" data-toc-modified-id=\"Save-to-.npy-files-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Save to .npy files</a></span></li></ul></li><li><span><a href=\"#Train-val-test-split\" data-toc-modified-id=\"Train-val-test-split-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Train-val-test split</a></span></li><li><span><a href=\"#Inputs-and-ends\" data-toc-modified-id=\"Inputs-and-ends-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Inputs and ends</a></span></li><li><span><a href=\"#Tensors,-DataLoader\" data-toc-modified-id=\"Tensors,-DataLoader-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Tensors, DataLoader</a></span></li><li><span><a href=\"#Create-DataLoader-for-training-data\" data-toc-modified-id=\"Create-DataLoader-for-training-data-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Create DataLoader for training data</a></span></li></ul></li><li><span><a href=\"#Model-Module\" data-toc-modified-id=\"Model-Module-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Model Module</a></span><ul class=\"toc-item\"><li><span><a href=\"#AR1:-linear-mapping\" data-toc-modified-id=\"AR1:-linear-mapping-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>AR1: linear mapping</a></span></li><li><span><a href=\"#de-Bézenac-et-al,-2019:-CNN-with-warp-mapping\" data-toc-modified-id=\"de-Bézenac-et-al,-2019:-CNN-with-warp-mapping-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>de Bézenac et al, 2019: CNN with warp mapping</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loss-Function\" data-toc-modified-id=\"Loss-Function-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Loss Function</a></span></li><li><span><a href=\"#Warp\" data-toc-modified-id=\"Warp-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Warp</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Model</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-3.2.4\"><span class=\"toc-item-num\">3.2.4&nbsp;&nbsp;</span>Training</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb70983",
   "metadata": {},
   "source": [
    "# Imports and setup functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6754139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Function, Variable\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2088495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datadir(x):\n",
    "    return \"/projectnb/labci/Lucia/data/\" + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "248f8717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename):\n",
    "    torch.save(state, filename)  \n",
    "    print(\"State saved: \" + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f15e4f",
   "metadata": {},
   "source": [
    "# DataLoader Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a8f21d",
   "metadata": {},
   "source": [
    "## Train-val-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715c5887",
   "metadata": {},
   "source": [
    "The authors trained on SST data from 2006-2015 and tested on data from 2016-2017. For the IBI reanalysis SST data, we only have from June 5, 2021 to June 23, 2023 (749 days). From these, we will use 80% for training, 10% for validation, and 10% for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7d16162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_days(files):\n",
    "    \"\"\"Helper method to take a list of filenames and return total the number \n",
    "    of days represented by the files in the list. \n",
    "    \n",
    "    This method assumes a particular file naming convention that has been used \n",
    "    for this project. \n",
    "    \n",
    "    File naming convention: sst_geo_yyyymmdd.nc_region_XX.npy\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    files : list : data file names\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    delta : int : the number of days represented by the inputted files\n",
    "    \"\"\"\n",
    "    \n",
    "    files.sort()\n",
    "    \n",
    "    first = datetime.datetime.strptime(files[0][8:16], \"%Y%m%d\").date()\n",
    "    last = datetime.datetime.strptime(files[len(files)-1][8:16], \"%Y%m%d\").date()\n",
    "    \n",
    "    delta = int((last - first) / datetime.timedelta(days=1))\n",
    "    \n",
    "    return delta\n",
    "\n",
    "def train_val_test_cutoffs(topdir, split):\n",
    "    \"\"\"Helper method to create lists of filenames for the train, val, and test\n",
    "    data splits. Uses the dates in the filenames to determine file order and \n",
    "    split cutoffs.\n",
    "    \n",
    "    This method assumes a particular file naming convention that has been used \n",
    "    for this project. \n",
    "    \n",
    "    File naming convention: sst_geo_yyyymmdd.nc_region_XX.npy\n",
    "       \n",
    "    Parameters\n",
    "    ----------\n",
    "    topdir : string : the path to the directory holding the data\n",
    "    split : list : the fractions for each split, eg. [0.8, 0.1, 0.1]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    cutoffs : list : date cutoffs for each split\n",
    "    \"\"\"\n",
    "    \n",
    "    all_files = os.listdir(topdir)\n",
    "    all_files.sort()\n",
    "    nfiles = len(all_files)\n",
    "    ndays = all_days(all_files)\n",
    "    \n",
    "    start_date = datetime.datetime.strptime(all_files[0][8:16], \"%Y%m%d\").date()\n",
    "    end_date = datetime.datetime.strptime(all_files[nfiles-1][8:16], \"%Y%m%d\").date()\n",
    "    \n",
    "    cutoffs = []\n",
    "    \n",
    "    for i in range(3):\n",
    "        delta = math.floor(ndays*split[i])\n",
    "        end = start_date + datetime.timedelta(days=delta)\n",
    "        cutoffs.append(end)\n",
    "        \n",
    "        start_date = end\n",
    "        \n",
    "    # Because of rounding, some files may have been missed\n",
    "    # Add these to the test split\n",
    "    if cutoffs[2] < end_date:\n",
    "        cutoffs[2] = end_date\n",
    "    \n",
    "    return cutoffs\n",
    "\n",
    "def train_val_test_split_files(topdir, split):\n",
    "    \"\"\"Method to split the data in a directory into training, validation, and\n",
    "    test sets. Uses the helper method train_val_test_cutoffs().\n",
    "    \n",
    "    This method assumes a particular file naming convention that has been used \n",
    "    for this project. \n",
    "    \n",
    "    File naming convention: sst_geo_yyyymmdd.nc_region_XX.npy\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    topdir : string : the path to the directory holding the data\n",
    "    split : list : the fractions for each split, eg. [0.8, 0.1, 0.1]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    train : list : list of filenames for the train set\n",
    "    val : list : list of filenames for the validation set\n",
    "    test : list : list of filenames for the test set\n",
    "    \"\"\"\n",
    "    \n",
    "    assert len(split) == 3, \"Please include a % split for train, validation, and test sets.\"\n",
    "    \n",
    "    cutoffs = train_val_test_cutoffs(topdir, split)\n",
    "    \n",
    "    all_files = os.listdir(topdir)\n",
    "    all_files.sort()\n",
    "    \n",
    "    train, val, test = [], [], []\n",
    "    \n",
    "    for f in all_files:\n",
    "        file_date = datetime.datetime.strptime(f[8:16], \"%Y%m%d\").date()\n",
    "        \n",
    "        if file_date <= cutoffs[0]:\n",
    "            train.append(f)\n",
    "        elif (file_date > cutoffs[0]) & (file_date <= cutoffs[1]):\n",
    "            val.append(f)\n",
    "        else:\n",
    "            test.append(f)\n",
    "            \n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38bda7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_file(filename):\n",
    "    \"\"\"Helper method to load a single .npy file.\"\"\"\n",
    "    return np.load(datadir(\"sst_npy/\" + filename))\n",
    "\n",
    "\n",
    "def load_data_from_files(files):\n",
    "    \"\"\"Method to load data from a list of .npy files.\"\"\"\n",
    "    data = []\n",
    "    for f in files:\n",
    "        data.append(load_data_from_file(f))\n",
    "        \n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2117c9",
   "metadata": {},
   "source": [
    "## Inputs and ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5a6a4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_by_region(files, region):\n",
    "    \"\"\"Helper method to search a list of files for only those corresponding to\n",
    "    a desired region. \n",
    "    \n",
    "    This method assumes a particular file naming convention that has been used \n",
    "    for this project. \n",
    "    \n",
    "    File naming convention: sst_geo_yyyymmdd.nc_region_XX.npy\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    files : list : list of filenames in which to search\n",
    "    region : int : desired region\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    region_files : list : sorted list of matching files\n",
    "    \"\"\"\n",
    "    \n",
    "    region_files = []\n",
    "    for fname in files:\n",
    "        if \"region_\" + str(region) + \".npy\" in fname:\n",
    "            region_files.append(fname)\n",
    "            \n",
    "    region_files.sort()\n",
    "    \n",
    "    return region_files\n",
    "\n",
    "def get_pairs_by_region(files, region, ndays=1):\n",
    "    \"\"\"Method to separate data into inputs (X) and ends (y), for example to\n",
    "    use 4 previous days (ndays=4) to predict the next day. The \"pairs\" are \n",
    "    pairs of (X,y) inputs and ends. This method works on one region at a time.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    files : list : list of files from which to get pairs\n",
    "    region : int : desired region\n",
    "    ndays : int : number of days to use as inputs\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    inps : np.ndarray : filenames for inputs\n",
    "    ends : list : filenames for ends\n",
    "    \"\"\"\n",
    "    \n",
    "    region_files = search_by_region(files, region)\n",
    "    \n",
    "    n = len(region_files)\n",
    "    \n",
    "    inps = []\n",
    "    ends = region_files[ndays:]\n",
    "    \n",
    "    for i in range(n - ndays):\n",
    "        inps.append(region_files[i:i+ndays])\n",
    "    \n",
    "    return np.array(inps), np.array(ends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43858887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_regions(files):\n",
    "    \"\"\"Helper method to take a list of filenames and return a list of the \n",
    "    unique region numbers. \n",
    "    \n",
    "    This method assumes a particular file naming convention that has been used \n",
    "    for this project. \n",
    "    \n",
    "    File naming convention: sst_geo_yyyymmdd.nc_region_XX.npy\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    files : list : data file names\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    regions : list : list of unique region numbers in the directory\n",
    "    \"\"\"\n",
    "    \n",
    "    files.sort()\n",
    "    regions = []\n",
    "    \n",
    "    for f in files:\n",
    "        if \"region_\" in f:\n",
    "            \n",
    "            start_ind = f.find(\"region_\") + len(\"region_\")\n",
    "            end_ind = f.find(\".npy\")\n",
    "            \n",
    "            reg = f[start_ind:end_ind]\n",
    "            \n",
    "            if int(reg) not in regions:\n",
    "                regions.append(int(reg))\n",
    "            \n",
    "        else:\n",
    "            print(\"Files in this directory do not match the naming convention.\")\n",
    "    \n",
    "    regions.sort()\n",
    "    \n",
    "    return regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8510e497",
   "metadata": {},
   "source": [
    "## Tensors, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa7d662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(batchsize, files, ndays, dtype=torch.FloatTensor):\n",
    "    \"\"\"Method to create a PyTorch DataLoader object from a list of files and\n",
    "    additional parameters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dtype : torch.dtype : the data type for the DataLoader\n",
    "    batchsize : int : the desired batchsize for loading data\n",
    "    files : str : a list of files holding data to put into the DataLoader\n",
    "    ndays : int : the number of days to use as inputs to predict the next day\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    training : torch.utils.data.DataLoader : the DataLoader object\n",
    "    \"\"\"\n",
    "    \n",
    "    regions = all_regions(files)\n",
    "\n",
    "    data = []\n",
    "    ends = []\n",
    "\n",
    "    for reg in regions:\n",
    "        reg_pairs = get_pairs_by_region(files, reg, ndays)\n",
    "        \n",
    "        for i in range(len(reg_pairs[0])):\n",
    "            dat = load_data_from_files(reg_pairs[0][i])\n",
    "            end = load_data_from_file(reg_pairs[1][i])\n",
    "        \n",
    "            data.append(dat)\n",
    "            ends.append(end)\n",
    "        \n",
    "    final_data = torch.from_numpy(np.array(data)).type(dtype)\n",
    "    final_ends = torch.from_numpy(np.array(ends)).type(dtype)\n",
    "    \n",
    "    training = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(final_data, final_ends),\n",
    "                                           batch_size=batchsize, shuffle=False)\n",
    "    \n",
    "    return training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06015e1",
   "metadata": {},
   "source": [
    "# Model Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ade1fba",
   "metadata": {},
   "source": [
    "## de Bézenac et al, 2019: CNN with warp mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e569ea",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2632738",
   "metadata": {},
   "source": [
    "The authors used a Charbonnier penality to measure the discrepancy between the predicted next image and the target: \n",
    "\n",
    "$\\rho(x) = (x + \\epsilon)^\\frac{1}{\\alpha}$\n",
    "\n",
    "Note that with $\\epsilon=0$ and $\\alpha=\\frac{1}{2}$, we recover the $\\textit{l}_2$ norm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a26ac1",
   "metadata": {},
   "source": [
    "The gradient wrt $x$:\n",
    "\n",
    "$\\frac{d \\rho(x)}{dx} = \\frac{1}{\\alpha}(x+\\epsilon)^{\\frac{1}{\\alpha}-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc041ab",
   "metadata": {},
   "source": [
    "Additional penalty terms were added to the loss function, specifically to regulate the divergence of the displacement $\\omega$ between the prediction and the target, its magnitude, and its smoothness:\n",
    "\n",
    "$L_t = \\underset{x \\in \\Omega}\\Sigma \\rho(\\hat{I}_{t+1}(x) - I_{t+1}(x)) + \\lambda_{div}(\\nabla.\\omega_t(x))^2 + \\lambda_{magn}||\\omega_t(x)||^2 + \\lambda_{grad}||\\nabla \\omega_t(x)||^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29f28761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_regloss(F):\n",
    "    gradient = reduce(np.add, np.gradient(F))\n",
    "    \n",
    "    divergence = np.array([np.mean(gradient.sum(0)**2)])                         # 1st reg term above\n",
    "    magnitude  = np.array([np.mean(np.linalg.norm(F, axis=0, ord=2)**2)])        # 2nd reg term above\n",
    "    smoothness = np.array([np.mean(np.linalg.norm(gradient, axis=0, ord=2)**2)]) # 3rd reg term above\n",
    "    \n",
    "    return torch.from_numpy(divergence).type(torch.FloatTensor), torch.from_numpy(magnitude).type(torch.FloatTensor), torch.from_numpy(smoothness).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "741a61d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def charbonnier(x, alpha, eps):\n",
    "    \n",
    "    res = torch.mean(torch.pow(x + eps, (1. / alpha)))\n",
    "\n",
    "    return res\n",
    "\n",
    "def grad_charbonnier(x, alpha, eps):\n",
    "    \n",
    "    res = (1. / alpha)*torch.pow(x + eps, (1. / alpha) - 1)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "108d33db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Charbonnier_Loss(Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctl, y_pred, y, w, alpha=0.5, eps=0):\n",
    "        lambda_div, lambda_magn, lambda_grad = 1, -0.1, 0.4\n",
    "        ctl.save_for_backward(y_pred, y) # saves Tensor ctl for future call to backward()\n",
    "        \n",
    "        divergence, magnitude, smoothness = compute_regloss(w[0,:,:,:].numpy())\n",
    "        \n",
    "        distsq = torch.pow(y_pred - y, 2)\n",
    "        loss = charbonnier(distsq, alpha, eps) + lambda_div*divergence + lambda_magn*magnitude + lambda_grad*smoothness\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctl, alpha=0.5, eps=0):\n",
    "        y_pred, y = ctl.saved_tensors\n",
    "        distsq = torch.pow(y_pred - y, 2)\n",
    "\n",
    "        grad = grad_charbonnier(distsq, alpha, eps)\n",
    "        \n",
    "        return grad, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b406bf74",
   "metadata": {},
   "source": [
    "### Warp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e686d5",
   "metadata": {},
   "source": [
    "The future image is calculated based on a \"warp\" of the motion field estimate, $\\hat{\\omega}$, which can be thought of in this application as the wind vector field:\n",
    "\n",
    "$\\hat{I}_{t+1}(x) = \\underset{y \\in \\Omega} \\Sigma k(x - \\hat{\\omega}(x), y) I_t (y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5484aec7",
   "metadata": {},
   "source": [
    "where $k(u, v)$ is a radial basis function kernel, or equivalent a 2D Gaussian probability distribution:\n",
    "\n",
    "$k(x - \\hat{\\omega}(x), y) = \\frac{1}{4 \\pi D\\Delta t}e^{\\frac{-1}{4D \\Delta t} ||x - \\hat{\\omega}(x) - y||^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad59f08",
   "metadata": {},
   "source": [
    "for diffusion coefficient D and time step value $\\Delta t$ between $t$ and $t+1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "917ddf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel(distsq, D, dt):\n",
    "    \"\"\"Method to implement the k() function or radial basis function kernel \n",
    "    described above.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    distsq : float or torch.FloatTensor : the value of the squared norm of \n",
    "                 the distance\n",
    "    D : float : the diffusion coefficient\n",
    "    dt : float : the timestep\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    res : float or torch.FloatTensor: the result of the function\n",
    "    \"\"\"\n",
    "    \n",
    "    res = torch.exp(-distsq/(4*D*dt))/(4*np.pi*D*dt)\n",
    "    return res\n",
    "\n",
    "def kernel_gradient(self, dist, D, dt):\n",
    "    \"\"\"Method to implement the gradient of the k() function with respect to \n",
    "    the distance.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dist : float : the distance\n",
    "    D : float : the diffusion coefficient\n",
    "    dt : float : the timestep\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    res : float : the gradient of the function with respect to the distance\n",
    "    \"\"\"\n",
    "    \n",
    "    res = dist*torch.exp(-(dist**2).sum(1)/(4*D*dt))/(8*np.pi*D**2*dt**2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56d65cd",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b915e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(*models):\n",
    "    for model in models:\n",
    "        for module in model.modules():\n",
    "            \n",
    "            if isinstance(module, nn.Conv2d) or isinstance(module, nn.ConvTranspose2d) or isinstance(module, nn.Linear):\n",
    "                \n",
    "                # He initialization, from He, K. et al, 2015\n",
    "                nn.init.kaiming_normal_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    module.bias.data.zero_()\n",
    "                    \n",
    "            elif isinstance(module, nn.BatchNorm2d):\n",
    "                module.weight.data.fill_(1)\n",
    "                module.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71dfa15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(_EncoderBlock, self).__init__()\n",
    "        self.cv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.lr1 = nn.LeakyReLU(0.1)\n",
    "        self.cv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.lr2 = nn.LeakyReLU(0.1)\n",
    "        self.maxp = nn.MaxPool2d(kernel_size=3, stride=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual=x\n",
    "        #print(\"residual\",residual.shape)\n",
    "        out=self.cv1(x)\n",
    "        #print(\"cv1\",out.shape)\n",
    "        out=self.bn1(out)\n",
    "        #print(\"bn1\",out.shape)\n",
    "        out=self.lr1(out)\n",
    "        #print(\"lr1\",out.shape)\n",
    "        out+=residual\n",
    "        out=self.cv2(out)\n",
    "        out=self.bn2(out)\n",
    "        out=self.lr2(out)\n",
    "        out=self.maxp(out)\n",
    "        return out\n",
    "\n",
    "class _DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels):\n",
    "        super(_DecoderBlock, self).__init__()\n",
    "        self.cv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.lr1 = nn.LeakyReLU(0.1)\n",
    "        self.cv2 = nn.Conv2d(in_channels, middle_channels, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(middle_channels) \n",
    "        self.lr2 = nn.LeakyReLU(0.1)\n",
    "        self.tcv = nn.ConvTranspose2d(middle_channels, out_channels, kernel_size=3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual=x\n",
    "        #print(\"residual\",residual.shape)\n",
    "        out=self.cv1(x)\n",
    "        #print(\"cv1\",out.shape)\n",
    "        out=self.bn1(out)\n",
    "        #print(\"bn1\",out.shape)\n",
    "        out=self.lr1(out)\n",
    "        #print(\"lr1\",out.shape)\n",
    "        out+=residual\n",
    "        out=self.cv2(out)\n",
    "        out=self.bn2(out)\n",
    "        out=self.lr2(out)\n",
    "        out=self.tcv(out)\n",
    "        return out\n",
    "\n",
    "class _CenterBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(_CenterBlock, self).__init__()\n",
    "        self.cv1 = nn.Conv2d(in_channels,in_channels , kernel_size=3,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)  \n",
    "        self.lr1 = nn.LeakyReLU(0.1)\n",
    "        self.cv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels) \n",
    "        self.lr2 = nn.LeakyReLU(0.1)\n",
    "        self.tcv = nn.ConvTranspose2d(out_channels, out_channels, kernel_size=3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual=x\n",
    "        out=self.cv1(x)\n",
    "        out=self.bn1(out)\n",
    "        out=self.lr1(out)\n",
    "        out+=residual\n",
    "        out=self.cv2(out)\n",
    "        out=self.bn2(out)\n",
    "        out=self.lr2(out)\n",
    "        out=self.tcv(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dc45117",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDNN(nn.Module):\n",
    "    \"\"\"Class to implement a physics-driven Convolution-Deconvolution Neural \n",
    "    Network (CDNN) as described in (de Bezenac et al, 2019). This model \n",
    "    takes as input historical image(s) of Sea Surface Temperature (SST)\n",
    "    data, X, and uses a convolutional neural network (CNN) to estimate the \n",
    "    wind vector field W that drives the motion of X. From there, the next \n",
    "    image is predicted using a \"warping\" of the most recent input image and W,\n",
    "    as if to see how the SST variable evolves with the wind. \n",
    "    \n",
    "    The \"warping\" in this paper is a radial basis function kernel, or a \n",
    "    Gaussian centered in X-W. Other models we will implement later may use a\n",
    "    different warping scheme. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hist=1):\n",
    "        \"\"\"Function to construct the model. \n",
    "           \n",
    "           Parameters\n",
    "           ----------\n",
    "           hist : int : the number of days of \"history\" to use for prediction, \n",
    "                        default = 1.\n",
    "        \"\"\"\n",
    "        \n",
    "        super(CDNN, self).__init__()\n",
    "        \n",
    "        self.enc1 = _EncoderBlock(hist, 64)  \n",
    "        self.enc2 = _EncoderBlock(64, 128)\n",
    "        self.enc3 = _EncoderBlock(128, 256)\n",
    "        self.enc4 = _EncoderBlock(256, 512)\n",
    "        self.dec4 = _CenterBlock(512, 386)\n",
    "        self.dec3 = _DecoderBlock(386+256, 256, 194)\n",
    "        self.dec2 = _DecoderBlock(194+128, 128, 98)\n",
    "        self.dec1 = _DecoderBlock(98+64, 64, 2)\n",
    "        \n",
    "        self.final = nn.Sequential(nn.Conv2d(2, 2, kernel_size=3),) \n",
    "        initialize_weights(self)\n",
    "\n",
    "        self.hist = hist\n",
    "\n",
    "    def wind(self, x):\n",
    "        \"\"\"Function to estimate the wind vector field from historical input images.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.FloatTensor : the historical input images\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        wind : torch.FloatTensor : the estimated wind vector field\n",
    "        \"\"\"\n",
    "        \n",
    "        enc1 = self.enc1(x)\n",
    "        #print(\"x\",x.shape)\n",
    "        #print(\"enc1\",enc1.shape)\n",
    "        enc2 = self.enc2(enc1)\n",
    "        #print(\"enc2\",enc2.shape)\n",
    "        enc3 = self.enc3(enc2)\n",
    "        #print(\"enc3\",enc3.shape)\n",
    "        enc4 = self.enc4(enc3)\n",
    "        #print(\"enc4\",enc4.shape)\n",
    "        dec4 = self.dec4(enc4)\n",
    "        #print(\"dec4\",dec4.shape)\n",
    "        \n",
    "        dec3 = self.dec3(torch.cat([dec4, F.interpolate(enc3, dec4.size()[2:], mode='bilinear')], 1))\n",
    "        dec2 = self.dec2(torch.cat([dec3, F.interpolate(enc2, dec3.size()[2:], mode='bilinear')], 1))\n",
    "        dec1 = self.dec1(torch.cat([dec2, F.interpolate(enc1, dec2.size()[2:], mode='bilinear')], 1))\n",
    "        final = self.final(dec1)\n",
    "        \n",
    "        wind = F.interpolate(final, x.size()[2:], mode='bilinear')\n",
    "\n",
    "        return wind\n",
    "    \n",
    "    @staticmethod\n",
    "    def warp(I, W, hist):\n",
    "        \"\"\"Function to compute the warping of the input data and an estimated \n",
    "        wind vector field, in order to produce an output predicted image. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        I : torch.FloatTensor : the most recent input image to warp\n",
    "        W : torch.FloatTensor : the estimated wind vector field\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        warped : torch.FloatTensor : the warped prediction image\n",
    "        \"\"\"\n",
    "        \n",
    "        D = 0.45\n",
    "        dt = 1\n",
    "        \n",
    "        interval=torch.arange(I.size()[-1]).type(torch.FloatTensor)\n",
    "        \n",
    "        x1 = interval[None,:,None,None,None]\n",
    "        x2 = interval[None,None,:,None,None]\n",
    "        y1 = interval[None,None,None,:,None]\n",
    "        y2 = interval[None,None,None,None,:]\n",
    "        \n",
    "        # x - wind - y\n",
    "        distsq = (x1-y1-W[:,0,:,:,None,None])**2+(x2-y2-W[:,1,:,:,None,None])**2         \n",
    "        mult = I[:, hist-1, None,None,:,:] * kernel(distsq, D, dt)\n",
    "        warped = mult.sum(4).sum(3)\n",
    "        \n",
    "        return warped\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Function to execute the forward pass of the model. All of the \n",
    "        computations are done in the methods above, so this function \n",
    "        simply returns their outputs.\n",
    "        \n",
    "        Note: the wind vector field W is returned for use in the \n",
    "        regularized loss function later. For simple difference loss \n",
    "        functions, returning y_pred is sufficient. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.FloatTensor : the historical input images\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        W : torch.FloatTensor : the estimated wind vector field\n",
    "        y_pred : torch.FloatTensor : the predicted next image\n",
    "        \"\"\"\n",
    "        \n",
    "        W = self.wind(x)\n",
    "        y_pred = self.warp(x, W, self.hist) \n",
    "        \n",
    "        return W, y_pred "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd072838",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6550149",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "566d181e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment():\n",
    "    \n",
    "    def __init__(self, name, trainset, valset, testset, model, loss_fn, test_loss, optimizer, examples, outdir):\n",
    "        self.name = name\n",
    "        self.train_loader = trainset \n",
    "        self.val_loader = valset\n",
    "        self.test_loader = testset\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.test_loss = test_loss\n",
    "        self.optimizer = optimizer\n",
    "        self.examples = examples\n",
    "        \n",
    "        self.train_losses = []\n",
    "        self.valid_losses = []\n",
    "        self.test_losses  = []\n",
    "        \n",
    "        # Set up a directory for the experiment\n",
    "        self.dir_setup(outdir)\n",
    "        \n",
    "    def dir_setup(self, parent):\n",
    "        #datef = parent + str(datetime.date.today())#datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\") + \"/\"\n",
    "        self.outdir = parent + \"/\" + self.name\n",
    "        os.mkdir(self.outdir)\n",
    "        print(\"Created new directory to save model states and results: \" + self.outdir)\n",
    "        \n",
    "        #try:\n",
    "        #    os.mkdir(datef)\n",
    "        #except FileExistsError as e:\n",
    "        #    print(\"Already ran experiments today, creating new subfolder.\")\n",
    "        #finally:\n",
    "        #    self.outdir = datef + \"_\" + self.name\n",
    "        #    os.mkdir(self.outdir)\n",
    "        #    print(\"Created new directory to save model states and results: \" + self.outdir)\n",
    "    \n",
    "    def train_loop(self):\n",
    "        size = len(self.train_loader.dataset)\n",
    "        # Set the model to training mode - important for batch normalization and dropout layers\n",
    "        # Unnecessary in this situation but added for best practices\n",
    "        self.model.train()\n",
    "    \n",
    "        losses = []\n",
    "    \n",
    "        for batch, (X, y) in enumerate(self.train_loader):\n",
    "            # Compute prediction and loss\n",
    "            #X = X.to(device) \n",
    "            #y = y.to(device)\n",
    "            outputs = self.model(X)\n",
    "            wind = outputs[0]\n",
    "            y_pred = outputs[1]\n",
    "            \n",
    "            if self.loss_fn == nn.MSELoss():\n",
    "                loss = self.loss_fn(y_pred, y)\n",
    "            else:\n",
    "                loss = self.loss_fn(y_pred, y, wind)\n",
    "                \n",
    "            losses.append(loss.item())\n",
    "        \n",
    "            print(\"Step:\", batch, \"Loss:\", loss)\n",
    "        \n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "        \n",
    "        return losses\n",
    "    \n",
    "    # TODO: implement cross-validation?\n",
    "    # example: https://saturncloud.io/blog/how-to-use-kfold-cross-validation-with-dataloaders-in-pytorch/\n",
    "    def val_loop(self):\n",
    "        # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "        # Unnecessary in this situation but added for best practices\n",
    "        self.model.eval()\n",
    "        losses = []\n",
    "        num_loops = 0\n",
    "\n",
    "        # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "        # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "        with torch.no_grad():\n",
    "            for X, y in self.val_loader:\n",
    "                #X = X.to(device) \n",
    "                #y = y.to(device)\n",
    "                outputs = self.model(X)\n",
    "                y_pred = outputs[1]\n",
    "            \n",
    "                step_loss = self.loss_fn(y_pred, y).item()\n",
    "                print(\"Item:\", num_loops, \"Loss:\", step_loss)\n",
    "                losses.append(step_loss)\n",
    "                num_loops += 1\n",
    "\n",
    "        return losses\n",
    "    \n",
    "    def test(self):\n",
    "        # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "        # Unnecessary in this situation but added for best practices\n",
    "        self.model.eval()\n",
    "        losses = []\n",
    "        num_loops = 0\n",
    "\n",
    "        # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "        # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "        with torch.no_grad():\n",
    "            for X, y in self.test_loader:\n",
    "                #X = X.to(device) \n",
    "                #y = y.to(device)\n",
    "                outputs = self.model(X)\n",
    "                y_pred = outputs[1]\n",
    "            \n",
    "                step_loss = self.test_loss(y_pred, y).item()\n",
    "                print(\"Item:\", num_loops, \"Loss:\", step_loss)\n",
    "                losses.append(step_loss)\n",
    "                num_loops += 1\n",
    "\n",
    "        return losses\n",
    "    \n",
    "    def save_results(self, losses, fname):\n",
    "        np.save(fname + \".npy\", losses)\n",
    "    \n",
    "    def save_model_state(self, fname):\n",
    "        pass\n",
    "    \n",
    "    def run(self, epochs):\n",
    "        print(\"Running experiment: \" + self.name + \"...\")\n",
    "        \n",
    "        # -------------------- Training -------------------------\n",
    "        \n",
    "        print(\"Training over \" + str(epochs) + \" epochs...\")\n",
    "                \n",
    "        for t in range(epochs):\n",
    "            print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "            epoch_losses = self.train_loop()\n",
    "            \n",
    "            fname = self.outdir + \"/train_epoch_\" + str(t)\n",
    "            self.save_results(epoch_losses, fname)\n",
    "            \n",
    "            epoch_mean = np.round(np.mean(epoch_losses), 5)\n",
    "            print(\"Mean:\", epoch_mean)\n",
    "            self.train_losses.append(epoch_mean)\n",
    "        \n",
    "        self.plot_loss(self.train_losses, \"Training Loss\", \"Epoch\", [\"train\"])\n",
    "        \n",
    "        # -------------------- Validation ------------------------\n",
    "        # -------------------- Testing ---------------------------\n",
    "    \n",
    "    # TODO: implement with the \"interesting\" examples found earlier\n",
    "    def visualize_examples(self):\n",
    "        pass\n",
    "    \n",
    "    def plot_loss(self, loss_to_plot, title, xlab, legend_items):\n",
    "        plt.plot(loss_to_plot)\n",
    "        plt.title(self.name + \" \" + title)\n",
    "        \n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.xlabel(xlab)\n",
    "        plt.legend(legend_items, loc=\"upper left\")\n",
    "    \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272c33ed",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14566a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600\n",
      "3552\n",
      "28800\n",
      "284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14930a300ac0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split = train_val_test_split_files(datadir(\"sst_npy/\"), [0.1, 0.1, 0.1]) # using small amount for now, to test\n",
    "\n",
    "train_split = split[0]\n",
    "val_split   = split[1]\n",
    "test_split  = split[2]\n",
    "\n",
    "# Total number of files in each split\n",
    "print(len(train_split))\n",
    "print(len(val_split))\n",
    "print(len(test_split))\n",
    "\n",
    "training_loader = create_dataloader(batchsize=12, files=train_split, ndays=4)\n",
    "#val_loader = create_dataloader(batchsize=12, files=val_split, ndays=4)\n",
    "\n",
    "# Total number of batches in the loader\n",
    "print(len(training_loader))\n",
    "\n",
    "train_first, train_next = next(iter(training_loader)) \n",
    "plt.imshow(train_first[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "539b084e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already ran experiments today.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(\"/projectnb/labci/Lucia/rainfall-pde-ml/experiments/\" + str(datetime.date.today()))\n",
    "except FileExistsError as e:\n",
    "    print(\"Already ran experiments today.\")\n",
    "finally:\n",
    "    path = \"/projectnb/labci/Lucia/rainfall-pde-ml/experiments/\" + str(datetime.date.today())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cbe793",
   "metadata": {},
   "source": [
    "### Training with MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dec38d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new directory to save model states and results: /projectnb/labci/Lucia/rainfall-pde-ml/experiments/2023-09-11_14:57:14/Bezenac_MSE_small_0\n",
      "Running experiment: Bezenac_MSE_small_0...\n",
      "Training over 3 epochs...\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(31.0899, grad_fn=<MseLossBackward0>)\n",
      "Step: 1 Loss: tensor(22.3373, grad_fn=<MseLossBackward0>)\n",
      "Step: 2 Loss: tensor(46.6428, grad_fn=<MseLossBackward0>)\n",
      "Step: 3 Loss: tensor(47.9047, grad_fn=<MseLossBackward0>)\n",
      "Step: 4 Loss: tensor(12.5814, grad_fn=<MseLossBackward0>)\n",
      "Step: 5 Loss: tensor(12.4826, grad_fn=<MseLossBackward0>)\n",
      "Step: 6 Loss: tensor(8.4481, grad_fn=<MseLossBackward0>)\n",
      "Step: 7 Loss: tensor(4.1078, grad_fn=<MseLossBackward0>)\n",
      "Step: 8 Loss: tensor(4.9656, grad_fn=<MseLossBackward0>)\n",
      "Step: 9 Loss: tensor(2.0769, grad_fn=<MseLossBackward0>)\n",
      "Step: 10 Loss: tensor(0.7177, grad_fn=<MseLossBackward0>)\n",
      "Step: 11 Loss: tensor(0.5258, grad_fn=<MseLossBackward0>)\n",
      "Step: 12 Loss: tensor(0.4037, grad_fn=<MseLossBackward0>)\n",
      "Step: 13 Loss: tensor(0.3604, grad_fn=<MseLossBackward0>)\n",
      "Step: 14 Loss: tensor(0.6979, grad_fn=<MseLossBackward0>)\n",
      "Step: 15 Loss: tensor(0.6398, grad_fn=<MseLossBackward0>)\n",
      "Step: 16 Loss: tensor(0.2698, grad_fn=<MseLossBackward0>)\n",
      "Step: 17 Loss: tensor(0.6001, grad_fn=<MseLossBackward0>)\n",
      "Step: 18 Loss: tensor(0.0850, grad_fn=<MseLossBackward0>)\n",
      "Step: 19 Loss: tensor(0.2051, grad_fn=<MseLossBackward0>)\n",
      "Step: 20 Loss: tensor(0.3124, grad_fn=<MseLossBackward0>)\n",
      "Step: 21 Loss: tensor(0.0940, grad_fn=<MseLossBackward0>)\n",
      "Step: 22 Loss: tensor(0.0885, grad_fn=<MseLossBackward0>)\n",
      "Step: 23 Loss: tensor(0.1667, grad_fn=<MseLossBackward0>)\n",
      "Step: 24 Loss: tensor(0.2628, grad_fn=<MseLossBackward0>)\n",
      "Step: 25 Loss: tensor(0.1134, grad_fn=<MseLossBackward0>)\n",
      "Step: 26 Loss: tensor(0.0733, grad_fn=<MseLossBackward0>)\n",
      "Step: 27 Loss: tensor(0.0924, grad_fn=<MseLossBackward0>)\n",
      "Step: 28 Loss: tensor(0.1647, grad_fn=<MseLossBackward0>)\n",
      "Step: 29 Loss: tensor(0.0450, grad_fn=<MseLossBackward0>)\n",
      "Step: 30 Loss: tensor(0.2665, grad_fn=<MseLossBackward0>)\n",
      "Step: 31 Loss: tensor(0.1158, grad_fn=<MseLossBackward0>)\n",
      "Step: 32 Loss: tensor(0.1928, grad_fn=<MseLossBackward0>)\n",
      "Step: 33 Loss: tensor(0.1248, grad_fn=<MseLossBackward0>)\n",
      "Step: 34 Loss: tensor(0.0610, grad_fn=<MseLossBackward0>)\n",
      "Step: 35 Loss: tensor(0.1136, grad_fn=<MseLossBackward0>)\n",
      "Step: 36 Loss: tensor(0.1801, grad_fn=<MseLossBackward0>)\n",
      "Step: 37 Loss: tensor(0.3169, grad_fn=<MseLossBackward0>)\n",
      "Step: 38 Loss: tensor(0.1079, grad_fn=<MseLossBackward0>)\n",
      "Step: 39 Loss: tensor(0.1003, grad_fn=<MseLossBackward0>)\n",
      "Step: 40 Loss: tensor(0.1875, grad_fn=<MseLossBackward0>)\n",
      "Step: 41 Loss: tensor(0.0596, grad_fn=<MseLossBackward0>)\n",
      "Step: 42 Loss: tensor(0.1527, grad_fn=<MseLossBackward0>)\n",
      "Step: 43 Loss: tensor(0.0840, grad_fn=<MseLossBackward0>)\n",
      "Step: 44 Loss: tensor(0.1777, grad_fn=<MseLossBackward0>)\n",
      "Step: 45 Loss: tensor(0.0740, grad_fn=<MseLossBackward0>)\n",
      "Step: 46 Loss: tensor(0.0771, grad_fn=<MseLossBackward0>)\n",
      "Step: 47 Loss: tensor(0.2299, grad_fn=<MseLossBackward0>)\n",
      "Step: 48 Loss: tensor(0.1404, grad_fn=<MseLossBackward0>)\n",
      "Step: 49 Loss: tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "Step: 50 Loss: tensor(0.1238, grad_fn=<MseLossBackward0>)\n",
      "Step: 51 Loss: tensor(0.3222, grad_fn=<MseLossBackward0>)\n",
      "Step: 52 Loss: tensor(0.1277, grad_fn=<MseLossBackward0>)\n",
      "Step: 53 Loss: tensor(0.1563, grad_fn=<MseLossBackward0>)\n",
      "Step: 54 Loss: tensor(0.1678, grad_fn=<MseLossBackward0>)\n",
      "Step: 55 Loss: tensor(1.2366, grad_fn=<MseLossBackward0>)\n",
      "Step: 56 Loss: tensor(0.1843, grad_fn=<MseLossBackward0>)\n",
      "Step: 57 Loss: tensor(0.2041, grad_fn=<MseLossBackward0>)\n",
      "Step: 58 Loss: tensor(0.0856, grad_fn=<MseLossBackward0>)\n",
      "Step: 59 Loss: tensor(0.0289, grad_fn=<MseLossBackward0>)\n",
      "Step: 60 Loss: tensor(0.4175, grad_fn=<MseLossBackward0>)\n",
      "Step: 61 Loss: tensor(2.4176, grad_fn=<MseLossBackward0>)\n",
      "Step: 62 Loss: tensor(0.1839, grad_fn=<MseLossBackward0>)\n",
      "Step: 63 Loss: tensor(0.6803, grad_fn=<MseLossBackward0>)\n",
      "Step: 64 Loss: tensor(0.1146, grad_fn=<MseLossBackward0>)\n",
      "Step: 65 Loss: tensor(0.1538, grad_fn=<MseLossBackward0>)\n",
      "Step: 66 Loss: tensor(0.0939, grad_fn=<MseLossBackward0>)\n",
      "Step: 67 Loss: tensor(0.1225, grad_fn=<MseLossBackward0>)\n",
      "Step: 68 Loss: tensor(0.2511, grad_fn=<MseLossBackward0>)\n",
      "Step: 69 Loss: tensor(0.4129, grad_fn=<MseLossBackward0>)\n",
      "Step: 70 Loss: tensor(1.9245, grad_fn=<MseLossBackward0>)\n",
      "Step: 71 Loss: tensor(1.2397, grad_fn=<MseLossBackward0>)\n",
      "Step: 72 Loss: tensor(0.1470, grad_fn=<MseLossBackward0>)\n",
      "Step: 73 Loss: tensor(0.6270, grad_fn=<MseLossBackward0>)\n",
      "Step: 78 Loss: tensor(0.1235, grad_fn=<MseLossBackward0>)\n",
      "Step: 79 Loss: tensor(0.0373, grad_fn=<MseLossBackward0>)\n",
      "Step: 80 Loss: tensor(0.1102, grad_fn=<MseLossBackward0>)\n",
      "Step: 81 Loss: tensor(0.1556, grad_fn=<MseLossBackward0>)\n",
      "Step: 82 Loss: tensor(0.0770, grad_fn=<MseLossBackward0>)\n",
      "Step: 83 Loss: tensor(0.0740, grad_fn=<MseLossBackward0>)\n",
      "Step: 84 Loss: tensor(0.0787, grad_fn=<MseLossBackward0>)\n",
      "Step: 85 Loss: tensor(0.1391, grad_fn=<MseLossBackward0>)\n",
      "Step: 86 Loss: tensor(0.1200, grad_fn=<MseLossBackward0>)\n",
      "Step: 87 Loss: tensor(0.0654, grad_fn=<MseLossBackward0>)\n",
      "Step: 88 Loss: tensor(0.0341, grad_fn=<MseLossBackward0>)\n",
      "Step: 89 Loss: tensor(0.1137, grad_fn=<MseLossBackward0>)\n",
      "Step: 90 Loss: tensor(0.1795, grad_fn=<MseLossBackward0>)\n",
      "Step: 91 Loss: tensor(0.9319, grad_fn=<MseLossBackward0>)\n",
      "Step: 92 Loss: tensor(0.0817, grad_fn=<MseLossBackward0>)\n",
      "Step: 93 Loss: tensor(0.1113, grad_fn=<MseLossBackward0>)\n",
      "Step: 94 Loss: tensor(0.1879, grad_fn=<MseLossBackward0>)\n",
      "Step: 95 Loss: tensor(0.1048, grad_fn=<MseLossBackward0>)\n",
      "Step: 96 Loss: tensor(0.0923, grad_fn=<MseLossBackward0>)\n",
      "Step: 97 Loss: tensor(0.0959, grad_fn=<MseLossBackward0>)\n",
      "Step: 98 Loss: tensor(0.0929, grad_fn=<MseLossBackward0>)\n",
      "Step: 99 Loss: tensor(0.0462, grad_fn=<MseLossBackward0>)\n",
      "Step: 100 Loss: tensor(0.0586, grad_fn=<MseLossBackward0>)\n",
      "Step: 101 Loss: tensor(0.0877, grad_fn=<MseLossBackward0>)\n",
      "Step: 102 Loss: tensor(0.1129, grad_fn=<MseLossBackward0>)\n",
      "Step: 103 Loss: tensor(0.0537, grad_fn=<MseLossBackward0>)\n",
      "Step: 104 Loss: tensor(0.0788, grad_fn=<MseLossBackward0>)\n",
      "Step: 105 Loss: tensor(0.0893, grad_fn=<MseLossBackward0>)\n",
      "Step: 106 Loss: tensor(0.1169, grad_fn=<MseLossBackward0>)\n",
      "Step: 107 Loss: tensor(0.1526, grad_fn=<MseLossBackward0>)\n",
      "Step: 108 Loss: tensor(0.0938, grad_fn=<MseLossBackward0>)\n",
      "Step: 109 Loss: tensor(0.0936, grad_fn=<MseLossBackward0>)\n",
      "Step: 110 Loss: tensor(0.1501, grad_fn=<MseLossBackward0>)\n",
      "Step: 111 Loss: tensor(0.0970, grad_fn=<MseLossBackward0>)\n",
      "Step: 112 Loss: tensor(0.0557, grad_fn=<MseLossBackward0>)\n",
      "Step: 113 Loss: tensor(0.0647, grad_fn=<MseLossBackward0>)\n",
      "Step: 114 Loss: tensor(0.0844, grad_fn=<MseLossBackward0>)\n",
      "Step: 115 Loss: tensor(0.0466, grad_fn=<MseLossBackward0>)\n",
      "Step: 116 Loss: tensor(0.0623, grad_fn=<MseLossBackward0>)\n",
      "Step: 117 Loss: tensor(0.0797, grad_fn=<MseLossBackward0>)\n",
      "Step: 118 Loss: tensor(0.1145, grad_fn=<MseLossBackward0>)\n",
      "Step: 119 Loss: tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "Step: 120 Loss: tensor(0.0411, grad_fn=<MseLossBackward0>)\n",
      "Step: 121 Loss: tensor(0.0510, grad_fn=<MseLossBackward0>)\n",
      "Step: 122 Loss: tensor(0.1177, grad_fn=<MseLossBackward0>)\n",
      "Step: 123 Loss: tensor(0.0506, grad_fn=<MseLossBackward0>)\n",
      "Step: 124 Loss: tensor(0.0746, grad_fn=<MseLossBackward0>)\n",
      "Step: 125 Loss: tensor(0.1768, grad_fn=<MseLossBackward0>)\n",
      "Step: 126 Loss: tensor(0.1041, grad_fn=<MseLossBackward0>)\n",
      "Step: 127 Loss: tensor(0.0505, grad_fn=<MseLossBackward0>)\n",
      "Step: 128 Loss: tensor(0.0383, grad_fn=<MseLossBackward0>)\n",
      "Step: 129 Loss: tensor(0.0728, grad_fn=<MseLossBackward0>)\n",
      "Step: 130 Loss: tensor(0.0418, grad_fn=<MseLossBackward0>)\n",
      "Step: 131 Loss: tensor(0.0370, grad_fn=<MseLossBackward0>)\n",
      "Step: 132 Loss: tensor(0.0505, grad_fn=<MseLossBackward0>)\n",
      "Step: 133 Loss: tensor(0.0552, grad_fn=<MseLossBackward0>)\n",
      "Step: 134 Loss: tensor(0.0657, grad_fn=<MseLossBackward0>)\n",
      "Step: 135 Loss: tensor(0.0379, grad_fn=<MseLossBackward0>)\n",
      "Step: 136 Loss: tensor(0.0333, grad_fn=<MseLossBackward0>)\n",
      "Step: 137 Loss: tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "Step: 138 Loss: tensor(0.0690, grad_fn=<MseLossBackward0>)\n",
      "Step: 139 Loss: tensor(0.0421, grad_fn=<MseLossBackward0>)\n",
      "Step: 140 Loss: tensor(0.0425, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 141 Loss: tensor(0.0364, grad_fn=<MseLossBackward0>)\n",
      "Step: 142 Loss: tensor(0.0662, grad_fn=<MseLossBackward0>)\n",
      "Step: 143 Loss: tensor(0.0671, grad_fn=<MseLossBackward0>)\n",
      "Step: 144 Loss: tensor(0.0525, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Testing the experiment class\n",
    "net = CDNN(hist=4)\n",
    "optim = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "exp0 = Experiment(name=\"Bezenac_MSE_small_0\",                           # de Bezenac model, trained on MSE Loss\n",
    "                  trainset=training_loader, valset=None, testset=None,  # data loaders\n",
    "                  model=net,                                            # model with 4 days of history\n",
    "                  loss_fn=nn.MSELoss(reduction=\"mean\"),                 # loss function for training\n",
    "                  test_loss=nn.MSELoss(reduction=\"mean\"),               # loss function for testing\n",
    "                  optimizer=optim,\n",
    "                  examples=None,\n",
    "                  outdir=path)\n",
    "\n",
    "exp0.run(epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a1ca72",
   "metadata": {},
   "source": [
    "### Training with Charbonnier Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f09f43a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new directory to save model states and results: /projectnb/labci/Lucia/rainfall-pde-ml/experiments/2023-09-11/Bezenac_CharbReg_small_0\n",
      "Running experiment: Bezenac_CharbReg_small_0...\n",
      "Training over 3 epochs...\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor([4283.4150], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 1 Loss: tensor([18535.5977], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 2 Loss: tensor([32810.0469], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 3 Loss: tensor([54330.5195], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 4 Loss: tensor([51993.6953], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 5 Loss: tensor([41465.6797], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 6 Loss: tensor([19591.7520], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 7 Loss: tensor([26476.5137], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 8 Loss: tensor([34781.7500], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 9 Loss: tensor([56982.0391], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 10 Loss: tensor([52529.4336], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 11 Loss: tensor([42294.0117], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 12 Loss: tensor([18974.8711], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 13 Loss: tensor([29696.6094], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 14 Loss: tensor([36882.2500], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 15 Loss: tensor([61260.3164], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 16 Loss: tensor([50790.7695], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 17 Loss: tensor([40685.6719], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 18 Loss: tensor([18292.8613], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 19 Loss: tensor([32974.7188], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 20 Loss: tensor([37351.4805], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 21 Loss: tensor([54616.2109], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 22 Loss: tensor([48231.4141], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 23 Loss: tensor([37959.5156], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 24 Loss: tensor([26615.4805], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 25 Loss: tensor([35839.0664], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 26 Loss: tensor([52230.9023], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 27 Loss: tensor([89122.5938], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 28 Loss: tensor([66736.1172], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 29 Loss: tensor([42365.8203], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 30 Loss: tensor([24492.5742], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 31 Loss: tensor([34672.7383], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 32 Loss: tensor([51644.2539], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 33 Loss: tensor([79660.7344], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 34 Loss: tensor([62843.7188], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 35 Loss: tensor([38144.7109], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 36 Loss: tensor([25795.4766], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 37 Loss: tensor([35993.9023], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 38 Loss: tensor([53565.6367], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 39 Loss: tensor([69957.9922], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 40 Loss: tensor([58404.7148], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 41 Loss: tensor([33688.1836], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 42 Loss: tensor([27323.9316], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 43 Loss: tensor([36194.2227], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 44 Loss: tensor([50123.7305], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 45 Loss: tensor([66252.7344], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 46 Loss: tensor([57086.1133], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 47 Loss: tensor([38226.0898], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 48 Loss: tensor([34549.9141], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 49 Loss: tensor([46124.3516], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 50 Loss: tensor([71693.5547], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 51 Loss: tensor([83899.1406], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 52 Loss: tensor([69203.0781], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 53 Loss: tensor([39443.1758], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 54 Loss: tensor([33100.4844], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 55 Loss: tensor([44170.2891], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 56 Loss: tensor([70150.], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 57 Loss: tensor([81786.5000], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 58 Loss: tensor([64284.1758], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 59 Loss: tensor([37267.0117], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 60 Loss: tensor([36719.3125], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 61 Loss: tensor([48298.8398], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 62 Loss: tensor([75345.5000], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 63 Loss: tensor([80051.7031], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 64 Loss: tensor([65573.6641], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 65 Loss: tensor([34797.5742], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 66 Loss: tensor([40865.3867], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 67 Loss: tensor([46812.1602], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 68 Loss: tensor([71745.3438], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 69 Loss: tensor([74963.7500], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 70 Loss: tensor([65252.4414], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 71 Loss: tensor([40037.3633], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 72 Loss: tensor([46823.6680], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 73 Loss: tensor([53272.7227], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 74 Loss: tensor([86435.7500], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 75 Loss: tensor([74523.5234], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 76 Loss: tensor([69164.9141], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 77 Loss: tensor([43983.2383], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 78 Loss: tensor([50217.8438], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 79 Loss: tensor([58681.0898], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 80 Loss: tensor([94039.1484], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 81 Loss: tensor([78474.1484], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 82 Loss: tensor([68944.0156], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 83 Loss: tensor([44211.7344], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 84 Loss: tensor([49982.4805], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 85 Loss: tensor([61592.1992], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 86 Loss: tensor([90235.5703], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 87 Loss: tensor([80324.1406], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 88 Loss: tensor([65782.0156], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 89 Loss: tensor([42091.9688], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 90 Loss: tensor([50737.9219], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 91 Loss: tensor([65831.1641], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 92 Loss: tensor([86518.0938], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 93 Loss: tensor([77906.4609], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 94 Loss: tensor([66940.9609], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 95 Loss: tensor([58224.1914], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 96 Loss: tensor([60257.0508], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 97 Loss: tensor([68284.6406], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 98 Loss: tensor([105964.0547], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 99 Loss: tensor([89792.5078], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 100 Loss: tensor([76276.7422], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 101 Loss: tensor([56883.8633], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 102 Loss: tensor([60210.6211], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 103 Loss: tensor([71293.7344], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 104 Loss: tensor([101777.7969], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 105 Loss: tensor([91368.5547], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 106 Loss: tensor([75387.1094], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 107 Loss: tensor([51820.4062], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 108 Loss: tensor([62910.1328], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 109 Loss: tensor([77538.0234], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 110 Loss: tensor([98348.4453], grad_fn=<Charbonnier_LossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 111 Loss: tensor([93215.9375], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 112 Loss: tensor([68477.3750], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 113 Loss: tensor([49399.8398], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 114 Loss: tensor([61666.1914], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 115 Loss: tensor([77646.6016], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 116 Loss: tensor([101612.4844], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 117 Loss: tensor([90548.6797], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 118 Loss: tensor([76170.7031], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 119 Loss: tensor([63221.2500], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 120 Loss: tensor([75483.0781], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 121 Loss: tensor([91178.8984], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 122 Loss: tensor([115631.4297], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 123 Loss: tensor([111107.6172], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 124 Loss: tensor([79459.2500], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 125 Loss: tensor([62205.4180], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 126 Loss: tensor([79995.6719], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 127 Loss: tensor([97317.2031], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 128 Loss: tensor([124659.4375], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 129 Loss: tensor([117646.5859], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 130 Loss: tensor([75356.7188], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 131 Loss: tensor([61274.7383], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 132 Loss: tensor([75300.8984], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 133 Loss: tensor([111993.8281], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 134 Loss: tensor([122265.], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 135 Loss: tensor([117910.0547], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 136 Loss: tensor([69853.9062], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 137 Loss: tensor([69117.3047], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 138 Loss: tensor([77465.1953], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 139 Loss: tensor([107877.1484], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 140 Loss: tensor([123176.0312], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 141 Loss: tensor([123962.1562], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 142 Loss: tensor([77170.3047], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 143 Loss: tensor([77190.2969], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 144 Loss: tensor([95381.8203], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 145 Loss: tensor([115708.1406], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 146 Loss: tensor([142140.9219], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 147 Loss: tensor([153155.3281], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 148 Loss: tensor([85887.2188], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 149 Loss: tensor([79515.9766], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 150 Loss: tensor([105982.4766], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 151 Loss: tensor([135524.0625], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 152 Loss: tensor([141518.5938], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 153 Loss: tensor([144407.5156], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 154 Loss: tensor([77106.2969], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 155 Loss: tensor([80192.9062], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 156 Loss: tensor([100916.4766], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 157 Loss: tensor([130265.3125], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 158 Loss: tensor([139573.4375], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 159 Loss: tensor([134563.7656], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 160 Loss: tensor([75874.2891], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 161 Loss: tensor([96118.3984], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 162 Loss: tensor([99476.6562], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 163 Loss: tensor([140706.4219], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 164 Loss: tensor([145677.6406], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 165 Loss: tensor([137404.1250], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 166 Loss: tensor([86617.1172], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 167 Loss: tensor([105140.3203], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 168 Loss: tensor([124161.9062], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 169 Loss: tensor([139009.6562], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 170 Loss: tensor([150665.1562], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 171 Loss: tensor([150246.6562], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 172 Loss: tensor([85070.5625], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 173 Loss: tensor([111685.7422], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 174 Loss: tensor([121815.2734], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 175 Loss: tensor([168709.6406], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 176 Loss: tensor([182678.2344], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 177 Loss: tensor([171622.9531], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 178 Loss: tensor([85612.8594], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 179 Loss: tensor([113117.5469], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 180 Loss: tensor([141529.1875], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 181 Loss: tensor([162940.1406], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 182 Loss: tensor([180364.0156], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 183 Loss: tensor([153004.1719], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 184 Loss: tensor([100230.5312], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 185 Loss: tensor([133261.6875], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 186 Loss: tensor([158326.9062], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 187 Loss: tensor([180329.1406], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 188 Loss: tensor([206871.1719], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 189 Loss: tensor([144892.4062], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 190 Loss: tensor([106236.7969], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 191 Loss: tensor([136886.4531], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 192 Loss: tensor([141146.9844], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 193 Loss: tensor([164672.1406], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 194 Loss: tensor([190638.6875], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 195 Loss: tensor([123920.7812], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 196 Loss: tensor([103285.3828], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 197 Loss: tensor([155123.0781], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 198 Loss: tensor([156083.7812], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 199 Loss: tensor([177061.0469], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 200 Loss: tensor([212193.1406], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 201 Loss: tensor([127961.8594], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 202 Loss: tensor([109592.0625], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 203 Loss: tensor([137426.4062], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 204 Loss: tensor([174375.5625], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 205 Loss: tensor([191361.2344], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 206 Loss: tensor([219022.3281], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 207 Loss: tensor([130127.0312], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 208 Loss: tensor([117184.0312], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 209 Loss: tensor([156791.2500], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 210 Loss: tensor([176607.7188], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 211 Loss: tensor([205694.4844], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 212 Loss: tensor([239698.2031], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 213 Loss: tensor([118365.5547], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 214 Loss: tensor([117756.0859], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 215 Loss: tensor([145369.1406], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 216 Loss: tensor([166461.5156], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 217 Loss: tensor([185681.3594], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 218 Loss: tensor([192571.1562], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 219 Loss: tensor([117967.7344], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 220 Loss: tensor([130412.4688], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 221 Loss: tensor([154884.6406], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 222 Loss: tensor([182055.4219], grad_fn=<Charbonnier_LossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 223 Loss: tensor([206578.0156], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 224 Loss: tensor([222310.4688], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 225 Loss: tensor([131160.2969], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 226 Loss: tensor([154034.3906], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 227 Loss: tensor([167185.8438], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 228 Loss: tensor([206601.1094], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 229 Loss: tensor([223477.1562], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 230 Loss: tensor([227657.7344], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 231 Loss: tensor([133452.1406], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 232 Loss: tensor([150255.7031], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 233 Loss: tensor([183127.6875], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 234 Loss: tensor([225887.5938], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 235 Loss: tensor([252835.], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 236 Loss: tensor([248967.6094], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 237 Loss: tensor([132118.1562], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 238 Loss: tensor([146984.1562], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 239 Loss: tensor([168757.8125], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 240 Loss: tensor([187388.0156], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 241 Loss: tensor([199409.8594], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 242 Loss: tensor([199790.8438], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 243 Loss: tensor([141685.5469], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 244 Loss: tensor([160062.6875], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 245 Loss: tensor([162629.4062], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 246 Loss: tensor([200433.2500], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 247 Loss: tensor([223223.3438], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 248 Loss: tensor([235277.7969], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 249 Loss: tensor([155101.8750], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 250 Loss: tensor([182646.1406], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 251 Loss: tensor([198754.7031], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 252 Loss: tensor([230031.2812], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 253 Loss: tensor([251095.3438], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 254 Loss: tensor([195798.6875], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 255 Loss: tensor([152598.0781], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 256 Loss: tensor([191947.3125], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 257 Loss: tensor([222846.4219], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 258 Loss: tensor([254569.2656], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 259 Loss: tensor([268497.5312], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 260 Loss: tensor([191933.7500], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 261 Loss: tensor([156072.6562], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 262 Loss: tensor([177561.8125], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 263 Loss: tensor([190738.0938], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 264 Loss: tensor([212476.0312], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 265 Loss: tensor([226431.3906], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 266 Loss: tensor([168241.5312], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 267 Loss: tensor([155457.6562], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 268 Loss: tensor([188627.1406], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 269 Loss: tensor([195948.6406], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 270 Loss: tensor([224636.0938], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 271 Loss: tensor([241769.3281], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 272 Loss: tensor([173550.2031], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 273 Loss: tensor([175408.6875], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 274 Loss: tensor([213686.5312], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 275 Loss: tensor([218881.0625], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 276 Loss: tensor([251409.7969], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 277 Loss: tensor([276249.4375], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 278 Loss: tensor([174227.3438], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 279 Loss: tensor([183069.3594], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 280 Loss: tensor([239232.0312], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 281 Loss: tensor([244565.0312], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 282 Loss: tensor([283908.2812], grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 283 Loss: tensor([293193.3750], grad_fn=<Charbonnier_LossBackward>)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 15\u001b[0m\n\u001b[1;32m      4\u001b[0m optim \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(net\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[1;32m      6\u001b[0m exp0 \u001b[38;5;241m=\u001b[39m Experiment(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBezenac_CharbReg_small_0\u001b[39m\u001b[38;5;124m\"\u001b[39m,                      \u001b[38;5;66;03m# de Bezenac model, trained on Regularized Charb Loss\u001b[39;00m\n\u001b[1;32m      7\u001b[0m                   trainset\u001b[38;5;241m=\u001b[39mtraining_loader, valset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, testset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# data loaders\u001b[39;00m\n\u001b[1;32m      8\u001b[0m                   model\u001b[38;5;241m=\u001b[39mnet,                                            \u001b[38;5;66;03m# model with 4 days of history\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m                   examples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m                   outdir\u001b[38;5;241m=\u001b[39mpath)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mexp0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 136\u001b[0m, in \u001b[0;36mExperiment.run\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m    133\u001b[0m fname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutdir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/train_epoch_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(t)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_results(epoch_losses, fname)\n\u001b[0;32m--> 136\u001b[0m epoch_mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(\u001b[43mepoch_losses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m(), \u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean:\u001b[39m\u001b[38;5;124m\"\u001b[39m, epoch_mean)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_losses\u001b[38;5;241m.\u001b[39mappend(epoch_mean)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'mean'"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "net = CDNN(hist=4)\n",
    "optim = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "exp0 = Experiment(name=\"Bezenac_CharbReg_small_0\",                      # de Bezenac model, trained on Regularized Charb Loss\n",
    "                  trainset=training_loader, valset=None, testset=None,  # data loaders\n",
    "                  model=net,                                            # model with 4 days of history\n",
    "                  loss_fn=Charbonnier_Loss.apply,                       # loss function for training\n",
    "                  test_loss=nn.MSELoss(reduction=\"mean\"),               # loss function for testing\n",
    "                  optimizer=optim,\n",
    "                  examples=None,\n",
    "                  outdir=path)\n",
    "\n",
    "exp0.run(epochs=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "218.182px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
