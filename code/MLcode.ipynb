{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e51c2d6",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports-and-setup-functions\" data-toc-modified-id=\"Imports-and-setup-functions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports and setup functions</a></span></li><li><span><a href=\"#DataLoader-Module\" data-toc-modified-id=\"DataLoader-Module-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>DataLoader Module</a></span><ul class=\"toc-item\"><li><span><a href=\"#Image-regions\" data-toc-modified-id=\"Image-regions-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Image regions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Find-interesting-regions-to-test-on\" data-toc-modified-id=\"Find-interesting-regions-to-test-on-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Find interesting regions to test on</a></span></li><li><span><a href=\"#Cut-all-data-into-64x64-regions\" data-toc-modified-id=\"Cut-all-data-into-64x64-regions-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Cut all data into 64x64 regions</a></span></li><li><span><a href=\"#Save-to-.npy-files\" data-toc-modified-id=\"Save-to-.npy-files-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Save to .npy files</a></span></li></ul></li><li><span><a href=\"#Train-val-test-split\" data-toc-modified-id=\"Train-val-test-split-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Train-val-test split</a></span></li><li><span><a href=\"#Inputs-and-ends\" data-toc-modified-id=\"Inputs-and-ends-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Inputs and ends</a></span></li><li><span><a href=\"#Tensors,-DataLoader\" data-toc-modified-id=\"Tensors,-DataLoader-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Tensors, DataLoader</a></span></li><li><span><a href=\"#Create-DataLoader-for-training-data\" data-toc-modified-id=\"Create-DataLoader-for-training-data-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Create DataLoader for training data</a></span></li></ul></li><li><span><a href=\"#Model-Module\" data-toc-modified-id=\"Model-Module-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Model Module</a></span><ul class=\"toc-item\"><li><span><a href=\"#AR1:-linear-mapping\" data-toc-modified-id=\"AR1:-linear-mapping-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>AR1: linear mapping</a></span></li><li><span><a href=\"#de-Bézenac-et-al,-2019:-CNN-with-warp-mapping\" data-toc-modified-id=\"de-Bézenac-et-al,-2019:-CNN-with-warp-mapping-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>de Bézenac et al, 2019: CNN with warp mapping</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loss-Function\" data-toc-modified-id=\"Loss-Function-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Loss Function</a></span></li><li><span><a href=\"#Warp\" data-toc-modified-id=\"Warp-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Warp</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Model</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-3.2.4\"><span class=\"toc-item-num\">3.2.4&nbsp;&nbsp;</span>Training</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb70983",
   "metadata": {},
   "source": [
    "# Imports and setup functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6754139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Function, Variable\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2088495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datadir(x):\n",
    "    return \"/projectnb/labci/Lucia/data/\" + x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f15e4f",
   "metadata": {},
   "source": [
    "# DataLoader Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a8f21d",
   "metadata": {},
   "source": [
    "## Train-val-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715c5887",
   "metadata": {},
   "source": [
    "The authors trained on SST data from 2006-2015 and tested on data from 2016-2017. For the IBI reanalysis SST data, we only have from June 5, 2021 to June 23, 2023 (749 days). From these, we will use 80% for training, 10% for validation, and 10% for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7d16162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_days(files):\n",
    "    \"\"\"Helper method to take a list of filenames and return total the number \n",
    "    of days represented by the files in the list. \n",
    "    \n",
    "    This method assumes a particular file naming convention that has been used \n",
    "    for this project. \n",
    "    \n",
    "    File naming convention: sst_geo_yyyymmdd.nc_region_XX.npy\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    files : list : data file names\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    delta : int : the number of days represented by the inputted files\n",
    "    \"\"\"\n",
    "    \n",
    "    files.sort()\n",
    "    \n",
    "    first = datetime.datetime.strptime(files[0][8:16], \"%Y%m%d\").date()\n",
    "    last = datetime.datetime.strptime(files[len(files)-1][8:16], \"%Y%m%d\").date()\n",
    "    \n",
    "    delta = int((last - first) / datetime.timedelta(days=1))\n",
    "    \n",
    "    return delta\n",
    "\n",
    "def train_val_test_cutoffs(topdir, split):\n",
    "    \"\"\"Helper method to create lists of filenames for the train, val, and test\n",
    "    data splits. Uses the dates in the filenames to determine file order and \n",
    "    split cutoffs.\n",
    "    \n",
    "    This method assumes a particular file naming convention that has been used \n",
    "    for this project. \n",
    "    \n",
    "    File naming convention: sst_geo_yyyymmdd.nc_region_XX.npy\n",
    "       \n",
    "    Parameters\n",
    "    ----------\n",
    "    topdir : string : the path to the directory holding the data\n",
    "    split : list : the fractions for each split, eg. [0.8, 0.1, 0.1]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    cutoffs : list : date cutoffs for each split\n",
    "    \"\"\"\n",
    "    \n",
    "    all_files = os.listdir(topdir)\n",
    "    all_files.sort()\n",
    "    nfiles = len(all_files)\n",
    "    ndays = all_days(all_files)\n",
    "    \n",
    "    start_date = datetime.datetime.strptime(all_files[0][8:16], \"%Y%m%d\").date()\n",
    "    end_date = datetime.datetime.strptime(all_files[nfiles-1][8:16], \"%Y%m%d\").date()\n",
    "    \n",
    "    cutoffs = []\n",
    "    \n",
    "    for i in range(3):\n",
    "        delta = math.floor(ndays*split[i])\n",
    "        end = start_date + datetime.timedelta(days=delta)\n",
    "        cutoffs.append(end)\n",
    "        \n",
    "        start_date = end\n",
    "        \n",
    "    # Because of rounding, some files may have been missed\n",
    "    # Add these to the test split\n",
    "    if cutoffs[2] < end_date:\n",
    "        cutoffs[2] = end_date\n",
    "    \n",
    "    return cutoffs\n",
    "\n",
    "def train_val_test_split_files(topdir, split):\n",
    "    \"\"\"Method to split the data in a directory into training, validation, and\n",
    "    test sets. Uses the helper method train_val_test_cutoffs().\n",
    "    \n",
    "    This method assumes a particular file naming convention that has been used \n",
    "    for this project. \n",
    "    \n",
    "    File naming convention: sst_geo_yyyymmdd.nc_region_XX.npy\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    topdir : string : the path to the directory holding the data\n",
    "    split : list : the fractions for each split, eg. [0.8, 0.1, 0.1]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    train : list : list of filenames for the train set\n",
    "    val : list : list of filenames for the validation set\n",
    "    test : list : list of filenames for the test set\n",
    "    \"\"\"\n",
    "    \n",
    "    assert len(split) == 3, \"Please include a % split for train, validation, and test sets.\"\n",
    "    \n",
    "    cutoffs = train_val_test_cutoffs(topdir, split)\n",
    "    \n",
    "    all_files = os.listdir(topdir)\n",
    "    all_files.sort()\n",
    "    \n",
    "    train, val, test = [], [], []\n",
    "    \n",
    "    for f in all_files:\n",
    "        file_date = datetime.datetime.strptime(f[8:16], \"%Y%m%d\").date()\n",
    "        \n",
    "        if file_date <= cutoffs[0]:\n",
    "            train.append(f)\n",
    "        elif (file_date > cutoffs[0]) & (file_date <= cutoffs[1]):\n",
    "            val.append(f)\n",
    "        else:\n",
    "            test.append(f)\n",
    "            \n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38bda7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_file(filename):\n",
    "    \"\"\"Helper method to load a single .npy file.\"\"\"\n",
    "    return np.load(datadir(\"sst_npy/\" + filename))\n",
    "\n",
    "\n",
    "def load_data_from_files(files):\n",
    "    \"\"\"Method to load data from a list of .npy files.\"\"\"\n",
    "    data = []\n",
    "    for f in files:\n",
    "        data.append(load_data_from_file(f))\n",
    "        \n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2117c9",
   "metadata": {},
   "source": [
    "## Inputs and ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5a6a4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_by_region(files, region):\n",
    "    \"\"\"Helper method to search a list of files for only those corresponding to\n",
    "    a desired region. \n",
    "    \n",
    "    This method assumes a particular file naming convention that has been used \n",
    "    for this project. \n",
    "    \n",
    "    File naming convention: sst_geo_yyyymmdd.nc_region_XX.npy\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    files : list : list of filenames in which to search\n",
    "    region : int : desired region\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    region_files : list : sorted list of matching files\n",
    "    \"\"\"\n",
    "    \n",
    "    region_files = []\n",
    "    for fname in files:\n",
    "        if \"region_\" + str(region) + \".npy\" in fname:\n",
    "            region_files.append(fname)\n",
    "            \n",
    "    region_files.sort()\n",
    "    \n",
    "    return region_files\n",
    "\n",
    "def get_pairs_by_region(files, region, ndays=1):\n",
    "    \"\"\"Method to separate data into inputs (X) and ends (y), for example to\n",
    "    use 4 previous days (ndays=4) to predict the next day. The \"pairs\" are \n",
    "    pairs of (X,y) inputs and ends. This method works on one region at a time.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    files : list : list of files from which to get pairs\n",
    "    region : int : desired region\n",
    "    ndays : int : number of days to use as inputs\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    inps : np.ndarray : filenames for inputs\n",
    "    ends : list : filenames for ends\n",
    "    \"\"\"\n",
    "    \n",
    "    region_files = search_by_region(files, region)\n",
    "    \n",
    "    n = len(region_files)\n",
    "    \n",
    "    inps = []\n",
    "    ends = region_files[ndays:]\n",
    "    \n",
    "    for i in range(n - ndays):\n",
    "        inps.append(region_files[i:i+ndays])\n",
    "    \n",
    "    return np.array(inps), np.array(ends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43858887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_regions(files):\n",
    "    \"\"\"Helper method to take a list of filenames and return a list of the \n",
    "    unique region numbers. \n",
    "    \n",
    "    This method assumes a particular file naming convention that has been used \n",
    "    for this project. \n",
    "    \n",
    "    File naming convention: sst_geo_yyyymmdd.nc_region_XX.npy\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    files : list : data file names\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    regions : list : list of unique region numbers in the directory\n",
    "    \"\"\"\n",
    "    \n",
    "    files.sort()\n",
    "    regions = []\n",
    "    \n",
    "    for f in files:\n",
    "        if \"region_\" in f:\n",
    "            \n",
    "            start_ind = f.find(\"region_\") + len(\"region_\")\n",
    "            end_ind = f.find(\".npy\")\n",
    "            \n",
    "            reg = f[start_ind:end_ind]\n",
    "            \n",
    "            if int(reg) not in regions:\n",
    "                regions.append(int(reg))\n",
    "            \n",
    "        else:\n",
    "            print(\"Files in this directory do not match the naming convention.\")\n",
    "    \n",
    "    regions.sort()\n",
    "    \n",
    "    return regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8510e497",
   "metadata": {},
   "source": [
    "## Tensors, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa7d662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(batchsize, files, ndays, dtype=torch.FloatTensor, shuff=True):\n",
    "    \"\"\"Method to create a PyTorch DataLoader object from a list of files and\n",
    "    additional parameters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dtype : torch.dtype : the data type for the DataLoader\n",
    "    batchsize : int : the desired batchsize for loading data\n",
    "    files : str : a list of files holding data to put into the DataLoader\n",
    "    ndays : int : the number of days to use as inputs to predict the next day\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    loader : torch.utils.data.DataLoader : the DataLoader object\n",
    "    \"\"\"\n",
    "    \n",
    "    regions = all_regions(files)\n",
    "\n",
    "    data = []\n",
    "    ends = []\n",
    "\n",
    "    for reg in regions:\n",
    "        reg_pairs = get_pairs_by_region(files, reg, ndays)\n",
    "        \n",
    "        for i in range(len(reg_pairs[0])):\n",
    "            dat = load_data_from_files(reg_pairs[0][i])\n",
    "            end = load_data_from_file(reg_pairs[1][i])\n",
    "        \n",
    "            data.append(dat)\n",
    "            ends.append(end)\n",
    "        \n",
    "    final_data = torch.from_numpy(np.array(data)).type(dtype)\n",
    "    final_ends = torch.from_numpy(np.array(ends)).type(dtype)\n",
    "    \n",
    "    loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(final_data, final_ends),\n",
    "                                           batch_size=batchsize, shuffle=shuff)\n",
    "    \n",
    "    return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06015e1",
   "metadata": {},
   "source": [
    "# Model Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ade1fba",
   "metadata": {},
   "source": [
    "## de Bézenac et al, 2019: CNN with warp mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e569ea",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2632738",
   "metadata": {},
   "source": [
    "The authors used a Charbonnier penality to measure the discrepancy between the predicted next image and the target: \n",
    "\n",
    "$\\rho(x) = (x + \\epsilon)^\\frac{1}{\\alpha}$\n",
    "\n",
    "Note that with $\\epsilon=0$ and $\\alpha=\\frac{1}{2}$, we recover the $\\textit{l}_2$ norm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc041ab",
   "metadata": {},
   "source": [
    "Additional penalty terms were added to the loss function, specifically to regulate the divergence of the displacement $\\omega$ between the prediction and the target, its magnitude, and its smoothness:\n",
    "\n",
    "$L_t = \\underset{x \\in \\Omega}\\Sigma \\rho(\\hat{I}_{t+1}(x) - I_{t+1}(x)) + \\lambda_{div}(\\nabla.\\omega_t(x))^2 + \\lambda_{magn}||\\omega_t(x)||^2 + \\lambda_{grad}||\\nabla \\omega_t(x)||^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29f28761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_regloss(F):\n",
    "    gradient = reduce(np.add, np.gradient(F))\n",
    "    \n",
    "    # TODO: try magnitude regularization in norm loss function\n",
    "    # could also move to inside model class\n",
    "    divergence = np.array([np.mean(gradient.sum(0)**2)])                         # 1st reg term above\n",
    "    magnitude  = np.array([np.mean(np.linalg.norm(F, axis=0, ord=2)**2)])        # 2nd reg term above\n",
    "    smoothness = np.array([np.mean(np.linalg.norm(gradient, axis=0, ord=2)**2)]) # 3rd reg term above\n",
    "    \n",
    "    return torch.from_numpy(divergence).type(torch.FloatTensor), torch.from_numpy(magnitude).type(torch.FloatTensor), torch.from_numpy(smoothness).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "741a61d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def charbonnier(x, alpha, eps):\n",
    "    \n",
    "    res = torch.mean(torch.pow(x + eps, (1. / alpha)))\n",
    "\n",
    "    return res\n",
    "\n",
    "def grad_charbonnier(x, alpha, eps):\n",
    "    \n",
    "    res = (1. / alpha)*torch.pow(x + eps, (1. / alpha) - 1)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "108d33db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Charbonnier_Loss(Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctl, y_pred, y, w, reg, alpha=0.5, eps=0):\n",
    "        ctl.save_for_backward(y_pred, y) # saves Tensor ctl for future call to backward()\n",
    "        \n",
    "        distsq = torch.pow(y_pred - y, 2)\n",
    "        charb_loss = charbonnier(distsq, alpha, eps)\n",
    "        \n",
    "        if reg:\n",
    "            lambda_div, lambda_magn, lambda_grad = 1, -0.1, 0.4\n",
    "            divergence, magnitude, smoothness = compute_regloss(w[0,:,:,:].numpy())\n",
    "            regulariz = lambda_div*divergence + lambda_magn*magnitude + lambda_grad*smoothness\n",
    "            charb_loss += regulariz[0]\n",
    "        \n",
    "        return charb_loss\n",
    "    \n",
    "    @staticmethod\n",
    "    # FIXME: with regularization constants, this is incomplete -> need grad(w) wrt x\n",
    "    def backward(ctl, alpha=0.5, eps=0):\n",
    "        y_pred, y = ctl.saved_tensors\n",
    "        distsq = torch.pow(y_pred - y, 2)\n",
    "\n",
    "        grad = grad_charbonnier(distsq, alpha, eps)\n",
    "        \n",
    "        return grad, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fe6c0aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_error_loss(y_pred, y): \n",
    "    error = torch.sum((y_pred - y)**2, axis=1)\n",
    "    loss = torch.mean(error)\n",
    "    return loss\n",
    "\n",
    "def charbonnier_loss(y_pred, y, alpha=0.5, epsilon=0):\n",
    "    error = torch.sum((y_pred - y)**2, axis=1)\n",
    "    loss = torch.mean(torch.pow(error + epsilon, (1. / alpha)))\n",
    "    return loss\n",
    "\n",
    "# TODO: add reg terms on W somehow (start with magnitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b406bf74",
   "metadata": {},
   "source": [
    "### Warp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e686d5",
   "metadata": {},
   "source": [
    "The future image is calculated based on a \"warp\" of the motion field estimate, $\\hat{\\omega}$, which can be thought of in this application as the wind vector field:\n",
    "\n",
    "$\\hat{I}_{t+1}(x) = \\underset{y \\in \\Omega} \\Sigma k(x - \\hat{\\omega}(x), y) I_t (y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5484aec7",
   "metadata": {},
   "source": [
    "where $k(u, v)$ is a radial basis function kernel, or equivalent a 2D Gaussian probability distribution:\n",
    "\n",
    "$k(x - \\hat{\\omega}(x), y) = \\frac{1}{4 \\pi D\\Delta t}e^{\\frac{-1}{4D \\Delta t} ||x - \\hat{\\omega}(x) - y||^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad59f08",
   "metadata": {},
   "source": [
    "for diffusion coefficient D and time step value $\\Delta t$ between $t$ and $t+1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "917ddf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel(distsq, D, dt):\n",
    "    \"\"\"Method to implement the k() function or radial basis function kernel \n",
    "    described above.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    distsq : float or torch.FloatTensor : the value of the squared norm of \n",
    "                 the distance\n",
    "    D : float : the diffusion coefficient\n",
    "    dt : float : the timestep\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    res : float or torch.FloatTensor: the result of the function\n",
    "    \"\"\"\n",
    "    \n",
    "    res = torch.exp(-distsq/(4*D*dt))/(4*np.pi*D*dt)\n",
    "    return res\n",
    "\n",
    "def kernel_gradient(self, dist, D, dt):\n",
    "    \"\"\"Method to implement the gradient of the k() function with respect to \n",
    "    the distance.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dist : float : the distance\n",
    "    D : float : the diffusion coefficient\n",
    "    dt : float : the timestep\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    res : float : the gradient of the function with respect to the distance\n",
    "    \"\"\"\n",
    "    \n",
    "    res = dist*torch.exp(-(dist**2).sum(1)/(4*D*dt))/(8*np.pi*D**2*dt**2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56d65cd",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b915e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(*models):\n",
    "    for model in models:\n",
    "        for module in model.modules():\n",
    "            \n",
    "            if isinstance(module, nn.Conv2d) or isinstance(module, nn.ConvTranspose2d) or isinstance(module, nn.Linear):\n",
    "                \n",
    "                # He initialization, from He, K. et al, 2015\n",
    "                nn.init.kaiming_normal_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    module.bias.data.zero_()\n",
    "                    \n",
    "            elif isinstance(module, nn.BatchNorm2d):\n",
    "                module.weight.data.fill_(1)\n",
    "                module.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71dfa15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(_EncoderBlock, self).__init__()\n",
    "        self.cv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.lr1 = nn.LeakyReLU(0.1)\n",
    "        self.cv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.lr2 = nn.LeakyReLU(0.1)\n",
    "        self.maxp = nn.MaxPool2d(kernel_size=3, stride=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual=x\n",
    "        #print(\"residual\",residual.shape)\n",
    "        out=self.cv1(x)\n",
    "        #print(\"cv1\",out.shape)\n",
    "        out=self.bn1(out)\n",
    "        #print(\"bn1\",out.shape)\n",
    "        out=self.lr1(out)\n",
    "        #print(\"lr1\",out.shape)\n",
    "        out+=residual\n",
    "        out=self.cv2(out)\n",
    "        out=self.bn2(out)\n",
    "        out=self.lr2(out)\n",
    "        out=self.maxp(out)\n",
    "        return out\n",
    "\n",
    "class _DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels):\n",
    "        super(_DecoderBlock, self).__init__()\n",
    "        self.cv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.lr1 = nn.LeakyReLU(0.1)\n",
    "        self.cv2 = nn.Conv2d(in_channels, middle_channels, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(middle_channels) \n",
    "        self.lr2 = nn.LeakyReLU(0.1)\n",
    "        self.tcv = nn.ConvTranspose2d(middle_channels, out_channels, kernel_size=3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual=x\n",
    "        #print(\"residual\",residual.shape)\n",
    "        out=self.cv1(x)\n",
    "        #print(\"cv1\",out.shape)\n",
    "        out=self.bn1(out)\n",
    "        #print(\"bn1\",out.shape)\n",
    "        out=self.lr1(out)\n",
    "        #print(\"lr1\",out.shape)\n",
    "        out+=residual\n",
    "        out=self.cv2(out)\n",
    "        out=self.bn2(out)\n",
    "        out=self.lr2(out)\n",
    "        out=self.tcv(out)\n",
    "        return out\n",
    "\n",
    "class _CenterBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(_CenterBlock, self).__init__()\n",
    "        self.cv1 = nn.Conv2d(in_channels,in_channels , kernel_size=3,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)  \n",
    "        self.lr1 = nn.LeakyReLU(0.1)\n",
    "        self.cv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels) \n",
    "        self.lr2 = nn.LeakyReLU(0.1)\n",
    "        self.tcv = nn.ConvTranspose2d(out_channels, out_channels, kernel_size=3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual=x\n",
    "        out=self.cv1(x)\n",
    "        out=self.bn1(out)\n",
    "        out=self.lr1(out)\n",
    "        out+=residual\n",
    "        out=self.cv2(out)\n",
    "        out=self.bn2(out)\n",
    "        out=self.lr2(out)\n",
    "        out=self.tcv(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0dc45117",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDNN(nn.Module):\n",
    "    \"\"\"Class to implement a physics-driven Convolution-Deconvolution Neural \n",
    "    Network (CDNN) as described in (de Bezenac et al, 2019). This model \n",
    "    takes as input historical image(s) of Sea Surface Temperature (SST)\n",
    "    data, X, and uses a convolutional neural network (CNN) to estimate the \n",
    "    wind vector field W that drives the motion of X. From there, the next \n",
    "    image is predicted using a \"warping\" of the most recent input image and W,\n",
    "    as if to see how the SST variable evolves with the wind. \n",
    "    \n",
    "    The \"warping\" in this paper is a radial basis function kernel, or a \n",
    "    Gaussian centered in X-W. Other models we will implement later may use a\n",
    "    different warping scheme. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hist=1):\n",
    "        \"\"\"Function to construct the model. \n",
    "           \n",
    "           Parameters\n",
    "           ----------\n",
    "           hist : int : the number of days of \"history\" to use for prediction, \n",
    "                        default = 1.\n",
    "        \"\"\"\n",
    "        \n",
    "        super(CDNN, self).__init__()\n",
    "        \n",
    "        self.enc1 = _EncoderBlock(hist, 64)  \n",
    "        self.enc2 = _EncoderBlock(64, 128)\n",
    "        self.enc3 = _EncoderBlock(128, 256)\n",
    "        self.enc4 = _EncoderBlock(256, 512)\n",
    "        self.dec4 = _CenterBlock(512, 386)\n",
    "        self.dec3 = _DecoderBlock(386+256, 256, 194)\n",
    "        self.dec2 = _DecoderBlock(194+128, 128, 98)\n",
    "        self.dec1 = _DecoderBlock(98+64, 64, 2)\n",
    "        \n",
    "        self.final = nn.Sequential(nn.Conv2d(2, 2, kernel_size=3),) \n",
    "        initialize_weights(self)\n",
    "\n",
    "        self.hist = hist\n",
    "\n",
    "    def wind(self, x):\n",
    "        \"\"\"Function to estimate the wind vector field from historical input images.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.FloatTensor : the historical input images\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        wind : torch.FloatTensor : the estimated wind vector field\n",
    "        \"\"\"\n",
    "        \n",
    "        enc1 = self.enc1(x)\n",
    "        #print(\"x\",x.shape)\n",
    "        #print(\"enc1\",enc1.shape)\n",
    "        enc2 = self.enc2(enc1)\n",
    "        #print(\"enc2\",enc2.shape)\n",
    "        enc3 = self.enc3(enc2)\n",
    "        #print(\"enc3\",enc3.shape)\n",
    "        enc4 = self.enc4(enc3)\n",
    "        #print(\"enc4\",enc4.shape)\n",
    "        dec4 = self.dec4(enc4)\n",
    "        #print(\"dec4\",dec4.shape)\n",
    "        \n",
    "        dec3 = self.dec3(torch.cat([dec4, F.interpolate(enc3, dec4.size()[2:], mode='bilinear')], 1))\n",
    "        dec2 = self.dec2(torch.cat([dec3, F.interpolate(enc2, dec3.size()[2:], mode='bilinear')], 1))\n",
    "        dec1 = self.dec1(torch.cat([dec2, F.interpolate(enc1, dec2.size()[2:], mode='bilinear')], 1))\n",
    "        final = self.final(dec1)\n",
    "        \n",
    "        wind = F.interpolate(final, x.size()[2:], mode='bilinear')\n",
    "\n",
    "        return wind\n",
    "    \n",
    "    @staticmethod\n",
    "    def warp(I, W, hist):\n",
    "        \"\"\"Function to compute the warping of the input data and an estimated \n",
    "        wind vector field, in order to produce an output predicted image. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        I : torch.FloatTensor : the most recent input image to warp\n",
    "        W : torch.FloatTensor : the estimated wind vector field\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        warped : torch.FloatTensor : the warped prediction image\n",
    "        \"\"\"\n",
    "        \n",
    "        D = 0.45\n",
    "        dt = 1\n",
    "        \n",
    "        interval=torch.arange(I.size()[-1]).type(torch.FloatTensor)\n",
    "        \n",
    "        x1 = interval[None,:,None,None,None]\n",
    "        x2 = interval[None,None,:,None,None]\n",
    "        y1 = interval[None,None,None,:,None]\n",
    "        y2 = interval[None,None,None,None,:]\n",
    "        \n",
    "        # x - wind - y\n",
    "        distsq = (x1-y1-W[:,0,:,:,None,None])**2+(x2-y2-W[:,1,:,:,None,None])**2         \n",
    "        mult = I[:, hist-1, None,None,:,:] * kernel(distsq, D, dt)\n",
    "        warped = mult.sum(4).sum(3)\n",
    "        \n",
    "        return warped\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Function to execute the forward pass of the model. All of the \n",
    "        computations are done in the methods above, so this function \n",
    "        simply returns their outputs.\n",
    "        \n",
    "        Note: the wind vector field W is returned for use in the \n",
    "        regularized loss function later. For simple difference loss \n",
    "        functions, returning y_pred is sufficient. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.FloatTensor : the historical input images\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        W : torch.FloatTensor : the estimated wind vector field\n",
    "        y_pred : torch.FloatTensor : the predicted next image\n",
    "        \"\"\"\n",
    "        \n",
    "        W = self.wind(x)\n",
    "        y_pred = self.warp(x, W, self.hist) \n",
    "        \n",
    "        return W, y_pred "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd072838",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6550149",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566d181e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment():\n",
    "    \n",
    "    def __init__(self, name, trainset, valset, testset, model, loss_fn, regloss, test_loss, optimizer, examples, outdir):\n",
    "        self.name = name\n",
    "        self.train_loader = trainset \n",
    "        self.val_loader = valset\n",
    "        self.test_loader = testset\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.regloss = regloss\n",
    "        self.test_loss = test_loss\n",
    "        self.optimizer = optimizer\n",
    "        self.examples = examples\n",
    "        \n",
    "        self.train_losses = []\n",
    "        self.valid_losses = []\n",
    "        self.test_losses  = []\n",
    "        \n",
    "        # Set up a directory for the experiment\n",
    "        self.dir_setup(outdir)\n",
    "        \n",
    "    def dir_setup(self, parent):\n",
    "        self.outdir = parent + \"/\" + self.name\n",
    "        os.mkdir(self.outdir)\n",
    "        print(\"Created new directory to save model states and results: \" + self.outdir)\n",
    "    \n",
    "    def train_loop(self):\n",
    "        size = len(self.train_loader.dataset)\n",
    "        # Set the model to training mode - important for batch normalization and dropout layers\n",
    "        # Unnecessary in this situation but added for best practices\n",
    "        self.model.train()\n",
    "    \n",
    "        losses = []\n",
    "    \n",
    "        for batch, (X, y) in enumerate(self.train_loader):\n",
    "            # Compute prediction and loss\n",
    "            #X = X.to(device) \n",
    "            #y = y.to(device)\n",
    "            outputs = self.model(X)\n",
    "            wind = outputs[0]\n",
    "            y_pred = outputs[1]\n",
    "            \n",
    "            if \"MSE\" or \"Err\" in self.name:\n",
    "                loss = self.loss_fn(y_pred, y)\n",
    "            else:\n",
    "                loss = self.loss_fn(y_pred, y, wind, self.regloss)\n",
    "                \n",
    "            losses.append(loss.item())\n",
    "        \n",
    "            print(\"Step:\", batch, \"Loss:\", loss)\n",
    "        \n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "        \n",
    "        return losses\n",
    "    \n",
    "    # TODO: implement cross-validation?\n",
    "    # example: https://saturncloud.io/blog/how-to-use-kfold-cross-validation-with-dataloaders-in-pytorch/\n",
    "    def val_loop(self):\n",
    "        # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "        # Unnecessary in this situation but added for best practices\n",
    "        self.model.eval()\n",
    "        losses = []\n",
    "        num_loops = 0\n",
    "\n",
    "        # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "        # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "        with torch.no_grad():\n",
    "            for X, y in self.val_loader:\n",
    "                #X = X.to(device) \n",
    "                #y = y.to(device)\n",
    "                outputs = self.model(X)\n",
    "                y_pred = outputs[1]\n",
    "            \n",
    "                step_loss = self.loss_fn(y_pred, y).item()\n",
    "                print(\"Item:\", num_loops, \"Loss:\", step_loss)\n",
    "                losses.append(step_loss)\n",
    "                num_loops += 1\n",
    "\n",
    "        return losses\n",
    "    \n",
    "    def test(self):\n",
    "        # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "        # Unnecessary in this situation but added for best practices\n",
    "        self.model.eval()\n",
    "        losses = []\n",
    "        num_loops = 0\n",
    "\n",
    "        # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "        # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "        with torch.no_grad():\n",
    "            for X, y in self.test_loader:\n",
    "                #X = X.to(device) \n",
    "                #y = y.to(device)\n",
    "                outputs = self.model(X)\n",
    "                y_pred = outputs[1]\n",
    "            \n",
    "                step_loss = self.test_loss(y_pred, y).item()\n",
    "                print(\"Item:\", num_loops, \"Loss:\", step_loss)\n",
    "                losses.append(step_loss)\n",
    "                num_loops += 1\n",
    "\n",
    "        return losses\n",
    "    \n",
    "    def save_results(self, losses, fname):\n",
    "        np.save(fname + \".npy\", losses)\n",
    "    \n",
    "    def save_model_state(self, epoch):\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'loss': self.train_losses,\n",
    "            }, self.outdir)\n",
    "        \n",
    "        print(\"Saved checkpoint at epoch\", epoch)\n",
    "    \n",
    "    def run(self, epochs):\n",
    "        print(\"Running experiment: \" + self.name + \"...\")\n",
    "        \n",
    "        # -------------------- Training -------------------------\n",
    "        \n",
    "        print(\"Training over \" + str(epochs) + \" epochs...\")\n",
    "                \n",
    "        for t in range(epochs):\n",
    "            print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "            \n",
    "            start = datetime.now()\n",
    "            epoch_losses = self.train_loop()\n",
    "            \n",
    "            fname = self.outdir + \"/train_epoch_\" + str(t)\n",
    "            self.save_results(epoch_losses, fname)\n",
    "            \n",
    "            epoch_mean = np.round(np.mean(epoch_losses), 5)\n",
    "            \n",
    "            print(\"Mean:\", epoch_mean)\n",
    "            print(\"Runtime:\", datetime.now() - start)\n",
    "            \n",
    "            self.train_losses.append(epoch_mean)\n",
    "            \n",
    "            if t % 100 == 0:\n",
    "                self.save_model_state(t)\n",
    "        \n",
    "        self.plot_loss(self.train_losses, \"Training Loss\", \"Epoch\", [\"train\"])\n",
    "        \n",
    "        # -------------------- Validation ------------------------\n",
    "        # -------------------- Testing ---------------------------\n",
    "    \n",
    "    # TODO: implement with the \"interesting\" examples found earlier\n",
    "    def visualize_examples(self):\n",
    "        # \"Interesting\" regions were 3, 22, 29, 44 -> each 64x64\n",
    "        # Need to figure out where each region went in the DataLoader & how to index them\n",
    "        # Or, what if we don't need them to be in the DataLoader? Just load the arr.s & input thru constructor?\n",
    "        pass\n",
    "    \n",
    "    def plot_loss(self, loss_to_plot, title, xlab, legend_items):\n",
    "        plt.plot(loss_to_plot)\n",
    "        plt.title(self.name + \" \" + title)\n",
    "        \n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.xlabel(xlab)\n",
    "        plt.legend(legend_items, loc=\"upper left\")\n",
    "    \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272c33ed",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14566a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720\n",
      "3552\n",
      "31680\n",
      "44\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14cdea474df0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "split = train_val_test_split_files(datadir(\"sst_npy/\"), [0.02, 0.1, 0.1]) # using small amount for now, to test\n",
    "\n",
    "train_split = split[0]\n",
    "val_split   = split[1]\n",
    "test_split  = split[2]\n",
    "\n",
    "# Total number of files in each split\n",
    "print(len(train_split))\n",
    "print(len(val_split))\n",
    "print(len(test_split))\n",
    "\n",
    "# For faster training, try larger batchsize\n",
    "training_loader = create_dataloader(batchsize=12, files=train_split, ndays=4, shuff=True)\n",
    "#val_loader = create_dataloader(batchsize=12, files=val_split, ndays=4, shuff=True)\n",
    "\n",
    "# Total number of batches in the loader\n",
    "print(len(training_loader))\n",
    "\n",
    "train_first, train_next = next(iter(training_loader)) \n",
    "plt.imshow(train_first[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "539b084e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(\"/projectnb/labci/Lucia/rainfall-pde-ml/experiments/\" + str(datetime.date.today()))\n",
    "except FileExistsError as e:\n",
    "    print(\"Already ran experiments today.\")\n",
    "finally:\n",
    "    path = \"/projectnb/labci/Lucia/rainfall-pde-ml/experiments/\" + str(datetime.date.today())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cbe793",
   "metadata": {},
   "source": [
    "### Training with MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dec38d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new directory to save model states and results: /projectnb/labci/Lucia/rainfall-pde-ml/experiments/2023-09-15/Bezenac_MSE_small_3\n",
      "Running experiment: Bezenac_MSE_small_3...\n",
      "Training over 5 epochs...\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(71.3972, grad_fn=<MseLossBackward0>)\n",
      "Step: 1 Loss: tensor(109.3598, grad_fn=<MseLossBackward0>)\n",
      "Step: 2 Loss: tensor(39.6824, grad_fn=<MseLossBackward0>)\n",
      "Step: 3 Loss: tensor(56.3631, grad_fn=<MseLossBackward0>)\n",
      "Step: 4 Loss: tensor(60.0565, grad_fn=<MseLossBackward0>)\n",
      "Step: 5 Loss: tensor(36.2472, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "net0 = CDNN(hist=4)\n",
    "optim = torch.optim.Adam(net0.parameters(), lr=1e-3)\n",
    "\n",
    "exp0 = Experiment(name=\"Bezenac_MSE_small_3\",                           # de Bezenac model, trained on MSE Loss\n",
    "                  trainset=training_loader, valset=None, testset=None,  # data loaders\n",
    "                  model=net0,                                           # model with 4 days of history\n",
    "                  loss_fn=nn.MSELoss(reduction=\"mean\"),                 # loss function for training\n",
    "                  regloss=False,                                        # whether to regularize the training loss  \n",
    "                  test_loss=nn.MSELoss(reduction=\"mean\"),               # loss function for testing\n",
    "                  optimizer=optim,\n",
    "                  examples=None,\n",
    "                  outdir=path)\n",
    "\n",
    "exp0.run(epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beab998",
   "metadata": {},
   "source": [
    "### Training with (Unregularized) Charbonnier Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "858610d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new directory to save model states and results: /projectnb/labci/Lucia/rainfall-pde-ml/experiments/2023-09-15/Bezenac_Charb_small_3\n",
      "Running experiment: Bezenac_Charb_small_3...\n",
      "Training over 5 epochs...\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(18999658., grad_fn=<MeanBackward0>)\n",
      "Step: 1 Loss: tensor(69332480., grad_fn=<MeanBackward0>)\n",
      "Step: 2 Loss: tensor(30322246., grad_fn=<MeanBackward0>)\n",
      "Step: 3 Loss: tensor(19650786., grad_fn=<MeanBackward0>)\n",
      "Step: 4 Loss: tensor(23429334., grad_fn=<MeanBackward0>)\n",
      "Step: 5 Loss: tensor(6356429.5000, grad_fn=<MeanBackward0>)\n",
      "Step: 6 Loss: tensor(17030198., grad_fn=<MeanBackward0>)\n",
      "Step: 7 Loss: tensor(2062093.5000, grad_fn=<MeanBackward0>)\n",
      "Step: 8 Loss: tensor(3158114.7500, grad_fn=<MeanBackward0>)\n",
      "Step: 9 Loss: tensor(1782738.8750, grad_fn=<MeanBackward0>)\n",
      "Step: 10 Loss: tensor(941032.1875, grad_fn=<MeanBackward0>)\n",
      "Step: 11 Loss: tensor(464825.0938, grad_fn=<MeanBackward0>)\n",
      "Step: 12 Loss: tensor(1899194., grad_fn=<MeanBackward0>)\n",
      "Step: 13 Loss: tensor(794010.4375, grad_fn=<MeanBackward0>)\n",
      "Step: 14 Loss: tensor(133711.2969, grad_fn=<MeanBackward0>)\n",
      "Step: 15 Loss: tensor(198392.7500, grad_fn=<MeanBackward0>)\n",
      "Step: 16 Loss: tensor(786341.7500, grad_fn=<MeanBackward0>)\n",
      "Step: 17 Loss: tensor(122468.7500, grad_fn=<MeanBackward0>)\n",
      "Step: 18 Loss: tensor(108619.8750, grad_fn=<MeanBackward0>)\n",
      "Step: 19 Loss: tensor(121458.2266, grad_fn=<MeanBackward0>)\n",
      "Step: 20 Loss: tensor(25420.1738, grad_fn=<MeanBackward0>)\n",
      "Step: 21 Loss: tensor(19359.6562, grad_fn=<MeanBackward0>)\n",
      "Step: 22 Loss: tensor(44792.7227, grad_fn=<MeanBackward0>)\n",
      "Step: 23 Loss: tensor(15348.8164, grad_fn=<MeanBackward0>)\n",
      "Step: 24 Loss: tensor(31842.2578, grad_fn=<MeanBackward0>)\n",
      "Step: 25 Loss: tensor(15863.8154, grad_fn=<MeanBackward0>)\n",
      "Step: 26 Loss: tensor(381939.8438, grad_fn=<MeanBackward0>)\n",
      "Step: 27 Loss: tensor(12168.2461, grad_fn=<MeanBackward0>)\n",
      "Step: 28 Loss: tensor(11657.0303, grad_fn=<MeanBackward0>)\n",
      "Step: 29 Loss: tensor(9091.9658, grad_fn=<MeanBackward0>)\n",
      "Step: 30 Loss: tensor(21531.7285, grad_fn=<MeanBackward0>)\n",
      "Step: 31 Loss: tensor(33084.5039, grad_fn=<MeanBackward0>)\n",
      "Step: 32 Loss: tensor(19796.7637, grad_fn=<MeanBackward0>)\n",
      "Step: 33 Loss: tensor(4435.0474, grad_fn=<MeanBackward0>)\n",
      "Step: 34 Loss: tensor(12349.2471, grad_fn=<MeanBackward0>)\n",
      "Step: 35 Loss: tensor(4575.4663, grad_fn=<MeanBackward0>)\n",
      "Step: 36 Loss: tensor(15992.8994, grad_fn=<MeanBackward0>)\n",
      "Step: 37 Loss: tensor(11640.4014, grad_fn=<MeanBackward0>)\n",
      "Step: 38 Loss: tensor(8902.2705, grad_fn=<MeanBackward0>)\n",
      "Step: 39 Loss: tensor(4447.1572, grad_fn=<MeanBackward0>)\n",
      "Step: 40 Loss: tensor(5850.0430, grad_fn=<MeanBackward0>)\n",
      "Step: 41 Loss: tensor(4693.6558, grad_fn=<MeanBackward0>)\n",
      "Step: 42 Loss: tensor(3926.8713, grad_fn=<MeanBackward0>)\n",
      "Step: 43 Loss: tensor(3842.3232, grad_fn=<MeanBackward0>)\n",
      "Mean: 4509470.13407\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(8490.2373, grad_fn=<MeanBackward0>)\n",
      "Step: 1 Loss: tensor(2630.4619, grad_fn=<MeanBackward0>)\n",
      "Step: 2 Loss: tensor(3628.1609, grad_fn=<MeanBackward0>)\n",
      "Step: 3 Loss: tensor(4270.6167, grad_fn=<MeanBackward0>)\n",
      "Step: 4 Loss: tensor(5831.4907, grad_fn=<MeanBackward0>)\n",
      "Step: 5 Loss: tensor(7056.4507, grad_fn=<MeanBackward0>)\n",
      "Step: 6 Loss: tensor(2958.9304, grad_fn=<MeanBackward0>)\n",
      "Step: 7 Loss: tensor(4023.6570, grad_fn=<MeanBackward0>)\n",
      "Step: 8 Loss: tensor(2935.2080, grad_fn=<MeanBackward0>)\n",
      "Step: 9 Loss: tensor(2544.2856, grad_fn=<MeanBackward0>)\n",
      "Step: 10 Loss: tensor(10219.6699, grad_fn=<MeanBackward0>)\n",
      "Step: 11 Loss: tensor(1881.4408, grad_fn=<MeanBackward0>)\n",
      "Step: 12 Loss: tensor(2746.9990, grad_fn=<MeanBackward0>)\n",
      "Step: 13 Loss: tensor(3516.3630, grad_fn=<MeanBackward0>)\n",
      "Step: 14 Loss: tensor(3828.0808, grad_fn=<MeanBackward0>)\n",
      "Step: 15 Loss: tensor(1508.9156, grad_fn=<MeanBackward0>)\n",
      "Step: 16 Loss: tensor(1965.8301, grad_fn=<MeanBackward0>)\n",
      "Step: 17 Loss: tensor(3458.2607, grad_fn=<MeanBackward0>)\n",
      "Step: 18 Loss: tensor(2680.2983, grad_fn=<MeanBackward0>)\n",
      "Step: 19 Loss: tensor(741.3386, grad_fn=<MeanBackward0>)\n",
      "Step: 20 Loss: tensor(1948.0781, grad_fn=<MeanBackward0>)\n",
      "Step: 21 Loss: tensor(4300.7490, grad_fn=<MeanBackward0>)\n",
      "Step: 22 Loss: tensor(3389.0752, grad_fn=<MeanBackward0>)\n",
      "Step: 23 Loss: tensor(6383.9414, grad_fn=<MeanBackward0>)\n",
      "Step: 24 Loss: tensor(16037.8096, grad_fn=<MeanBackward0>)\n",
      "Step: 25 Loss: tensor(4061.7273, grad_fn=<MeanBackward0>)\n",
      "Step: 26 Loss: tensor(4889.5684, grad_fn=<MeanBackward0>)\n",
      "Step: 27 Loss: tensor(2182.7961, grad_fn=<MeanBackward0>)\n",
      "Step: 28 Loss: tensor(3637.4102, grad_fn=<MeanBackward0>)\n",
      "Step: 29 Loss: tensor(1298.3373, grad_fn=<MeanBackward0>)\n",
      "Step: 30 Loss: tensor(3567.5840, grad_fn=<MeanBackward0>)\n",
      "Step: 31 Loss: tensor(1831.3246, grad_fn=<MeanBackward0>)\n",
      "Step: 32 Loss: tensor(3095.0811, grad_fn=<MeanBackward0>)\n",
      "Step: 33 Loss: tensor(1297.3842, grad_fn=<MeanBackward0>)\n",
      "Step: 34 Loss: tensor(1341.3975, grad_fn=<MeanBackward0>)\n",
      "Step: 35 Loss: tensor(1451.0104, grad_fn=<MeanBackward0>)\n",
      "Step: 36 Loss: tensor(2012.8008, grad_fn=<MeanBackward0>)\n",
      "Step: 37 Loss: tensor(1328.2373, grad_fn=<MeanBackward0>)\n",
      "Step: 38 Loss: tensor(1381.8970, grad_fn=<MeanBackward0>)\n",
      "Step: 39 Loss: tensor(1542.2538, grad_fn=<MeanBackward0>)\n",
      "Step: 40 Loss: tensor(707.5552, grad_fn=<MeanBackward0>)\n",
      "Step: 41 Loss: tensor(2085.7532, grad_fn=<MeanBackward0>)\n",
      "Step: 42 Loss: tensor(1136.5665, grad_fn=<MeanBackward0>)\n",
      "Step: 43 Loss: tensor(1053.8439, grad_fn=<MeanBackward0>)\n",
      "Mean: 3383.61086\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(1293.8690, grad_fn=<MeanBackward0>)\n",
      "Step: 1 Loss: tensor(1961.3707, grad_fn=<MeanBackward0>)\n",
      "Step: 2 Loss: tensor(4009.7178, grad_fn=<MeanBackward0>)\n",
      "Step: 3 Loss: tensor(1448.5933, grad_fn=<MeanBackward0>)\n",
      "Step: 4 Loss: tensor(641.8228, grad_fn=<MeanBackward0>)\n",
      "Step: 5 Loss: tensor(2091.5544, grad_fn=<MeanBackward0>)\n",
      "Step: 6 Loss: tensor(1580.4183, grad_fn=<MeanBackward0>)\n",
      "Step: 7 Loss: tensor(924.8819, grad_fn=<MeanBackward0>)\n",
      "Step: 8 Loss: tensor(826.9891, grad_fn=<MeanBackward0>)\n",
      "Step: 9 Loss: tensor(736.5206, grad_fn=<MeanBackward0>)\n",
      "Step: 10 Loss: tensor(1609.3444, grad_fn=<MeanBackward0>)\n",
      "Step: 11 Loss: tensor(2080.9814, grad_fn=<MeanBackward0>)\n",
      "Step: 12 Loss: tensor(1766.8707, grad_fn=<MeanBackward0>)\n",
      "Step: 13 Loss: tensor(1121.3453, grad_fn=<MeanBackward0>)\n",
      "Step: 14 Loss: tensor(1161.1122, grad_fn=<MeanBackward0>)\n",
      "Step: 15 Loss: tensor(2391.3850, grad_fn=<MeanBackward0>)\n",
      "Step: 16 Loss: tensor(2478.9426, grad_fn=<MeanBackward0>)\n",
      "Step: 17 Loss: tensor(1254.5316, grad_fn=<MeanBackward0>)\n",
      "Step: 18 Loss: tensor(2217.5298, grad_fn=<MeanBackward0>)\n",
      "Step: 19 Loss: tensor(1067.6985, grad_fn=<MeanBackward0>)\n",
      "Step: 20 Loss: tensor(1390.6696, grad_fn=<MeanBackward0>)\n",
      "Step: 21 Loss: tensor(2145.5549, grad_fn=<MeanBackward0>)\n",
      "Step: 22 Loss: tensor(730.7078, grad_fn=<MeanBackward0>)\n",
      "Step: 23 Loss: tensor(832.9511, grad_fn=<MeanBackward0>)\n",
      "Step: 24 Loss: tensor(1641.7191, grad_fn=<MeanBackward0>)\n",
      "Step: 25 Loss: tensor(1042.7168, grad_fn=<MeanBackward0>)\n",
      "Step: 26 Loss: tensor(733.7786, grad_fn=<MeanBackward0>)\n",
      "Step: 27 Loss: tensor(1082.0162, grad_fn=<MeanBackward0>)\n",
      "Step: 28 Loss: tensor(1316.7340, grad_fn=<MeanBackward0>)\n",
      "Step: 29 Loss: tensor(1631.9116, grad_fn=<MeanBackward0>)\n",
      "Step: 30 Loss: tensor(1000.4592, grad_fn=<MeanBackward0>)\n",
      "Step: 31 Loss: tensor(927.2758, grad_fn=<MeanBackward0>)\n",
      "Step: 32 Loss: tensor(641.7432, grad_fn=<MeanBackward0>)\n",
      "Step: 33 Loss: tensor(1331.9147, grad_fn=<MeanBackward0>)\n",
      "Step: 34 Loss: tensor(1271.2133, grad_fn=<MeanBackward0>)\n",
      "Step: 35 Loss: tensor(1569.7174, grad_fn=<MeanBackward0>)\n",
      "Step: 36 Loss: tensor(870.4200, grad_fn=<MeanBackward0>)\n",
      "Step: 37 Loss: tensor(621.5682, grad_fn=<MeanBackward0>)\n",
      "Step: 38 Loss: tensor(877.8511, grad_fn=<MeanBackward0>)\n",
      "Step: 39 Loss: tensor(719.4592, grad_fn=<MeanBackward0>)\n",
      "Step: 40 Loss: tensor(510.5116, grad_fn=<MeanBackward0>)\n",
      "Step: 41 Loss: tensor(1270.9576, grad_fn=<MeanBackward0>)\n",
      "Step: 42 Loss: tensor(620.9312, grad_fn=<MeanBackward0>)\n",
      "Step: 43 Loss: tensor(1210.8983, grad_fn=<MeanBackward0>)\n",
      "Mean: 1333.16273\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(2189.5051, grad_fn=<MeanBackward0>)\n",
      "Step: 1 Loss: tensor(1058.9398, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2 Loss: tensor(1201.5653, grad_fn=<MeanBackward0>)\n",
      "Step: 3 Loss: tensor(594.3157, grad_fn=<MeanBackward0>)\n",
      "Step: 4 Loss: tensor(1371.3224, grad_fn=<MeanBackward0>)\n",
      "Step: 5 Loss: tensor(4455.9126, grad_fn=<MeanBackward0>)\n",
      "Step: 6 Loss: tensor(486.5388, grad_fn=<MeanBackward0>)\n",
      "Step: 7 Loss: tensor(966.7439, grad_fn=<MeanBackward0>)\n",
      "Step: 8 Loss: tensor(839.6509, grad_fn=<MeanBackward0>)\n",
      "Step: 9 Loss: tensor(632.9714, grad_fn=<MeanBackward0>)\n",
      "Step: 10 Loss: tensor(642.0200, grad_fn=<MeanBackward0>)\n",
      "Step: 11 Loss: tensor(1354.6632, grad_fn=<MeanBackward0>)\n",
      "Step: 12 Loss: tensor(1190.2474, grad_fn=<MeanBackward0>)\n",
      "Step: 13 Loss: tensor(537.4678, grad_fn=<MeanBackward0>)\n",
      "Step: 14 Loss: tensor(1703.9889, grad_fn=<MeanBackward0>)\n",
      "Step: 15 Loss: tensor(1787.1489, grad_fn=<MeanBackward0>)\n",
      "Step: 16 Loss: tensor(769.7100, grad_fn=<MeanBackward0>)\n",
      "Step: 17 Loss: tensor(1842.5006, grad_fn=<MeanBackward0>)\n",
      "Step: 18 Loss: tensor(448.9977, grad_fn=<MeanBackward0>)\n",
      "Step: 19 Loss: tensor(884.3109, grad_fn=<MeanBackward0>)\n",
      "Step: 20 Loss: tensor(547.8301, grad_fn=<MeanBackward0>)\n",
      "Step: 21 Loss: tensor(567.6872, grad_fn=<MeanBackward0>)\n",
      "Step: 22 Loss: tensor(517.6945, grad_fn=<MeanBackward0>)\n",
      "Step: 23 Loss: tensor(592.5685, grad_fn=<MeanBackward0>)\n",
      "Step: 24 Loss: tensor(1069.6830, grad_fn=<MeanBackward0>)\n",
      "Step: 25 Loss: tensor(727.3040, grad_fn=<MeanBackward0>)\n",
      "Step: 26 Loss: tensor(1363.9569, grad_fn=<MeanBackward0>)\n",
      "Step: 27 Loss: tensor(1552.7338, grad_fn=<MeanBackward0>)\n",
      "Step: 28 Loss: tensor(481.5448, grad_fn=<MeanBackward0>)\n",
      "Step: 29 Loss: tensor(1784.5674, grad_fn=<MeanBackward0>)\n",
      "Step: 30 Loss: tensor(675.4666, grad_fn=<MeanBackward0>)\n",
      "Step: 31 Loss: tensor(573.6253, grad_fn=<MeanBackward0>)\n",
      "Step: 32 Loss: tensor(577.6996, grad_fn=<MeanBackward0>)\n",
      "Step: 33 Loss: tensor(478.9565, grad_fn=<MeanBackward0>)\n",
      "Step: 34 Loss: tensor(666.0991, grad_fn=<MeanBackward0>)\n",
      "Step: 35 Loss: tensor(435.1952, grad_fn=<MeanBackward0>)\n",
      "Step: 36 Loss: tensor(630.2636, grad_fn=<MeanBackward0>)\n",
      "Step: 37 Loss: tensor(809.5840, grad_fn=<MeanBackward0>)\n",
      "Step: 38 Loss: tensor(1017.4251, grad_fn=<MeanBackward0>)\n",
      "Step: 39 Loss: tensor(711.8705, grad_fn=<MeanBackward0>)\n",
      "Step: 40 Loss: tensor(1837.7148, grad_fn=<MeanBackward0>)\n",
      "Step: 41 Loss: tensor(855.2025, grad_fn=<MeanBackward0>)\n",
      "Step: 42 Loss: tensor(950.1176, grad_fn=<MeanBackward0>)\n",
      "Step: 43 Loss: tensor(510.8481, grad_fn=<MeanBackward0>)\n",
      "Mean: 1020.32182\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(572.1411, grad_fn=<MeanBackward0>)\n",
      "Step: 1 Loss: tensor(571.5398, grad_fn=<MeanBackward0>)\n",
      "Step: 2 Loss: tensor(511.0272, grad_fn=<MeanBackward0>)\n",
      "Step: 3 Loss: tensor(1790.8485, grad_fn=<MeanBackward0>)\n",
      "Step: 4 Loss: tensor(347.9462, grad_fn=<MeanBackward0>)\n",
      "Step: 5 Loss: tensor(600.0360, grad_fn=<MeanBackward0>)\n",
      "Step: 6 Loss: tensor(430.9974, grad_fn=<MeanBackward0>)\n",
      "Step: 7 Loss: tensor(468.6077, grad_fn=<MeanBackward0>)\n",
      "Step: 8 Loss: tensor(707.5261, grad_fn=<MeanBackward0>)\n",
      "Step: 9 Loss: tensor(542.1511, grad_fn=<MeanBackward0>)\n",
      "Step: 10 Loss: tensor(442.9612, grad_fn=<MeanBackward0>)\n",
      "Step: 11 Loss: tensor(902.2246, grad_fn=<MeanBackward0>)\n",
      "Step: 12 Loss: tensor(335.0422, grad_fn=<MeanBackward0>)\n",
      "Step: 13 Loss: tensor(486.7861, grad_fn=<MeanBackward0>)\n",
      "Step: 14 Loss: tensor(840.7521, grad_fn=<MeanBackward0>)\n",
      "Step: 15 Loss: tensor(629.7921, grad_fn=<MeanBackward0>)\n",
      "Step: 16 Loss: tensor(292.8291, grad_fn=<MeanBackward0>)\n",
      "Step: 17 Loss: tensor(570.4711, grad_fn=<MeanBackward0>)\n",
      "Step: 18 Loss: tensor(378.9613, grad_fn=<MeanBackward0>)\n",
      "Step: 19 Loss: tensor(900.9687, grad_fn=<MeanBackward0>)\n",
      "Step: 20 Loss: tensor(474.9761, grad_fn=<MeanBackward0>)\n",
      "Step: 21 Loss: tensor(1162.1273, grad_fn=<MeanBackward0>)\n",
      "Step: 22 Loss: tensor(570.8642, grad_fn=<MeanBackward0>)\n",
      "Step: 23 Loss: tensor(316.7260, grad_fn=<MeanBackward0>)\n",
      "Step: 24 Loss: tensor(935.8864, grad_fn=<MeanBackward0>)\n",
      "Step: 25 Loss: tensor(526.8994, grad_fn=<MeanBackward0>)\n",
      "Step: 26 Loss: tensor(475.0525, grad_fn=<MeanBackward0>)\n",
      "Step: 27 Loss: tensor(682.2429, grad_fn=<MeanBackward0>)\n",
      "Step: 28 Loss: tensor(371.4360, grad_fn=<MeanBackward0>)\n",
      "Step: 29 Loss: tensor(496.1714, grad_fn=<MeanBackward0>)\n",
      "Step: 30 Loss: tensor(1258.9354, grad_fn=<MeanBackward0>)\n",
      "Step: 31 Loss: tensor(404.4240, grad_fn=<MeanBackward0>)\n",
      "Step: 32 Loss: tensor(343.1864, grad_fn=<MeanBackward0>)\n",
      "Step: 33 Loss: tensor(652.6904, grad_fn=<MeanBackward0>)\n",
      "Step: 34 Loss: tensor(382.8551, grad_fn=<MeanBackward0>)\n",
      "Step: 35 Loss: tensor(2517.7734, grad_fn=<MeanBackward0>)\n",
      "Step: 36 Loss: tensor(467.1041, grad_fn=<MeanBackward0>)\n",
      "Step: 37 Loss: tensor(607.3420, grad_fn=<MeanBackward0>)\n",
      "Step: 38 Loss: tensor(847.9194, grad_fn=<MeanBackward0>)\n",
      "Step: 39 Loss: tensor(1417.8185, grad_fn=<MeanBackward0>)\n",
      "Step: 40 Loss: tensor(294.3730, grad_fn=<MeanBackward0>)\n",
      "Step: 41 Loss: tensor(957.8049, grad_fn=<MeanBackward0>)\n",
      "Step: 42 Loss: tensor(434.8357, grad_fn=<MeanBackward0>)\n",
      "Step: 43 Loss: tensor(366.6584, grad_fn=<MeanBackward0>)\n",
      "Mean: 665.67528\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net1 = CDNN(hist=4)\n",
    "optim = torch.optim.Adam(net1.parameters(), lr=1e-3)\n",
    "\n",
    "exp1 = Experiment(name=\"Bezenac_Charb_small_3\",                         # de Bezenac model, trained on Charb Loss\n",
    "                  trainset=training_loader, valset=None, testset=None,  # data loaders\n",
    "                  model=net1,                                           # model with 4 days of history\n",
    "                  loss_fn=charbonnier_loss,                             # loss function for training\n",
    "                  regloss=False,                                        # whether to regularize the training loss \n",
    "                  test_loss=nn.MSELoss(reduction=\"mean\"),               # loss function for testing\n",
    "                  optimizer=optim,\n",
    "                  examples=None,\n",
    "                  outdir=path)\n",
    "\n",
    "exp1.run(epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a1ca72",
   "metadata": {},
   "source": [
    "### Training with (Regularized) Charbonnier Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f09f43a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new directory to save model states and results: /projectnb/labci/Lucia/rainfall-pde-ml/experiments/2023-09-15/Bezenac_CharbReg_small_2\n",
      "Running experiment: Bezenac_CharbReg_small_2...\n",
      "Training over 5 epochs...\n",
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() missing 2 required positional arguments: 'w' and 'reg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 14\u001b[0m\n\u001b[1;32m      2\u001b[0m optim \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(net2\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[1;32m      4\u001b[0m exp2 \u001b[38;5;241m=\u001b[39m Experiment(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBezenac_CharbReg_small_2\u001b[39m\u001b[38;5;124m\"\u001b[39m,                      \u001b[38;5;66;03m# de Bezenac model, trained on Regularized Charb Loss\u001b[39;00m\n\u001b[1;32m      5\u001b[0m                   trainset\u001b[38;5;241m=\u001b[39mtraining_loader, valset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, testset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# data loaders\u001b[39;00m\n\u001b[1;32m      6\u001b[0m                   model\u001b[38;5;241m=\u001b[39mnet2,                                           \u001b[38;5;66;03m# model with 4 days of history\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m                   examples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m                   outdir\u001b[38;5;241m=\u001b[39mpath)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mexp2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[36], line 122\u001b[0m, in \u001b[0;36mExperiment.run\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 122\u001b[0m     epoch_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m     fname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutdir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/train_epoch_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(t)\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_results(epoch_losses, fname)\n",
      "Cell \u001b[0;32mIn[36], line 44\u001b[0m, in \u001b[0;36mExperiment.train_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMSE\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mErr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname:\n\u001b[0;32m---> 44\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(y_pred, y, wind, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregloss)\n",
      "File \u001b[0;32m/projectnb/labci/luciav/.conda/envs/bez-torch/lib/python3.9/site-packages/torch/autograd/function.py:506\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    505\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    510\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 2 required positional arguments: 'w' and 'reg'"
     ]
    }
   ],
   "source": [
    "net2 = CDNN(hist=4)\n",
    "optim = torch.optim.Adam(net2.parameters(), lr=1e-3)\n",
    "\n",
    "exp2 = Experiment(name=\"Bezenac_CharbReg_small_2\",                      # de Bezenac model, trained on Regularized Charb Loss\n",
    "                  trainset=training_loader, valset=None, testset=None,  # data loaders\n",
    "                  model=net2,                                           # model with 4 days of history\n",
    "                  loss_fn=Charbonnier_Loss.apply,                       # loss function for training\n",
    "                  regloss=True,                                         # whether to regularize the training loss \n",
    "                  test_loss=nn.MSELoss(reduction=\"mean\"),               # loss function for testing\n",
    "                  optimizer=optim,\n",
    "                  examples=None,\n",
    "                  outdir=path)\n",
    "\n",
    "exp2.run(epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff8b067",
   "metadata": {},
   "source": [
    "### Training with Squared Error Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8dbbcb5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new directory to save model states and results: /projectnb/labci/Lucia/rainfall-pde-ml/experiments/2023-09-15/Bezenac_SqErr_small_0\n",
      "Running experiment: Bezenac_SqErr_small_0...\n",
      "Training over 5 epochs...\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(4217.4121, grad_fn=<MeanBackward0>)\n",
      "Step: 1 Loss: tensor(8013.2891, grad_fn=<MeanBackward0>)\n",
      "Step: 2 Loss: tensor(2224.2229, grad_fn=<MeanBackward0>)\n",
      "Step: 3 Loss: tensor(4523.1372, grad_fn=<MeanBackward0>)\n",
      "Step: 4 Loss: tensor(3231.8889, grad_fn=<MeanBackward0>)\n",
      "Step: 5 Loss: tensor(1050.1475, grad_fn=<MeanBackward0>)\n",
      "Step: 6 Loss: tensor(810.1934, grad_fn=<MeanBackward0>)\n",
      "Step: 7 Loss: tensor(525.2222, grad_fn=<MeanBackward0>)\n",
      "Step: 8 Loss: tensor(435.0779, grad_fn=<MeanBackward0>)\n",
      "Step: 9 Loss: tensor(598.0999, grad_fn=<MeanBackward0>)\n",
      "Step: 10 Loss: tensor(396.8212, grad_fn=<MeanBackward0>)\n",
      "Step: 11 Loss: tensor(151.8920, grad_fn=<MeanBackward0>)\n",
      "Step: 12 Loss: tensor(159.2534, grad_fn=<MeanBackward0>)\n",
      "Step: 13 Loss: tensor(135.9928, grad_fn=<MeanBackward0>)\n",
      "Step: 14 Loss: tensor(54.7838, grad_fn=<MeanBackward0>)\n",
      "Step: 15 Loss: tensor(113.5952, grad_fn=<MeanBackward0>)\n",
      "Step: 16 Loss: tensor(34.5637, grad_fn=<MeanBackward0>)\n",
      "Step: 17 Loss: tensor(48.5641, grad_fn=<MeanBackward0>)\n",
      "Step: 18 Loss: tensor(49.8648, grad_fn=<MeanBackward0>)\n",
      "Step: 19 Loss: tensor(47.7806, grad_fn=<MeanBackward0>)\n",
      "Step: 20 Loss: tensor(125.0309, grad_fn=<MeanBackward0>)\n",
      "Step: 21 Loss: tensor(27.0193, grad_fn=<MeanBackward0>)\n",
      "Step: 22 Loss: tensor(11.7196, grad_fn=<MeanBackward0>)\n",
      "Step: 23 Loss: tensor(57.8400, grad_fn=<MeanBackward0>)\n",
      "Step: 24 Loss: tensor(29.9627, grad_fn=<MeanBackward0>)\n",
      "Step: 25 Loss: tensor(13.9296, grad_fn=<MeanBackward0>)\n",
      "Step: 26 Loss: tensor(10.2371, grad_fn=<MeanBackward0>)\n",
      "Step: 27 Loss: tensor(6.4702, grad_fn=<MeanBackward0>)\n",
      "Step: 28 Loss: tensor(10.4396, grad_fn=<MeanBackward0>)\n",
      "Step: 29 Loss: tensor(9.3755, grad_fn=<MeanBackward0>)\n",
      "Step: 30 Loss: tensor(9.6711, grad_fn=<MeanBackward0>)\n",
      "Step: 31 Loss: tensor(15.5224, grad_fn=<MeanBackward0>)\n",
      "Step: 32 Loss: tensor(7.6888, grad_fn=<MeanBackward0>)\n",
      "Step: 33 Loss: tensor(6.3504, grad_fn=<MeanBackward0>)\n",
      "Step: 34 Loss: tensor(10.4036, grad_fn=<MeanBackward0>)\n",
      "Step: 35 Loss: tensor(5.4633, grad_fn=<MeanBackward0>)\n",
      "Step: 36 Loss: tensor(6.1580, grad_fn=<MeanBackward0>)\n",
      "Step: 37 Loss: tensor(6.7030, grad_fn=<MeanBackward0>)\n",
      "Step: 38 Loss: tensor(8.7331, grad_fn=<MeanBackward0>)\n",
      "Step: 39 Loss: tensor(7.7841, grad_fn=<MeanBackward0>)\n",
      "Step: 40 Loss: tensor(7.5171, grad_fn=<MeanBackward0>)\n",
      "Step: 41 Loss: tensor(3.2399, grad_fn=<MeanBackward0>)\n",
      "Step: 42 Loss: tensor(5.8744, grad_fn=<MeanBackward0>)\n",
      "Step: 43 Loss: tensor(6.4304, grad_fn=<MeanBackward0>)\n",
      "Mean: 618.8947\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(4.2489, grad_fn=<MeanBackward0>)\n",
      "Step: 1 Loss: tensor(4.4969, grad_fn=<MeanBackward0>)\n",
      "Step: 2 Loss: tensor(4.6463, grad_fn=<MeanBackward0>)\n",
      "Step: 3 Loss: tensor(12.7850, grad_fn=<MeanBackward0>)\n",
      "Step: 4 Loss: tensor(8.6303, grad_fn=<MeanBackward0>)\n",
      "Step: 5 Loss: tensor(3.6075, grad_fn=<MeanBackward0>)\n",
      "Step: 6 Loss: tensor(3.5945, grad_fn=<MeanBackward0>)\n",
      "Step: 7 Loss: tensor(4.8920, grad_fn=<MeanBackward0>)\n",
      "Step: 8 Loss: tensor(8.1398, grad_fn=<MeanBackward0>)\n",
      "Step: 13 Loss: tensor(2.7586, grad_fn=<MeanBackward0>)\n",
      "Step: 14 Loss: tensor(5.3127, grad_fn=<MeanBackward0>)\n",
      "Step: 15 Loss: tensor(5.7276, grad_fn=<MeanBackward0>)\n",
      "Step: 16 Loss: tensor(3.4048, grad_fn=<MeanBackward0>)\n",
      "Step: 17 Loss: tensor(7.5803, grad_fn=<MeanBackward0>)\n",
      "Step: 18 Loss: tensor(4.3402, grad_fn=<MeanBackward0>)\n",
      "Step: 19 Loss: tensor(3.6368, grad_fn=<MeanBackward0>)\n",
      "Step: 20 Loss: tensor(3.4436, grad_fn=<MeanBackward0>)\n",
      "Step: 21 Loss: tensor(7.5837, grad_fn=<MeanBackward0>)\n",
      "Step: 22 Loss: tensor(6.4848, grad_fn=<MeanBackward0>)\n",
      "Step: 23 Loss: tensor(5.9340, grad_fn=<MeanBackward0>)\n",
      "Step: 24 Loss: tensor(5.8979, grad_fn=<MeanBackward0>)\n",
      "Step: 25 Loss: tensor(4.8147, grad_fn=<MeanBackward0>)\n",
      "Step: 26 Loss: tensor(5.8465, grad_fn=<MeanBackward0>)\n",
      "Step: 27 Loss: tensor(3.6284, grad_fn=<MeanBackward0>)\n",
      "Step: 28 Loss: tensor(3.8057, grad_fn=<MeanBackward0>)\n",
      "Step: 29 Loss: tensor(4.8024, grad_fn=<MeanBackward0>)\n",
      "Step: 30 Loss: tensor(3.4762, grad_fn=<MeanBackward0>)\n",
      "Step: 31 Loss: tensor(7.3610, grad_fn=<MeanBackward0>)\n",
      "Step: 32 Loss: tensor(5.8000, grad_fn=<MeanBackward0>)\n",
      "Step: 33 Loss: tensor(2.8818, grad_fn=<MeanBackward0>)\n",
      "Step: 34 Loss: tensor(5.0377, grad_fn=<MeanBackward0>)\n",
      "Step: 35 Loss: tensor(4.7631, grad_fn=<MeanBackward0>)\n",
      "Step: 36 Loss: tensor(9.7377, grad_fn=<MeanBackward0>)\n",
      "Step: 37 Loss: tensor(3.8959, grad_fn=<MeanBackward0>)\n",
      "Step: 38 Loss: tensor(3.1715, grad_fn=<MeanBackward0>)\n",
      "Step: 39 Loss: tensor(9.9406, grad_fn=<MeanBackward0>)\n",
      "Step: 40 Loss: tensor(5.1785, grad_fn=<MeanBackward0>)\n",
      "Step: 41 Loss: tensor(10.2196, grad_fn=<MeanBackward0>)\n",
      "Step: 42 Loss: tensor(5.8968, grad_fn=<MeanBackward0>)\n",
      "Step: 43 Loss: tensor(7.4137, grad_fn=<MeanBackward0>)\n",
      "Mean: 5.72322\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(5.9718, grad_fn=<MeanBackward0>)\n",
      "Step: 1 Loss: tensor(3.8512, grad_fn=<MeanBackward0>)\n",
      "Step: 2 Loss: tensor(9.2173, grad_fn=<MeanBackward0>)\n",
      "Step: 3 Loss: tensor(3.4650, grad_fn=<MeanBackward0>)\n",
      "Step: 4 Loss: tensor(4.2383, grad_fn=<MeanBackward0>)\n",
      "Step: 5 Loss: tensor(6.2365, grad_fn=<MeanBackward0>)\n",
      "Step: 6 Loss: tensor(3.6497, grad_fn=<MeanBackward0>)\n",
      "Step: 7 Loss: tensor(5.6478, grad_fn=<MeanBackward0>)\n",
      "Step: 8 Loss: tensor(5.4131, grad_fn=<MeanBackward0>)\n",
      "Step: 9 Loss: tensor(2.3058, grad_fn=<MeanBackward0>)\n",
      "Step: 10 Loss: tensor(8.2939, grad_fn=<MeanBackward0>)\n",
      "Step: 11 Loss: tensor(6.6945, grad_fn=<MeanBackward0>)\n",
      "Step: 12 Loss: tensor(3.7585, grad_fn=<MeanBackward0>)\n",
      "Step: 13 Loss: tensor(2.6086, grad_fn=<MeanBackward0>)\n",
      "Step: 14 Loss: tensor(5.3510, grad_fn=<MeanBackward0>)\n",
      "Step: 15 Loss: tensor(11.0790, grad_fn=<MeanBackward0>)\n",
      "Step: 16 Loss: tensor(5.4440, grad_fn=<MeanBackward0>)\n",
      "Step: 17 Loss: tensor(3.5969, grad_fn=<MeanBackward0>)\n",
      "Step: 18 Loss: tensor(2.4953, grad_fn=<MeanBackward0>)\n",
      "Step: 19 Loss: tensor(6.4729, grad_fn=<MeanBackward0>)\n",
      "Step: 20 Loss: tensor(1.7908, grad_fn=<MeanBackward0>)\n",
      "Step: 21 Loss: tensor(8.2238, grad_fn=<MeanBackward0>)\n",
      "Step: 22 Loss: tensor(3.0583, grad_fn=<MeanBackward0>)\n",
      "Step: 23 Loss: tensor(3.6117, grad_fn=<MeanBackward0>)\n",
      "Step: 24 Loss: tensor(3.2504, grad_fn=<MeanBackward0>)\n",
      "Step: 25 Loss: tensor(5.4414, grad_fn=<MeanBackward0>)\n",
      "Step: 26 Loss: tensor(3.1814, grad_fn=<MeanBackward0>)\n",
      "Step: 27 Loss: tensor(7.2745, grad_fn=<MeanBackward0>)\n",
      "Step: 28 Loss: tensor(8.0840, grad_fn=<MeanBackward0>)\n",
      "Step: 29 Loss: tensor(5.6364, grad_fn=<MeanBackward0>)\n",
      "Step: 30 Loss: tensor(7.5286, grad_fn=<MeanBackward0>)\n",
      "Step: 31 Loss: tensor(5.0132, grad_fn=<MeanBackward0>)\n",
      "Step: 32 Loss: tensor(3.8310, grad_fn=<MeanBackward0>)\n",
      "Step: 33 Loss: tensor(6.5299, grad_fn=<MeanBackward0>)\n",
      "Step: 34 Loss: tensor(2.8088, grad_fn=<MeanBackward0>)\n",
      "Step: 35 Loss: tensor(4.4110, grad_fn=<MeanBackward0>)\n",
      "Step: 36 Loss: tensor(4.9553, grad_fn=<MeanBackward0>)\n",
      "Step: 37 Loss: tensor(3.2786, grad_fn=<MeanBackward0>)\n",
      "Step: 38 Loss: tensor(6.9861, grad_fn=<MeanBackward0>)\n",
      "Step: 39 Loss: tensor(5.8085, grad_fn=<MeanBackward0>)\n",
      "Step: 40 Loss: tensor(4.2130, grad_fn=<MeanBackward0>)\n",
      "Step: 41 Loss: tensor(7.5284, grad_fn=<MeanBackward0>)\n",
      "Step: 42 Loss: tensor(5.0285, grad_fn=<MeanBackward0>)\n",
      "Step: 43 Loss: tensor(3.5208, grad_fn=<MeanBackward0>)\n",
      "Mean: 5.15422\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(7.4188, grad_fn=<MeanBackward0>)\n",
      "Step: 1 Loss: tensor(6.0562, grad_fn=<MeanBackward0>)\n",
      "Step: 2 Loss: tensor(5.5352, grad_fn=<MeanBackward0>)\n",
      "Step: 3 Loss: tensor(7.0102, grad_fn=<MeanBackward0>)\n",
      "Step: 4 Loss: tensor(5.8766, grad_fn=<MeanBackward0>)\n",
      "Step: 5 Loss: tensor(7.2041, grad_fn=<MeanBackward0>)\n",
      "Step: 6 Loss: tensor(5.0394, grad_fn=<MeanBackward0>)\n",
      "Step: 7 Loss: tensor(4.2336, grad_fn=<MeanBackward0>)\n",
      "Step: 8 Loss: tensor(2.9662, grad_fn=<MeanBackward0>)\n",
      "Step: 9 Loss: tensor(6.4573, grad_fn=<MeanBackward0>)\n",
      "Step: 10 Loss: tensor(3.4682, grad_fn=<MeanBackward0>)\n",
      "Step: 11 Loss: tensor(2.9668, grad_fn=<MeanBackward0>)\n",
      "Step: 12 Loss: tensor(6.6996, grad_fn=<MeanBackward0>)\n",
      "Step: 13 Loss: tensor(6.3609, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 14 Loss: tensor(2.8350, grad_fn=<MeanBackward0>)\n",
      "Step: 15 Loss: tensor(4.0220, grad_fn=<MeanBackward0>)\n",
      "Step: 16 Loss: tensor(4.5661, grad_fn=<MeanBackward0>)\n",
      "Step: 17 Loss: tensor(3.6186, grad_fn=<MeanBackward0>)\n",
      "Step: 18 Loss: tensor(4.1965, grad_fn=<MeanBackward0>)\n",
      "Step: 19 Loss: tensor(5.8347, grad_fn=<MeanBackward0>)\n",
      "Step: 20 Loss: tensor(2.9659, grad_fn=<MeanBackward0>)\n",
      "Step: 21 Loss: tensor(1.9482, grad_fn=<MeanBackward0>)\n",
      "Step: 22 Loss: tensor(2.4295, grad_fn=<MeanBackward0>)\n",
      "Step: 23 Loss: tensor(4.8530, grad_fn=<MeanBackward0>)\n",
      "Step: 24 Loss: tensor(4.1803, grad_fn=<MeanBackward0>)\n",
      "Step: 25 Loss: tensor(4.6053, grad_fn=<MeanBackward0>)\n",
      "Step: 26 Loss: tensor(5.2404, grad_fn=<MeanBackward0>)\n",
      "Step: 27 Loss: tensor(2.3982, grad_fn=<MeanBackward0>)\n",
      "Step: 28 Loss: tensor(2.7741, grad_fn=<MeanBackward0>)\n",
      "Step: 29 Loss: tensor(6.5655, grad_fn=<MeanBackward0>)\n",
      "Step: 30 Loss: tensor(3.7174, grad_fn=<MeanBackward0>)\n",
      "Step: 31 Loss: tensor(5.4605, grad_fn=<MeanBackward0>)\n",
      "Step: 32 Loss: tensor(3.4221, grad_fn=<MeanBackward0>)\n",
      "Step: 33 Loss: tensor(3.6032, grad_fn=<MeanBackward0>)\n",
      "Step: 34 Loss: tensor(3.5693, grad_fn=<MeanBackward0>)\n",
      "Step: 35 Loss: tensor(4.4266, grad_fn=<MeanBackward0>)\n",
      "Step: 36 Loss: tensor(5.6171, grad_fn=<MeanBackward0>)\n",
      "Step: 37 Loss: tensor(5.6093, grad_fn=<MeanBackward0>)\n",
      "Step: 38 Loss: tensor(8.0812, grad_fn=<MeanBackward0>)\n",
      "Step: 39 Loss: tensor(4.6708, grad_fn=<MeanBackward0>)\n",
      "Step: 40 Loss: tensor(4.6708, grad_fn=<MeanBackward0>)\n",
      "Step: 41 Loss: tensor(3.5409, grad_fn=<MeanBackward0>)\n",
      "Step: 42 Loss: tensor(7.2679, grad_fn=<MeanBackward0>)\n",
      "Step: 43 Loss: tensor(8.8849, grad_fn=<MeanBackward0>)\n",
      "Mean: 4.83791\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(6.7200, grad_fn=<MeanBackward0>)\n",
      "Step: 1 Loss: tensor(4.0043, grad_fn=<MeanBackward0>)\n",
      "Step: 2 Loss: tensor(2.9127, grad_fn=<MeanBackward0>)\n",
      "Step: 3 Loss: tensor(5.3653, grad_fn=<MeanBackward0>)\n",
      "Step: 4 Loss: tensor(6.1338, grad_fn=<MeanBackward0>)\n",
      "Step: 5 Loss: tensor(4.4791, grad_fn=<MeanBackward0>)\n",
      "Step: 6 Loss: tensor(7.6086, grad_fn=<MeanBackward0>)\n",
      "Step: 7 Loss: tensor(4.3490, grad_fn=<MeanBackward0>)\n",
      "Step: 8 Loss: tensor(4.7409, grad_fn=<MeanBackward0>)\n",
      "Step: 9 Loss: tensor(8.1301, grad_fn=<MeanBackward0>)\n",
      "Step: 10 Loss: tensor(3.3851, grad_fn=<MeanBackward0>)\n",
      "Step: 11 Loss: tensor(5.1641, grad_fn=<MeanBackward0>)\n",
      "Step: 12 Loss: tensor(6.7140, grad_fn=<MeanBackward0>)\n",
      "Step: 13 Loss: tensor(5.4939, grad_fn=<MeanBackward0>)\n",
      "Step: 14 Loss: tensor(7.2505, grad_fn=<MeanBackward0>)\n",
      "Step: 15 Loss: tensor(4.4717, grad_fn=<MeanBackward0>)\n",
      "Step: 16 Loss: tensor(4.9376, grad_fn=<MeanBackward0>)\n",
      "Step: 17 Loss: tensor(8.1273, grad_fn=<MeanBackward0>)\n",
      "Step: 18 Loss: tensor(3.0808, grad_fn=<MeanBackward0>)\n",
      "Step: 19 Loss: tensor(3.5049, grad_fn=<MeanBackward0>)\n",
      "Step: 20 Loss: tensor(2.4834, grad_fn=<MeanBackward0>)\n",
      "Step: 21 Loss: tensor(4.7834, grad_fn=<MeanBackward0>)\n",
      "Step: 22 Loss: tensor(5.2964, grad_fn=<MeanBackward0>)\n",
      "Step: 23 Loss: tensor(3.0195, grad_fn=<MeanBackward0>)\n",
      "Step: 24 Loss: tensor(5.9318, grad_fn=<MeanBackward0>)\n",
      "Step: 25 Loss: tensor(1.9107, grad_fn=<MeanBackward0>)\n",
      "Step: 26 Loss: tensor(5.3687, grad_fn=<MeanBackward0>)\n",
      "Step: 27 Loss: tensor(5.5836, grad_fn=<MeanBackward0>)\n",
      "Step: 28 Loss: tensor(3.8562, grad_fn=<MeanBackward0>)\n",
      "Step: 29 Loss: tensor(6.6826, grad_fn=<MeanBackward0>)\n",
      "Step: 30 Loss: tensor(5.4997, grad_fn=<MeanBackward0>)\n",
      "Step: 31 Loss: tensor(3.8521, grad_fn=<MeanBackward0>)\n",
      "Step: 32 Loss: tensor(3.3570, grad_fn=<MeanBackward0>)\n",
      "Step: 33 Loss: tensor(6.0361, grad_fn=<MeanBackward0>)\n",
      "Step: 34 Loss: tensor(5.2350, grad_fn=<MeanBackward0>)\n",
      "Step: 35 Loss: tensor(3.1965, grad_fn=<MeanBackward0>)\n",
      "Step: 36 Loss: tensor(3.7355, grad_fn=<MeanBackward0>)\n",
      "Step: 37 Loss: tensor(3.1116, grad_fn=<MeanBackward0>)\n",
      "Step: 38 Loss: tensor(9.7291, grad_fn=<MeanBackward0>)\n",
      "Step: 39 Loss: tensor(1.9713, grad_fn=<MeanBackward0>)\n",
      "Step: 40 Loss: tensor(3.4772, grad_fn=<MeanBackward0>)\n",
      "Step: 41 Loss: tensor(2.7081, grad_fn=<MeanBackward0>)\n",
      "Step: 42 Loss: tensor(2.1715, grad_fn=<MeanBackward0>)\n",
      "Step: 43 Loss: tensor(3.9396, grad_fn=<MeanBackward0>)\n",
      "Mean: 4.7616\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net3 = CDNN(hist=4)\n",
    "optim = torch.optim.Adam(net3.parameters(), lr=1e-3)\n",
    "\n",
    "exp3 = Experiment(name=\"Bezenac_SqErr_small_0\",                         # de Bezenac model, trained on err^2 Loss\n",
    "                  trainset=training_loader, valset=None, testset=None,  # data loaders\n",
    "                  model=net3,                                           # model with 4 days of history\n",
    "                  loss_fn=squared_error_loss,                           # loss function for training\n",
    "                  regloss=False,                                        # whether to regularize the training loss \n",
    "                  test_loss=nn.MSELoss(reduction=\"mean\"),               # loss function for testing\n",
    "                  optimizer=optim,\n",
    "                  examples=None,\n",
    "                  outdir=path)\n",
    "\n",
    "exp3.run(epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "218.182px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
