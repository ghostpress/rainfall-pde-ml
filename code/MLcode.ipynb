{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e51c2d6",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports-and-setup-functions\" data-toc-modified-id=\"Imports-and-setup-functions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports and setup functions</a></span></li><li><span><a href=\"#DataLoader-Module\" data-toc-modified-id=\"DataLoader-Module-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>DataLoader Module</a></span><ul class=\"toc-item\"><li><span><a href=\"#Image-regions\" data-toc-modified-id=\"Image-regions-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Image regions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Find-interesting-regions-to-test-on\" data-toc-modified-id=\"Find-interesting-regions-to-test-on-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Find interesting regions to test on</a></span></li><li><span><a href=\"#Cut-all-data-into-64x64-regions\" data-toc-modified-id=\"Cut-all-data-into-64x64-regions-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Cut all data into 64x64 regions</a></span></li><li><span><a href=\"#Save-to-.npy-files\" data-toc-modified-id=\"Save-to-.npy-files-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Save to .npy files</a></span></li></ul></li><li><span><a href=\"#Train-val-test-split\" data-toc-modified-id=\"Train-val-test-split-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Train-val-test split</a></span></li><li><span><a href=\"#Inputs-and-ends\" data-toc-modified-id=\"Inputs-and-ends-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Inputs and ends</a></span></li><li><span><a href=\"#Tensors,-DataLoader\" data-toc-modified-id=\"Tensors,-DataLoader-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Tensors, DataLoader</a></span></li><li><span><a href=\"#Create-DataLoader-for-training-data\" data-toc-modified-id=\"Create-DataLoader-for-training-data-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Create DataLoader for training data</a></span></li></ul></li><li><span><a href=\"#Model-Module\" data-toc-modified-id=\"Model-Module-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Model Module</a></span><ul class=\"toc-item\"><li><span><a href=\"#AR1:-linear-mapping\" data-toc-modified-id=\"AR1:-linear-mapping-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>AR1: linear mapping</a></span></li><li><span><a href=\"#de-Bézenac-et-al,-2019:-CNN-with-warp-mapping\" data-toc-modified-id=\"de-Bézenac-et-al,-2019:-CNN-with-warp-mapping-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>de Bézenac et al, 2019: CNN with warp mapping</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loss-Function\" data-toc-modified-id=\"Loss-Function-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Loss Function</a></span></li><li><span><a href=\"#Warp\" data-toc-modified-id=\"Warp-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Warp</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Model</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-3.2.4\"><span class=\"toc-item-num\">3.2.4&nbsp;&nbsp;</span>Training</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb70983",
   "metadata": {},
   "source": [
    "# Imports and setup functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6754139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Function, Variable\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2088495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datadir(x):\n",
    "    return \"/projectnb/labci/Lucia/data/\" + x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f15e4f",
   "metadata": {},
   "source": [
    "# DataLoader Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a8f21d",
   "metadata": {},
   "source": [
    "## Train-val-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715c5887",
   "metadata": {},
   "source": [
    "The authors trained on SST data from 2006-2015 and tested on data from 2016-2017. For the IBI reanalysis SST data, we only have from June 5, 2021 to June 23, 2023 (749 days). From these, we will use 80% for training, 10% for validation, and 10% for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7d16162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_days(files):\n",
    "    \"\"\"Helper method to take a list of filenames and return total the number \n",
    "    of days represented by the files in the list. \n",
    "    \n",
    "    This method assumes a particular file naming convention that has been used \n",
    "    for this project. \n",
    "    \n",
    "    File naming convention: sst_geo_yyyymmdd.nc_region_XX.npy\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    files : list : data file names\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    delta : int : the number of days represented by the inputted files\n",
    "    \"\"\"\n",
    "    \n",
    "    files.sort()\n",
    "    \n",
    "    first = datetime.datetime.strptime(files[0][8:16], \"%Y%m%d\").date()\n",
    "    last = datetime.datetime.strptime(files[len(files)-1][8:16], \"%Y%m%d\").date()\n",
    "    \n",
    "    delta = int((last - first) / datetime.timedelta(days=1))\n",
    "    \n",
    "    return delta\n",
    "\n",
    "def train_val_test_cutoffs(topdir, split):\n",
    "    \"\"\"Helper method to create lists of filenames for the train, val, and test\n",
    "    data splits. Uses the dates in the filenames to determine file order and \n",
    "    split cutoffs.\n",
    "    \n",
    "    This method assumes a particular file naming convention that has been used \n",
    "    for this project. \n",
    "    \n",
    "    File naming convention: sst_geo_yyyymmdd.nc_region_XX.npy\n",
    "       \n",
    "    Parameters\n",
    "    ----------\n",
    "    topdir : string : the path to the directory holding the data\n",
    "    split : list : the fractions for each split, eg. [0.8, 0.1, 0.1]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    cutoffs : list : date cutoffs for each split\n",
    "    \"\"\"\n",
    "    \n",
    "    all_files = os.listdir(topdir)\n",
    "    all_files.sort()\n",
    "    nfiles = len(all_files)\n",
    "    ndays = all_days(all_files)\n",
    "    \n",
    "    start_date = datetime.datetime.strptime(all_files[0][8:16], \"%Y%m%d\").date()\n",
    "    end_date = datetime.datetime.strptime(all_files[nfiles-1][8:16], \"%Y%m%d\").date()\n",
    "    \n",
    "    cutoffs = []\n",
    "    \n",
    "    for i in range(3):\n",
    "        delta = math.floor(ndays*split[i])\n",
    "        end = start_date + datetime.timedelta(days=delta)\n",
    "        cutoffs.append(end)\n",
    "        \n",
    "        start_date = end\n",
    "        \n",
    "    # Because of rounding, some files may have been missed\n",
    "    # Add these to the test split\n",
    "    if cutoffs[2] < end_date:\n",
    "        cutoffs[2] = end_date\n",
    "    \n",
    "    return cutoffs\n",
    "\n",
    "def train_val_test_split_files(topdir, split):\n",
    "    \"\"\"Method to split the data in a directory into training, validation, and\n",
    "    test sets. Uses the helper method train_val_test_cutoffs().\n",
    "    \n",
    "    This method assumes a particular file naming convention that has been used \n",
    "    for this project. \n",
    "    \n",
    "    File naming convention: sst_geo_yyyymmdd.nc_region_XX.npy\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    topdir : string : the path to the directory holding the data\n",
    "    split : list : the fractions for each split, eg. [0.8, 0.1, 0.1]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    train : list : list of filenames for the train set\n",
    "    val : list : list of filenames for the validation set\n",
    "    test : list : list of filenames for the test set\n",
    "    \"\"\"\n",
    "    \n",
    "    assert len(split) == 3, \"Please include a % split for train, validation, and test sets.\"\n",
    "    \n",
    "    cutoffs = train_val_test_cutoffs(topdir, split)\n",
    "    \n",
    "    all_files = os.listdir(topdir)\n",
    "    all_files.sort()\n",
    "    \n",
    "    train, val, test = [], [], []\n",
    "    \n",
    "    for f in all_files:\n",
    "        file_date = datetime.datetime.strptime(f[8:16], \"%Y%m%d\").date()\n",
    "        \n",
    "        if file_date <= cutoffs[0]:\n",
    "            train.append(f)\n",
    "        elif (file_date > cutoffs[0]) & (file_date <= cutoffs[1]):\n",
    "            val.append(f)\n",
    "        else:\n",
    "            test.append(f)\n",
    "            \n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38bda7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_file(filename):\n",
    "    \"\"\"Helper method to load a single .npy file.\"\"\"\n",
    "    return np.load(datadir(\"sst_npy/\" + filename))\n",
    "\n",
    "\n",
    "def load_data_from_files(files):\n",
    "    \"\"\"Method to load data from a list of .npy files.\"\"\"\n",
    "    data = []\n",
    "    for f in files:\n",
    "        data.append(load_data_from_file(f))\n",
    "        \n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2117c9",
   "metadata": {},
   "source": [
    "## Inputs and ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5a6a4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_by_region(files, region):\n",
    "    \"\"\"Helper method to search a list of files for only those corresponding to\n",
    "    a desired region. \n",
    "    \n",
    "    This method assumes a particular file naming convention that has been used \n",
    "    for this project. \n",
    "    \n",
    "    File naming convention: sst_geo_yyyymmdd.nc_region_XX.npy\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    files : list : list of filenames in which to search\n",
    "    region : int : desired region\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    region_files : list : sorted list of matching files\n",
    "    \"\"\"\n",
    "    \n",
    "    region_files = []\n",
    "    for fname in files:\n",
    "        if \"region_\" + str(region) + \".npy\" in fname:\n",
    "            region_files.append(fname)\n",
    "            \n",
    "    region_files.sort()\n",
    "    \n",
    "    return region_files\n",
    "\n",
    "def get_pairs_by_region(files, region, ndays=1):\n",
    "    \"\"\"Method to separate data into inputs (X) and ends (y), for example to\n",
    "    use 4 previous days (ndays=4) to predict the next day. The \"pairs\" are \n",
    "    pairs of (X,y) inputs and ends. This method works on one region at a time.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    files : list : list of files from which to get pairs\n",
    "    region : int : desired region\n",
    "    ndays : int : number of days to use as inputs\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    inps : np.ndarray : filenames for inputs\n",
    "    ends : list : filenames for ends\n",
    "    \"\"\"\n",
    "    \n",
    "    region_files = search_by_region(files, region)\n",
    "    \n",
    "    n = len(region_files)\n",
    "    \n",
    "    inps = []\n",
    "    ends = region_files[ndays:]\n",
    "    \n",
    "    for i in range(n - ndays):\n",
    "        inps.append(region_files[i:i+ndays])\n",
    "    \n",
    "    return np.array(inps), np.array(ends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43858887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_regions(files):\n",
    "    \"\"\"Helper method to take a list of filenames and return a list of the \n",
    "    unique region numbers. \n",
    "    \n",
    "    This method assumes a particular file naming convention that has been used \n",
    "    for this project. \n",
    "    \n",
    "    File naming convention: sst_geo_yyyymmdd.nc_region_XX.npy\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    files : list : data file names\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    regions : list : list of unique region numbers in the directory\n",
    "    \"\"\"\n",
    "    \n",
    "    files.sort()\n",
    "    regions = []\n",
    "    \n",
    "    for f in files:\n",
    "        if \"region_\" in f:\n",
    "            \n",
    "            start_ind = f.find(\"region_\") + len(\"region_\")\n",
    "            end_ind = f.find(\".npy\")\n",
    "            \n",
    "            reg = f[start_ind:end_ind]\n",
    "            \n",
    "            if int(reg) not in regions:\n",
    "                regions.append(int(reg))\n",
    "            \n",
    "        else:\n",
    "            print(\"Files in this directory do not match the naming convention.\")\n",
    "    \n",
    "    regions.sort()\n",
    "    \n",
    "    return regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8510e497",
   "metadata": {},
   "source": [
    "## Tensors, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa7d662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(batchsize, files, ndays, dtype=torch.FloatTensor, shuff=True):\n",
    "    \"\"\"Method to create a PyTorch DataLoader object from a list of files and\n",
    "    additional parameters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dtype : torch.dtype : the data type for the DataLoader\n",
    "    batchsize : int : the desired batchsize for loading data\n",
    "    files : str : a list of files holding data to put into the DataLoader\n",
    "    ndays : int : the number of days to use as inputs to predict the next day\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    loader : torch.utils.data.DataLoader : the DataLoader object\n",
    "    \"\"\"\n",
    "    \n",
    "    regions = all_regions(files)\n",
    "\n",
    "    data = []\n",
    "    ends = []\n",
    "\n",
    "    for reg in regions:\n",
    "        reg_pairs = get_pairs_by_region(files, reg, ndays)\n",
    "        \n",
    "        for i in range(len(reg_pairs[0])):\n",
    "            dat = load_data_from_files(reg_pairs[0][i])\n",
    "            end = load_data_from_file(reg_pairs[1][i])\n",
    "        \n",
    "            data.append(dat)\n",
    "            ends.append(end)\n",
    "        \n",
    "    final_data = torch.from_numpy(np.array(data)).type(dtype)\n",
    "    final_ends = torch.from_numpy(np.array(ends)).type(dtype)\n",
    "    \n",
    "    loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(final_data, final_ends),\n",
    "                                           batch_size=batchsize, shuffle=shuff)\n",
    "    \n",
    "    return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06015e1",
   "metadata": {},
   "source": [
    "# Model Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ade1fba",
   "metadata": {},
   "source": [
    "## de Bézenac et al, 2019: CNN with warp mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e569ea",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2632738",
   "metadata": {},
   "source": [
    "The authors used a Charbonnier penality to measure the discrepancy between the predicted next image and the target: \n",
    "\n",
    "$\\rho(x) = (x + \\epsilon)^\\frac{1}{\\alpha}$\n",
    "\n",
    "Note that with $\\epsilon=0$ and $\\alpha=\\frac{1}{2}$, we recover the $\\textit{l}_2$ norm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc041ab",
   "metadata": {},
   "source": [
    "Additional penalty terms were added to the loss function, specifically to regulate the divergence of the displacement $\\omega$ between the prediction and the target, its magnitude, and its smoothness:\n",
    "\n",
    "$L_t = \\underset{x \\in \\Omega}\\Sigma \\rho(\\hat{I}_{t+1}(x) - I_{t+1}(x)) + \\lambda_{div}(\\nabla.\\omega_t(x))^2 + \\lambda_{magn}||\\omega_t(x)||^2 + \\lambda_{grad}||\\nabla \\omega_t(x)||^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29f28761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_regloss(F):\n",
    "    gradient = reduce(np.add, np.gradient(F))\n",
    "    \n",
    "    # TODO: try magnitude regularization in norm loss function\n",
    "    # could also move to inside model class\n",
    "    divergence = np.array([np.mean(gradient.sum(0)**2)])                         # 1st reg term above\n",
    "    magnitude  = np.array([np.mean(np.linalg.norm(F, axis=0, ord=2)**2)])        # 2nd reg term above\n",
    "    smoothness = np.array([np.mean(np.linalg.norm(gradient, axis=0, ord=2)**2)]) # 3rd reg term above\n",
    "    \n",
    "    return torch.from_numpy(divergence).type(torch.FloatTensor), torch.from_numpy(magnitude).type(torch.FloatTensor), torch.from_numpy(smoothness).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "741a61d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def charbonnier(x, alpha, eps):\n",
    "    \n",
    "    res = torch.mean(torch.pow(x + eps, (1. / alpha)))\n",
    "\n",
    "    return res\n",
    "\n",
    "def grad_charbonnier(x, alpha, eps):\n",
    "    \n",
    "    res = (1. / alpha)*torch.pow(x + eps, (1. / alpha) - 1)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "108d33db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Charbonnier_Loss(Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctl, y_pred, y, w, reg, alpha=0.5, eps=0):\n",
    "        ctl.save_for_backward(y_pred, y) # saves Tensor ctl for future call to backward()\n",
    "        \n",
    "        distsq = torch.pow(y_pred - y, 2)\n",
    "        charb_loss = charbonnier(distsq, alpha, eps)\n",
    "        \n",
    "        if reg:\n",
    "            lambda_div, lambda_magn, lambda_grad = 1, -0.1, 0.4\n",
    "            divergence, magnitude, smoothness = compute_regloss(w[0,:,:,:].numpy())\n",
    "            regulariz = lambda_div*divergence + lambda_magn*magnitude + lambda_grad*smoothness\n",
    "            charb_loss += regulariz[0]\n",
    "        \n",
    "        return charb_loss\n",
    "    \n",
    "    @staticmethod\n",
    "    # FIXME: with regularization constants, this is incomplete -> need grad(w) wrt x\n",
    "    def backward(ctl, alpha=0.5, eps=0):\n",
    "        y_pred, y = ctl.saved_tensors\n",
    "        distsq = torch.pow(y_pred - y, 2)\n",
    "\n",
    "        grad = grad_charbonnier(distsq, alpha, eps)\n",
    "        \n",
    "        return grad, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fe6c0aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_error_loss(y_pred, y): \n",
    "    error = torch.sum((y_pred - y)**2, axis=1)\n",
    "    loss = torch.mean(error)\n",
    "    return loss\n",
    "\n",
    "def charbonnier_loss(y_pred, y, alpha=0.5, epsilon=0):\n",
    "    error = torch.sum((y_pred - y)**2, axis=1)\n",
    "    loss = torch.mean(torch.pow(error + eps, (1. / alpha)))\n",
    "    return loss\n",
    "\n",
    "# TODO: add reg terms on W somehow (start with magnitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b406bf74",
   "metadata": {},
   "source": [
    "### Warp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e686d5",
   "metadata": {},
   "source": [
    "The future image is calculated based on a \"warp\" of the motion field estimate, $\\hat{\\omega}$, which can be thought of in this application as the wind vector field:\n",
    "\n",
    "$\\hat{I}_{t+1}(x) = \\underset{y \\in \\Omega} \\Sigma k(x - \\hat{\\omega}(x), y) I_t (y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5484aec7",
   "metadata": {},
   "source": [
    "where $k(u, v)$ is a radial basis function kernel, or equivalent a 2D Gaussian probability distribution:\n",
    "\n",
    "$k(x - \\hat{\\omega}(x), y) = \\frac{1}{4 \\pi D\\Delta t}e^{\\frac{-1}{4D \\Delta t} ||x - \\hat{\\omega}(x) - y||^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad59f08",
   "metadata": {},
   "source": [
    "for diffusion coefficient D and time step value $\\Delta t$ between $t$ and $t+1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "917ddf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel(distsq, D, dt):\n",
    "    \"\"\"Method to implement the k() function or radial basis function kernel \n",
    "    described above.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    distsq : float or torch.FloatTensor : the value of the squared norm of \n",
    "                 the distance\n",
    "    D : float : the diffusion coefficient\n",
    "    dt : float : the timestep\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    res : float or torch.FloatTensor: the result of the function\n",
    "    \"\"\"\n",
    "    \n",
    "    res = torch.exp(-distsq/(4*D*dt))/(4*np.pi*D*dt)\n",
    "    return res\n",
    "\n",
    "def kernel_gradient(self, dist, D, dt):\n",
    "    \"\"\"Method to implement the gradient of the k() function with respect to \n",
    "    the distance.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dist : float : the distance\n",
    "    D : float : the diffusion coefficient\n",
    "    dt : float : the timestep\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    res : float : the gradient of the function with respect to the distance\n",
    "    \"\"\"\n",
    "    \n",
    "    res = dist*torch.exp(-(dist**2).sum(1)/(4*D*dt))/(8*np.pi*D**2*dt**2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56d65cd",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b915e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(*models):\n",
    "    for model in models:\n",
    "        for module in model.modules():\n",
    "            \n",
    "            if isinstance(module, nn.Conv2d) or isinstance(module, nn.ConvTranspose2d) or isinstance(module, nn.Linear):\n",
    "                \n",
    "                # He initialization, from He, K. et al, 2015\n",
    "                nn.init.kaiming_normal_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    module.bias.data.zero_()\n",
    "                    \n",
    "            elif isinstance(module, nn.BatchNorm2d):\n",
    "                module.weight.data.fill_(1)\n",
    "                module.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71dfa15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(_EncoderBlock, self).__init__()\n",
    "        self.cv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.lr1 = nn.LeakyReLU(0.1)\n",
    "        self.cv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.lr2 = nn.LeakyReLU(0.1)\n",
    "        self.maxp = nn.MaxPool2d(kernel_size=3, stride=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual=x\n",
    "        #print(\"residual\",residual.shape)\n",
    "        out=self.cv1(x)\n",
    "        #print(\"cv1\",out.shape)\n",
    "        out=self.bn1(out)\n",
    "        #print(\"bn1\",out.shape)\n",
    "        out=self.lr1(out)\n",
    "        #print(\"lr1\",out.shape)\n",
    "        out+=residual\n",
    "        out=self.cv2(out)\n",
    "        out=self.bn2(out)\n",
    "        out=self.lr2(out)\n",
    "        out=self.maxp(out)\n",
    "        return out\n",
    "\n",
    "class _DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels):\n",
    "        super(_DecoderBlock, self).__init__()\n",
    "        self.cv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.lr1 = nn.LeakyReLU(0.1)\n",
    "        self.cv2 = nn.Conv2d(in_channels, middle_channels, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(middle_channels) \n",
    "        self.lr2 = nn.LeakyReLU(0.1)\n",
    "        self.tcv = nn.ConvTranspose2d(middle_channels, out_channels, kernel_size=3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual=x\n",
    "        #print(\"residual\",residual.shape)\n",
    "        out=self.cv1(x)\n",
    "        #print(\"cv1\",out.shape)\n",
    "        out=self.bn1(out)\n",
    "        #print(\"bn1\",out.shape)\n",
    "        out=self.lr1(out)\n",
    "        #print(\"lr1\",out.shape)\n",
    "        out+=residual\n",
    "        out=self.cv2(out)\n",
    "        out=self.bn2(out)\n",
    "        out=self.lr2(out)\n",
    "        out=self.tcv(out)\n",
    "        return out\n",
    "\n",
    "class _CenterBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(_CenterBlock, self).__init__()\n",
    "        self.cv1 = nn.Conv2d(in_channels,in_channels , kernel_size=3,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)  \n",
    "        self.lr1 = nn.LeakyReLU(0.1)\n",
    "        self.cv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels) \n",
    "        self.lr2 = nn.LeakyReLU(0.1)\n",
    "        self.tcv = nn.ConvTranspose2d(out_channels, out_channels, kernel_size=3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual=x\n",
    "        out=self.cv1(x)\n",
    "        out=self.bn1(out)\n",
    "        out=self.lr1(out)\n",
    "        out+=residual\n",
    "        out=self.cv2(out)\n",
    "        out=self.bn2(out)\n",
    "        out=self.lr2(out)\n",
    "        out=self.tcv(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dc45117",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDNN(nn.Module):\n",
    "    \"\"\"Class to implement a physics-driven Convolution-Deconvolution Neural \n",
    "    Network (CDNN) as described in (de Bezenac et al, 2019). This model \n",
    "    takes as input historical image(s) of Sea Surface Temperature (SST)\n",
    "    data, X, and uses a convolutional neural network (CNN) to estimate the \n",
    "    wind vector field W that drives the motion of X. From there, the next \n",
    "    image is predicted using a \"warping\" of the most recent input image and W,\n",
    "    as if to see how the SST variable evolves with the wind. \n",
    "    \n",
    "    The \"warping\" in this paper is a radial basis function kernel, or a \n",
    "    Gaussian centered in X-W. Other models we will implement later may use a\n",
    "    different warping scheme. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hist=1):\n",
    "        \"\"\"Function to construct the model. \n",
    "           \n",
    "           Parameters\n",
    "           ----------\n",
    "           hist : int : the number of days of \"history\" to use for prediction, \n",
    "                        default = 1.\n",
    "        \"\"\"\n",
    "        \n",
    "        super(CDNN, self).__init__()\n",
    "        \n",
    "        self.enc1 = _EncoderBlock(hist, 64)  \n",
    "        self.enc2 = _EncoderBlock(64, 128)\n",
    "        self.enc3 = _EncoderBlock(128, 256)\n",
    "        self.enc4 = _EncoderBlock(256, 512)\n",
    "        self.dec4 = _CenterBlock(512, 386)\n",
    "        self.dec3 = _DecoderBlock(386+256, 256, 194)\n",
    "        self.dec2 = _DecoderBlock(194+128, 128, 98)\n",
    "        self.dec1 = _DecoderBlock(98+64, 64, 2)\n",
    "        \n",
    "        self.final = nn.Sequential(nn.Conv2d(2, 2, kernel_size=3),) \n",
    "        initialize_weights(self)\n",
    "\n",
    "        self.hist = hist\n",
    "\n",
    "    def wind(self, x):\n",
    "        \"\"\"Function to estimate the wind vector field from historical input images.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.FloatTensor : the historical input images\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        wind : torch.FloatTensor : the estimated wind vector field\n",
    "        \"\"\"\n",
    "        \n",
    "        enc1 = self.enc1(x)\n",
    "        #print(\"x\",x.shape)\n",
    "        #print(\"enc1\",enc1.shape)\n",
    "        enc2 = self.enc2(enc1)\n",
    "        #print(\"enc2\",enc2.shape)\n",
    "        enc3 = self.enc3(enc2)\n",
    "        #print(\"enc3\",enc3.shape)\n",
    "        enc4 = self.enc4(enc3)\n",
    "        #print(\"enc4\",enc4.shape)\n",
    "        dec4 = self.dec4(enc4)\n",
    "        #print(\"dec4\",dec4.shape)\n",
    "        \n",
    "        dec3 = self.dec3(torch.cat([dec4, F.interpolate(enc3, dec4.size()[2:], mode='bilinear')], 1))\n",
    "        dec2 = self.dec2(torch.cat([dec3, F.interpolate(enc2, dec3.size()[2:], mode='bilinear')], 1))\n",
    "        dec1 = self.dec1(torch.cat([dec2, F.interpolate(enc1, dec2.size()[2:], mode='bilinear')], 1))\n",
    "        final = self.final(dec1)\n",
    "        \n",
    "        wind = F.interpolate(final, x.size()[2:], mode='bilinear')\n",
    "\n",
    "        return wind\n",
    "    \n",
    "    @staticmethod\n",
    "    def warp(I, W, hist):\n",
    "        \"\"\"Function to compute the warping of the input data and an estimated \n",
    "        wind vector field, in order to produce an output predicted image. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        I : torch.FloatTensor : the most recent input image to warp\n",
    "        W : torch.FloatTensor : the estimated wind vector field\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        warped : torch.FloatTensor : the warped prediction image\n",
    "        \"\"\"\n",
    "        \n",
    "        D = 0.45\n",
    "        dt = 1\n",
    "        \n",
    "        interval=torch.arange(I.size()[-1]).type(torch.FloatTensor)\n",
    "        \n",
    "        x1 = interval[None,:,None,None,None]\n",
    "        x2 = interval[None,None,:,None,None]\n",
    "        y1 = interval[None,None,None,:,None]\n",
    "        y2 = interval[None,None,None,None,:]\n",
    "        \n",
    "        # x - wind - y\n",
    "        distsq = (x1-y1-W[:,0,:,:,None,None])**2+(x2-y2-W[:,1,:,:,None,None])**2         \n",
    "        mult = I[:, hist-1, None,None,:,:] * kernel(distsq, D, dt)\n",
    "        warped = mult.sum(4).sum(3)\n",
    "        \n",
    "        return warped\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Function to execute the forward pass of the model. All of the \n",
    "        computations are done in the methods above, so this function \n",
    "        simply returns their outputs.\n",
    "        \n",
    "        Note: the wind vector field W is returned for use in the \n",
    "        regularized loss function later. For simple difference loss \n",
    "        functions, returning y_pred is sufficient. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.FloatTensor : the historical input images\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        W : torch.FloatTensor : the estimated wind vector field\n",
    "        y_pred : torch.FloatTensor : the predicted next image\n",
    "        \"\"\"\n",
    "        \n",
    "        W = self.wind(x)\n",
    "        y_pred = self.warp(x, W, self.hist) \n",
    "        \n",
    "        return W, y_pred "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd072838",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6550149",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "566d181e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment():\n",
    "    \n",
    "    def __init__(self, name, trainset, valset, testset, model, loss_fn, regloss, test_loss, optimizer, examples, outdir):\n",
    "        self.name = name\n",
    "        self.train_loader = trainset \n",
    "        self.val_loader = valset\n",
    "        self.test_loader = testset\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.regloss = regloss\n",
    "        self.test_loss = test_loss\n",
    "        self.optimizer = optimizer\n",
    "        self.examples = examples\n",
    "        \n",
    "        self.train_losses = []\n",
    "        self.valid_losses = []\n",
    "        self.test_losses  = []\n",
    "        \n",
    "        # Set up a directory for the experiment\n",
    "        self.dir_setup(outdir)\n",
    "        \n",
    "    def dir_setup(self, parent):\n",
    "        self.outdir = parent + \"/\" + self.name\n",
    "        os.mkdir(self.outdir)\n",
    "        print(\"Created new directory to save model states and results: \" + self.outdir)\n",
    "    \n",
    "    def train_loop(self):\n",
    "        size = len(self.train_loader.dataset)\n",
    "        # Set the model to training mode - important for batch normalization and dropout layers\n",
    "        # Unnecessary in this situation but added for best practices\n",
    "        self.model.train()\n",
    "    \n",
    "        losses = []\n",
    "    \n",
    "        for batch, (X, y) in enumerate(self.train_loader):\n",
    "            # Compute prediction and loss\n",
    "            #X = X.to(device) \n",
    "            #y = y.to(device)\n",
    "            outputs = self.model(X)\n",
    "            wind = outputs[0]\n",
    "            y_pred = outputs[1]\n",
    "            \n",
    "            if \"MSE\" or \"Diff\" in self.name:\n",
    "                loss = self.loss_fn(y_pred, y)\n",
    "            else:\n",
    "                loss = self.loss_fn(y_pred, y, wind, self.regloss)\n",
    "                \n",
    "            losses.append(loss.item())\n",
    "        \n",
    "            print(\"Step:\", batch, \"Loss:\", loss)\n",
    "        \n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "        \n",
    "        return losses\n",
    "    \n",
    "    # TODO: implement cross-validation?\n",
    "    # example: https://saturncloud.io/blog/how-to-use-kfold-cross-validation-with-dataloaders-in-pytorch/\n",
    "    def val_loop(self):\n",
    "        # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "        # Unnecessary in this situation but added for best practices\n",
    "        self.model.eval()\n",
    "        losses = []\n",
    "        num_loops = 0\n",
    "\n",
    "        # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "        # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "        with torch.no_grad():\n",
    "            for X, y in self.val_loader:\n",
    "                #X = X.to(device) \n",
    "                #y = y.to(device)\n",
    "                outputs = self.model(X)\n",
    "                y_pred = outputs[1]\n",
    "            \n",
    "                step_loss = self.loss_fn(y_pred, y).item()\n",
    "                print(\"Item:\", num_loops, \"Loss:\", step_loss)\n",
    "                losses.append(step_loss)\n",
    "                num_loops += 1\n",
    "\n",
    "        return losses\n",
    "    \n",
    "    def test(self):\n",
    "        # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "        # Unnecessary in this situation but added for best practices\n",
    "        self.model.eval()\n",
    "        losses = []\n",
    "        num_loops = 0\n",
    "\n",
    "        # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "        # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "        with torch.no_grad():\n",
    "            for X, y in self.test_loader:\n",
    "                #X = X.to(device) \n",
    "                #y = y.to(device)\n",
    "                outputs = self.model(X)\n",
    "                y_pred = outputs[1]\n",
    "            \n",
    "                step_loss = self.test_loss(y_pred, y).item()\n",
    "                print(\"Item:\", num_loops, \"Loss:\", step_loss)\n",
    "                losses.append(step_loss)\n",
    "                num_loops += 1\n",
    "\n",
    "        return losses\n",
    "    \n",
    "    def save_results(self, losses, fname):\n",
    "        np.save(fname + \".npy\", losses)\n",
    "    \n",
    "    def save_model_state(self, fname):\n",
    "        pass\n",
    "    \n",
    "    def run(self, epochs):\n",
    "        print(\"Running experiment: \" + self.name + \"...\")\n",
    "        \n",
    "        # -------------------- Training -------------------------\n",
    "        \n",
    "        print(\"Training over \" + str(epochs) + \" epochs...\")\n",
    "                \n",
    "        for t in range(epochs):\n",
    "            print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "            epoch_losses = self.train_loop()\n",
    "            \n",
    "            fname = self.outdir + \"/train_epoch_\" + str(t)\n",
    "            self.save_results(epoch_losses, fname)\n",
    "            \n",
    "            epoch_mean = np.round(np.mean(epoch_losses), 5)\n",
    "            print(\"Mean:\", epoch_mean)\n",
    "            self.train_losses.append(epoch_mean)\n",
    "        \n",
    "        self.plot_loss(self.train_losses, \"Training Loss\", \"Epoch\", [\"train\"])\n",
    "        \n",
    "        # -------------------- Validation ------------------------\n",
    "        # -------------------- Testing ---------------------------\n",
    "    \n",
    "    # TODO: implement with the \"interesting\" examples found earlier\n",
    "    def visualize_examples(self):\n",
    "        # \"Interesting\" regions were 3, 22, 29, 44 -> each 64x64\n",
    "        # Need to figure out where each region went in the DataLoader & how to index them\n",
    "        # Or, what if we don't need them to be in the DataLoader? Just load the arr.s & input thru constructor?\n",
    "        pass\n",
    "    \n",
    "    def plot_loss(self, loss_to_plot, title, xlab, legend_items):\n",
    "        plt.plot(loss_to_plot)\n",
    "        plt.title(self.name + \" \" + title)\n",
    "        \n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.xlabel(xlab)\n",
    "        plt.legend(legend_items, loc=\"upper left\")\n",
    "    \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272c33ed",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14566a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720\n",
      "3552\n",
      "31680\n",
      "44\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14b149002af0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "split = train_val_test_split_files(datadir(\"sst_npy/\"), [0.02, 0.1, 0.1]) # using small amount for now, to test\n",
    "\n",
    "train_split = split[0]\n",
    "val_split   = split[1]\n",
    "test_split  = split[2]\n",
    "\n",
    "# Total number of files in each split\n",
    "print(len(train_split))\n",
    "print(len(val_split))\n",
    "print(len(test_split))\n",
    "\n",
    "# For faster training, try larger batchsize\n",
    "training_loader = create_dataloader(batchsize=12, files=train_split, ndays=4, shuff=True)\n",
    "#val_loader = create_dataloader(batchsize=12, files=val_split, ndays=4, shuff=True)\n",
    "\n",
    "# Total number of batches in the loader\n",
    "print(len(training_loader))\n",
    "\n",
    "train_first, train_next = next(iter(training_loader)) \n",
    "plt.imshow(train_first[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "539b084e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(\"/projectnb/labci/Lucia/rainfall-pde-ml/experiments/\" + str(datetime.date.today()))\n",
    "except FileExistsError as e:\n",
    "    print(\"Already ran experiments today.\")\n",
    "finally:\n",
    "    path = \"/projectnb/labci/Lucia/rainfall-pde-ml/experiments/\" + str(datetime.date.today())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cbe793",
   "metadata": {},
   "source": [
    "### Training with MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7dec38d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new directory to save model states and results: /projectnb/labci/Lucia/rainfall-pde-ml/experiments/2023-09-12/Bezenac_MSE_small_1\n",
      "Running experiment: Bezenac_MSE_small_1...\n",
      "Training over 5 epochs...\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(71.3972, grad_fn=<MseLossBackward0>)\n",
      "Step: 1 Loss: tensor(109.3598, grad_fn=<MseLossBackward0>)\n",
      "Step: 2 Loss: tensor(39.6824, grad_fn=<MseLossBackward0>)\n",
      "Step: 3 Loss: tensor(56.3631, grad_fn=<MseLossBackward0>)\n",
      "Step: 4 Loss: tensor(60.0565, grad_fn=<MseLossBackward0>)\n",
      "Step: 5 Loss: tensor(36.2472, grad_fn=<MseLossBackward0>)\n",
      "Step: 6 Loss: tensor(23.0754, grad_fn=<MseLossBackward0>)\n",
      "Step: 7 Loss: tensor(7.1349, grad_fn=<MseLossBackward0>)\n",
      "Step: 8 Loss: tensor(11.9006, grad_fn=<MseLossBackward0>)\n",
      "Step: 9 Loss: tensor(2.1958, grad_fn=<MseLossBackward0>)\n",
      "Step: 10 Loss: tensor(1.6505, grad_fn=<MseLossBackward0>)\n",
      "Step: 11 Loss: tensor(2.8433, grad_fn=<MseLossBackward0>)\n",
      "Step: 12 Loss: tensor(1.4568, grad_fn=<MseLossBackward0>)\n",
      "Step: 13 Loss: tensor(0.4379, grad_fn=<MseLossBackward0>)\n",
      "Step: 14 Loss: tensor(1.6724, grad_fn=<MseLossBackward0>)\n",
      "Step: 15 Loss: tensor(1.3753, grad_fn=<MseLossBackward0>)\n",
      "Step: 16 Loss: tensor(0.2980, grad_fn=<MseLossBackward0>)\n",
      "Step: 17 Loss: tensor(0.5382, grad_fn=<MseLossBackward0>)\n",
      "Step: 18 Loss: tensor(0.3399, grad_fn=<MseLossBackward0>)\n",
      "Step: 19 Loss: tensor(0.4514, grad_fn=<MseLossBackward0>)\n",
      "Step: 20 Loss: tensor(0.2620, grad_fn=<MseLossBackward0>)\n",
      "Step: 21 Loss: tensor(0.2949, grad_fn=<MseLossBackward0>)\n",
      "Step: 22 Loss: tensor(0.2538, grad_fn=<MseLossBackward0>)\n",
      "Step: 23 Loss: tensor(0.1836, grad_fn=<MseLossBackward0>)\n",
      "Step: 24 Loss: tensor(0.1961, grad_fn=<MseLossBackward0>)\n",
      "Step: 25 Loss: tensor(0.2326, grad_fn=<MseLossBackward0>)\n",
      "Step: 26 Loss: tensor(0.2433, grad_fn=<MseLossBackward0>)\n",
      "Step: 27 Loss: tensor(0.2057, grad_fn=<MseLossBackward0>)\n",
      "Step: 28 Loss: tensor(0.1703, grad_fn=<MseLossBackward0>)\n",
      "Step: 29 Loss: tensor(0.1385, grad_fn=<MseLossBackward0>)\n",
      "Step: 30 Loss: tensor(0.1637, grad_fn=<MseLossBackward0>)\n",
      "Step: 31 Loss: tensor(0.1270, grad_fn=<MseLossBackward0>)\n",
      "Step: 32 Loss: tensor(0.1318, grad_fn=<MseLossBackward0>)\n",
      "Step: 33 Loss: tensor(0.1224, grad_fn=<MseLossBackward0>)\n",
      "Step: 34 Loss: tensor(0.1328, grad_fn=<MseLossBackward0>)\n",
      "Step: 35 Loss: tensor(0.1166, grad_fn=<MseLossBackward0>)\n",
      "Step: 36 Loss: tensor(0.1484, grad_fn=<MseLossBackward0>)\n",
      "Step: 37 Loss: tensor(0.1104, grad_fn=<MseLossBackward0>)\n",
      "Step: 38 Loss: tensor(0.1168, grad_fn=<MseLossBackward0>)\n",
      "Step: 39 Loss: tensor(0.1362, grad_fn=<MseLossBackward0>)\n",
      "Step: 40 Loss: tensor(0.0734, grad_fn=<MseLossBackward0>)\n",
      "Step: 41 Loss: tensor(0.0725, grad_fn=<MseLossBackward0>)\n",
      "Step: 42 Loss: tensor(0.1237, grad_fn=<MseLossBackward0>)\n",
      "Step: 43 Loss: tensor(0.2626, grad_fn=<MseLossBackward0>)\n",
      "Mean: 9.82945\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(0.1881, grad_fn=<MseLossBackward0>)\n",
      "Step: 1 Loss: tensor(0.0981, grad_fn=<MseLossBackward0>)\n",
      "Step: 2 Loss: tensor(0.1053, grad_fn=<MseLossBackward0>)\n",
      "Step: 3 Loss: tensor(0.1214, grad_fn=<MseLossBackward0>)\n",
      "Step: 4 Loss: tensor(0.1213, grad_fn=<MseLossBackward0>)\n",
      "Step: 5 Loss: tensor(0.1129, grad_fn=<MseLossBackward0>)\n",
      "Step: 6 Loss: tensor(0.1315, grad_fn=<MseLossBackward0>)\n",
      "Step: 7 Loss: tensor(0.1041, grad_fn=<MseLossBackward0>)\n",
      "Step: 8 Loss: tensor(0.1063, grad_fn=<MseLossBackward0>)\n",
      "Step: 9 Loss: tensor(0.1177, grad_fn=<MseLossBackward0>)\n",
      "Step: 10 Loss: tensor(0.1069, grad_fn=<MseLossBackward0>)\n",
      "Step: 11 Loss: tensor(0.1413, grad_fn=<MseLossBackward0>)\n",
      "Step: 12 Loss: tensor(0.0951, grad_fn=<MseLossBackward0>)\n",
      "Step: 13 Loss: tensor(0.0897, grad_fn=<MseLossBackward0>)\n",
      "Step: 14 Loss: tensor(0.0797, grad_fn=<MseLossBackward0>)\n",
      "Step: 15 Loss: tensor(0.1022, grad_fn=<MseLossBackward0>)\n",
      "Step: 16 Loss: tensor(0.1369, grad_fn=<MseLossBackward0>)\n",
      "Step: 17 Loss: tensor(0.0633, grad_fn=<MseLossBackward0>)\n",
      "Step: 18 Loss: tensor(0.1062, grad_fn=<MseLossBackward0>)\n",
      "Step: 19 Loss: tensor(0.0883, grad_fn=<MseLossBackward0>)\n",
      "Step: 20 Loss: tensor(0.0654, grad_fn=<MseLossBackward0>)\n",
      "Step: 21 Loss: tensor(0.1220, grad_fn=<MseLossBackward0>)\n",
      "Step: 22 Loss: tensor(0.1218, grad_fn=<MseLossBackward0>)\n",
      "Step: 23 Loss: tensor(0.1735, grad_fn=<MseLossBackward0>)\n",
      "Step: 24 Loss: tensor(0.0892, grad_fn=<MseLossBackward0>)\n",
      "Step: 25 Loss: tensor(0.0610, grad_fn=<MseLossBackward0>)\n",
      "Step: 26 Loss: tensor(0.1358, grad_fn=<MseLossBackward0>)\n",
      "Step: 27 Loss: tensor(0.0957, grad_fn=<MseLossBackward0>)\n",
      "Step: 28 Loss: tensor(0.1115, grad_fn=<MseLossBackward0>)\n",
      "Step: 29 Loss: tensor(0.1008, grad_fn=<MseLossBackward0>)\n",
      "Step: 30 Loss: tensor(0.1436, grad_fn=<MseLossBackward0>)\n",
      "Step: 31 Loss: tensor(0.0618, grad_fn=<MseLossBackward0>)\n",
      "Step: 32 Loss: tensor(0.0777, grad_fn=<MseLossBackward0>)\n",
      "Step: 33 Loss: tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "Step: 34 Loss: tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "Step: 35 Loss: tensor(0.0697, grad_fn=<MseLossBackward0>)\n",
      "Step: 36 Loss: tensor(0.0620, grad_fn=<MseLossBackward0>)\n",
      "Step: 37 Loss: tensor(0.0835, grad_fn=<MseLossBackward0>)\n",
      "Step: 38 Loss: tensor(0.1193, grad_fn=<MseLossBackward0>)\n",
      "Step: 39 Loss: tensor(0.1172, grad_fn=<MseLossBackward0>)\n",
      "Step: 40 Loss: tensor(0.1079, grad_fn=<MseLossBackward0>)\n",
      "Step: 41 Loss: tensor(0.0541, grad_fn=<MseLossBackward0>)\n",
      "Step: 42 Loss: tensor(0.0879, grad_fn=<MseLossBackward0>)\n",
      "Step: 43 Loss: tensor(0.0952, grad_fn=<MseLossBackward0>)\n",
      "Mean: 0.10217\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(0.0683, grad_fn=<MseLossBackward0>)\n",
      "Step: 1 Loss: tensor(0.0784, grad_fn=<MseLossBackward0>)\n",
      "Step: 2 Loss: tensor(0.0790, grad_fn=<MseLossBackward0>)\n",
      "Step: 3 Loss: tensor(0.1891, grad_fn=<MseLossBackward0>)\n",
      "Step: 4 Loss: tensor(0.1303, grad_fn=<MseLossBackward0>)\n",
      "Step: 5 Loss: tensor(0.0568, grad_fn=<MseLossBackward0>)\n",
      "Step: 6 Loss: tensor(0.0611, grad_fn=<MseLossBackward0>)\n",
      "Step: 7 Loss: tensor(0.0532, grad_fn=<MseLossBackward0>)\n",
      "Step: 8 Loss: tensor(0.1418, grad_fn=<MseLossBackward0>)\n",
      "Step: 9 Loss: tensor(0.0891, grad_fn=<MseLossBackward0>)\n",
      "Step: 10 Loss: tensor(0.1058, grad_fn=<MseLossBackward0>)\n",
      "Step: 11 Loss: tensor(0.0790, grad_fn=<MseLossBackward0>)\n",
      "Step: 12 Loss: tensor(0.0438, grad_fn=<MseLossBackward0>)\n",
      "Step: 13 Loss: tensor(0.0478, grad_fn=<MseLossBackward0>)\n",
      "Step: 14 Loss: tensor(0.0500, grad_fn=<MseLossBackward0>)\n",
      "Step: 15 Loss: tensor(0.0856, grad_fn=<MseLossBackward0>)\n",
      "Step: 16 Loss: tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "Step: 17 Loss: tensor(0.1159, grad_fn=<MseLossBackward0>)\n",
      "Step: 18 Loss: tensor(0.0669, grad_fn=<MseLossBackward0>)\n",
      "Step: 19 Loss: tensor(0.0620, grad_fn=<MseLossBackward0>)\n",
      "Step: 20 Loss: tensor(0.0506, grad_fn=<MseLossBackward0>)\n",
      "Step: 21 Loss: tensor(0.1166, grad_fn=<MseLossBackward0>)\n",
      "Step: 22 Loss: tensor(0.0830, grad_fn=<MseLossBackward0>)\n",
      "Step: 23 Loss: tensor(0.0948, grad_fn=<MseLossBackward0>)\n",
      "Step: 24 Loss: tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "Step: 25 Loss: tensor(0.0706, grad_fn=<MseLossBackward0>)\n",
      "Step: 26 Loss: tensor(0.0917, grad_fn=<MseLossBackward0>)\n",
      "Step: 27 Loss: tensor(0.0501, grad_fn=<MseLossBackward0>)\n",
      "Step: 28 Loss: tensor(0.0586, grad_fn=<MseLossBackward0>)\n",
      "Step: 29 Loss: tensor(0.0730, grad_fn=<MseLossBackward0>)\n",
      "Step: 30 Loss: tensor(0.0561, grad_fn=<MseLossBackward0>)\n",
      "Step: 31 Loss: tensor(0.1167, grad_fn=<MseLossBackward0>)\n",
      "Step: 32 Loss: tensor(0.0850, grad_fn=<MseLossBackward0>)\n",
      "Step: 33 Loss: tensor(0.0508, grad_fn=<MseLossBackward0>)\n",
      "Step: 34 Loss: tensor(0.0795, grad_fn=<MseLossBackward0>)\n",
      "Step: 35 Loss: tensor(0.0751, grad_fn=<MseLossBackward0>)\n",
      "Step: 36 Loss: tensor(0.1600, grad_fn=<MseLossBackward0>)\n",
      "Step: 37 Loss: tensor(0.0637, grad_fn=<MseLossBackward0>)\n",
      "Step: 38 Loss: tensor(0.0584, grad_fn=<MseLossBackward0>)\n",
      "Step: 39 Loss: tensor(0.1593, grad_fn=<MseLossBackward0>)\n",
      "Step: 40 Loss: tensor(0.0762, grad_fn=<MseLossBackward0>)\n",
      "Step: 41 Loss: tensor(0.1640, grad_fn=<MseLossBackward0>)\n",
      "Step: 42 Loss: tensor(0.0912, grad_fn=<MseLossBackward0>)\n",
      "Step: 43 Loss: tensor(0.1186, grad_fn=<MseLossBackward0>)\n",
      "Mean: 0.08639\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(0.0976, grad_fn=<MseLossBackward0>)\n",
      "Step: 1 Loss: tensor(0.0686, grad_fn=<MseLossBackward0>)\n",
      "Step: 2 Loss: tensor(0.1234, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 3 Loss: tensor(0.0622, grad_fn=<MseLossBackward0>)\n",
      "Step: 4 Loss: tensor(0.0588, grad_fn=<MseLossBackward0>)\n",
      "Step: 5 Loss: tensor(0.1046, grad_fn=<MseLossBackward0>)\n",
      "Step: 6 Loss: tensor(0.0599, grad_fn=<MseLossBackward0>)\n",
      "Step: 7 Loss: tensor(0.0871, grad_fn=<MseLossBackward0>)\n",
      "Step: 8 Loss: tensor(0.0894, grad_fn=<MseLossBackward0>)\n",
      "Step: 9 Loss: tensor(0.0390, grad_fn=<MseLossBackward0>)\n",
      "Step: 10 Loss: tensor(0.1366, grad_fn=<MseLossBackward0>)\n",
      "Step: 11 Loss: tensor(0.1018, grad_fn=<MseLossBackward0>)\n",
      "Step: 12 Loss: tensor(0.0586, grad_fn=<MseLossBackward0>)\n",
      "Step: 13 Loss: tensor(0.0428, grad_fn=<MseLossBackward0>)\n",
      "Step: 14 Loss: tensor(0.0884, grad_fn=<MseLossBackward0>)\n",
      "Step: 15 Loss: tensor(0.0963, grad_fn=<MseLossBackward0>)\n",
      "Step: 16 Loss: tensor(0.0882, grad_fn=<MseLossBackward0>)\n",
      "Step: 17 Loss: tensor(0.0628, grad_fn=<MseLossBackward0>)\n",
      "Step: 18 Loss: tensor(0.0415, grad_fn=<MseLossBackward0>)\n",
      "Step: 19 Loss: tensor(0.0995, grad_fn=<MseLossBackward0>)\n",
      "Step: 20 Loss: tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "Step: 21 Loss: tensor(0.1311, grad_fn=<MseLossBackward0>)\n",
      "Step: 22 Loss: tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "Step: 23 Loss: tensor(0.0561, grad_fn=<MseLossBackward0>)\n",
      "Step: 24 Loss: tensor(0.0455, grad_fn=<MseLossBackward0>)\n",
      "Step: 25 Loss: tensor(0.0877, grad_fn=<MseLossBackward0>)\n",
      "Step: 26 Loss: tensor(0.0511, grad_fn=<MseLossBackward0>)\n",
      "Step: 27 Loss: tensor(0.1212, grad_fn=<MseLossBackward0>)\n",
      "Step: 28 Loss: tensor(0.1174, grad_fn=<MseLossBackward0>)\n",
      "Step: 29 Loss: tensor(0.0899, grad_fn=<MseLossBackward0>)\n",
      "Step: 30 Loss: tensor(0.1170, grad_fn=<MseLossBackward0>)\n",
      "Step: 31 Loss: tensor(0.0806, grad_fn=<MseLossBackward0>)\n",
      "Step: 32 Loss: tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "Step: 33 Loss: tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "Step: 34 Loss: tensor(0.0414, grad_fn=<MseLossBackward0>)\n",
      "Step: 35 Loss: tensor(0.0726, grad_fn=<MseLossBackward0>)\n",
      "Step: 36 Loss: tensor(0.0822, grad_fn=<MseLossBackward0>)\n",
      "Step: 37 Loss: tensor(0.0533, grad_fn=<MseLossBackward0>)\n",
      "Step: 38 Loss: tensor(0.1173, grad_fn=<MseLossBackward0>)\n",
      "Step: 39 Loss: tensor(0.0966, grad_fn=<MseLossBackward0>)\n",
      "Step: 40 Loss: tensor(0.0698, grad_fn=<MseLossBackward0>)\n",
      "Step: 41 Loss: tensor(0.1160, grad_fn=<MseLossBackward0>)\n",
      "Step: 42 Loss: tensor(0.0795, grad_fn=<MseLossBackward0>)\n",
      "Step: 43 Loss: tensor(0.0579, grad_fn=<MseLossBackward0>)\n",
      "Mean: 0.08026\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(0.1258, grad_fn=<MseLossBackward0>)\n",
      "Step: 1 Loss: tensor(0.0989, grad_fn=<MseLossBackward0>)\n",
      "Step: 2 Loss: tensor(0.0961, grad_fn=<MseLossBackward0>)\n",
      "Step: 3 Loss: tensor(0.1100, grad_fn=<MseLossBackward0>)\n",
      "Step: 4 Loss: tensor(0.0910, grad_fn=<MseLossBackward0>)\n",
      "Step: 5 Loss: tensor(0.1081, grad_fn=<MseLossBackward0>)\n",
      "Step: 6 Loss: tensor(0.0827, grad_fn=<MseLossBackward0>)\n",
      "Step: 7 Loss: tensor(0.0710, grad_fn=<MseLossBackward0>)\n",
      "Step: 8 Loss: tensor(0.0495, grad_fn=<MseLossBackward0>)\n",
      "Step: 9 Loss: tensor(0.1041, grad_fn=<MseLossBackward0>)\n",
      "Step: 10 Loss: tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "Step: 11 Loss: tensor(0.0418, grad_fn=<MseLossBackward0>)\n",
      "Step: 12 Loss: tensor(0.0956, grad_fn=<MseLossBackward0>)\n",
      "Step: 13 Loss: tensor(0.1079, grad_fn=<MseLossBackward0>)\n",
      "Step: 14 Loss: tensor(0.0440, grad_fn=<MseLossBackward0>)\n",
      "Step: 15 Loss: tensor(0.0639, grad_fn=<MseLossBackward0>)\n",
      "Step: 16 Loss: tensor(0.0775, grad_fn=<MseLossBackward0>)\n",
      "Step: 17 Loss: tensor(0.0567, grad_fn=<MseLossBackward0>)\n",
      "Step: 18 Loss: tensor(0.0677, grad_fn=<MseLossBackward0>)\n",
      "Step: 19 Loss: tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "Step: 20 Loss: tensor(0.0444, grad_fn=<MseLossBackward0>)\n",
      "Step: 21 Loss: tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "Step: 22 Loss: tensor(0.0367, grad_fn=<MseLossBackward0>)\n",
      "Step: 23 Loss: tensor(0.0754, grad_fn=<MseLossBackward0>)\n",
      "Step: 24 Loss: tensor(0.0574, grad_fn=<MseLossBackward0>)\n",
      "Step: 25 Loss: tensor(0.0706, grad_fn=<MseLossBackward0>)\n",
      "Step: 26 Loss: tensor(0.0869, grad_fn=<MseLossBackward0>)\n",
      "Step: 27 Loss: tensor(0.0383, grad_fn=<MseLossBackward0>)\n",
      "Step: 28 Loss: tensor(0.0384, grad_fn=<MseLossBackward0>)\n",
      "Step: 29 Loss: tensor(0.1077, grad_fn=<MseLossBackward0>)\n",
      "Step: 30 Loss: tensor(0.0573, grad_fn=<MseLossBackward0>)\n",
      "Step: 31 Loss: tensor(0.0842, grad_fn=<MseLossBackward0>)\n",
      "Step: 32 Loss: tensor(0.0520, grad_fn=<MseLossBackward0>)\n",
      "Step: 33 Loss: tensor(0.0576, grad_fn=<MseLossBackward0>)\n",
      "Step: 34 Loss: tensor(0.0540, grad_fn=<MseLossBackward0>)\n",
      "Step: 35 Loss: tensor(0.0722, grad_fn=<MseLossBackward0>)\n",
      "Step: 36 Loss: tensor(0.0931, grad_fn=<MseLossBackward0>)\n",
      "Step: 37 Loss: tensor(0.0903, grad_fn=<MseLossBackward0>)\n",
      "Step: 38 Loss: tensor(0.1261, grad_fn=<MseLossBackward0>)\n",
      "Step: 39 Loss: tensor(0.0778, grad_fn=<MseLossBackward0>)\n",
      "Step: 40 Loss: tensor(0.0722, grad_fn=<MseLossBackward0>)\n",
      "Step: 41 Loss: tensor(0.0516, grad_fn=<MseLossBackward0>)\n",
      "Step: 42 Loss: tensor(0.1112, grad_fn=<MseLossBackward0>)\n",
      "Step: 43 Loss: tensor(0.1412, grad_fn=<MseLossBackward0>)\n",
      "Mean: 0.07651\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Testing the experiment class\n",
    "net0 = CDNN(hist=4)\n",
    "optim = torch.optim.Adam(net0.parameters(), lr=1e-3)\n",
    "\n",
    "exp0 = Experiment(name=\"Bezenac_MSE_small_1\",                           # de Bezenac model, trained on MSE Loss\n",
    "                  trainset=training_loader, valset=None, testset=None,  # data loaders\n",
    "                  model=net0,                                           # model with 4 days of history\n",
    "                  loss_fn=nn.MSELoss(reduction=\"mean\"),                 # loss function for training\n",
    "                  regloss=False,                                        # whether to regularize the training loss  \n",
    "                  test_loss=nn.MSELoss(reduction=\"mean\"),               # loss function for testing\n",
    "                  optimizer=optim,\n",
    "                  examples=None,\n",
    "                  outdir=path)\n",
    "\n",
    "exp0.run(epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beab998",
   "metadata": {},
   "source": [
    "### Training with (Unregularized) Charbonnier Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "858610d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new directory to save model states and results: /projectnb/labci/Lucia/rainfall-pde-ml/experiments/2023-09-12/Bezenac_Charb_small_1\n",
      "Running experiment: Bezenac_Charb_small_1...\n",
      "Training over 5 epochs...\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(5275.2524, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 1 Loss: tensor(20796.7480, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 2 Loss: tensor(24952.6816, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 3 Loss: tensor(41753.5625, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 4 Loss: tensor(38794.9336, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 5 Loss: tensor(37463.3203, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 6 Loss: tensor(51404.4883, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 7 Loss: tensor(50576.2383, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 8 Loss: tensor(37801.4219, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 9 Loss: tensor(38558.2969, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 10 Loss: tensor(48142.8594, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 11 Loss: tensor(48015.6836, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 12 Loss: tensor(70588.0703, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 13 Loss: tensor(57353.7773, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 14 Loss: tensor(81415.8672, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 15 Loss: tensor(68085.1406, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 16 Loss: tensor(70964.4141, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 17 Loss: tensor(79103.7266, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 18 Loss: tensor(70271.7891, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 19 Loss: tensor(59731.8477, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 20 Loss: tensor(58392.6602, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 21 Loss: tensor(66138.3984, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 22 Loss: tensor(84533.1562, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 23 Loss: tensor(73874.3047, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 24 Loss: tensor(82367.2422, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 25 Loss: tensor(90585.8828, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 26 Loss: tensor(29833.1816, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 27 Loss: tensor(84929.7500, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 28 Loss: tensor(84364.2109, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 29 Loss: tensor(86829.2734, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 30 Loss: tensor(60696.6055, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 31 Loss: tensor(76175.8750, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 32 Loss: tensor(85431.5625, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 33 Loss: tensor(69756.4141, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 34 Loss: tensor(72413.3750, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 35 Loss: tensor(105487.7266, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 36 Loss: tensor(83356.0703, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 37 Loss: tensor(79450.5156, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 38 Loss: tensor(63910.0352, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 39 Loss: tensor(79814.0469, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 40 Loss: tensor(84594.5234, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 41 Loss: tensor(62539.8867, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 42 Loss: tensor(75746.1328, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 43 Loss: tensor(72230.1406, grad_fn=<Charbonnier_LossBackward>)\n",
      "Mean: 63965.93387\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(78886.4688, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 1 Loss: tensor(65871.6953, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 2 Loss: tensor(91198.2109, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 3 Loss: tensor(63476.9180, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 4 Loss: tensor(59051.9414, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 5 Loss: tensor(67185.1797, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 6 Loss: tensor(89658.3984, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 7 Loss: tensor(86609.5078, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 8 Loss: tensor(84221.1641, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 9 Loss: tensor(54526.6133, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 10 Loss: tensor(89443.0391, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 11 Loss: tensor(70305.0547, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 12 Loss: tensor(70219.9375, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 13 Loss: tensor(74431.0781, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 14 Loss: tensor(88522.5703, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 15 Loss: tensor(90051.4141, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 16 Loss: tensor(88894.0625, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 17 Loss: tensor(55156.0312, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 18 Loss: tensor(85274.6797, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 19 Loss: tensor(96249.2266, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 20 Loss: tensor(89579.0703, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 21 Loss: tensor(75335.2891, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 22 Loss: tensor(61399.3594, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 23 Loss: tensor(71854.2266, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 24 Loss: tensor(97313.8047, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 25 Loss: tensor(77678.6250, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 26 Loss: tensor(70737.2188, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 27 Loss: tensor(52403.5625, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 28 Loss: tensor(68188.2422, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 29 Loss: tensor(71816.3750, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 30 Loss: tensor(66725.7031, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 31 Loss: tensor(95867.1875, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 32 Loss: tensor(87493.4375, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 33 Loss: tensor(89923.1562, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 34 Loss: tensor(71483.6172, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 35 Loss: tensor(66831.0469, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 36 Loss: tensor(96264.4609, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 37 Loss: tensor(89861.1797, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 38 Loss: tensor(88470.4922, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 39 Loss: tensor(81272.9141, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 40 Loss: tensor(79452.9141, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 41 Loss: tensor(61938.3594, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 42 Loss: tensor(83337.0859, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 43 Loss: tensor(73302.2266, grad_fn=<Charbonnier_LossBackward>)\n",
      "Mean: 77676.42605\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(65151.9375, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 1 Loss: tensor(71781.5156, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 2 Loss: tensor(63775.6992, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 3 Loss: tensor(69758.8203, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 4 Loss: tensor(70212.8047, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 5 Loss: tensor(78133.8125, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 6 Loss: tensor(85307.9141, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 7 Loss: tensor(88709.2812, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 8 Loss: tensor(87383.0859, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 9 Loss: tensor(109023.4688, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 10 Loss: tensor(67112.5859, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 11 Loss: tensor(84547.9141, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 12 Loss: tensor(72426.1797, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 13 Loss: tensor(85683.0625, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 14 Loss: tensor(56118.0117, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 15 Loss: tensor(70391.8359, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 16 Loss: tensor(76704.7188, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 17 Loss: tensor(48660.5195, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 18 Loss: tensor(73333.7812, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 19 Loss: tensor(71984.6562, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 20 Loss: tensor(76265.1172, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 21 Loss: tensor(104330.1484, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 22 Loss: tensor(59577.3750, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 23 Loss: tensor(80120.3984, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 24 Loss: tensor(93928.6484, grad_fn=<Charbonnier_LossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 25 Loss: tensor(63875.0312, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 26 Loss: tensor(60216.3086, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 27 Loss: tensor(96022.6484, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 28 Loss: tensor(87971.2891, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 29 Loss: tensor(86316.3984, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 30 Loss: tensor(99320.4297, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 31 Loss: tensor(74332.5312, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 32 Loss: tensor(91666.6875, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 33 Loss: tensor(63827.7930, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 34 Loss: tensor(74935.6641, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 35 Loss: tensor(96614.4141, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 36 Loss: tensor(83342.0078, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 37 Loss: tensor(75169.4297, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 38 Loss: tensor(94695.8047, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 39 Loss: tensor(61152.0508, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 40 Loss: tensor(80409.8125, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 41 Loss: tensor(87093.8906, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 42 Loss: tensor(67754.6953, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 43 Loss: tensor(90523.1875, grad_fn=<Charbonnier_LossBackward>)\n",
      "Mean: 78310.53107\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(72103.4609, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 1 Loss: tensor(94518.9297, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 2 Loss: tensor(92369.9062, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 3 Loss: tensor(70925.1953, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 4 Loss: tensor(93021.5391, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 5 Loss: tensor(82945.4844, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 6 Loss: tensor(102931.9141, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 7 Loss: tensor(85274.4766, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 8 Loss: tensor(84044.5547, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 9 Loss: tensor(104668.3750, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 10 Loss: tensor(76540.5078, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 11 Loss: tensor(96285.7734, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 12 Loss: tensor(68516.9062, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 13 Loss: tensor(73756.4609, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 14 Loss: tensor(70236.5547, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 15 Loss: tensor(68224.9297, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 16 Loss: tensor(72110., grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 17 Loss: tensor(91222.8828, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 18 Loss: tensor(79777.9531, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 19 Loss: tensor(86986.1719, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 20 Loss: tensor(81887.3828, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 21 Loss: tensor(47165.3086, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 22 Loss: tensor(61137.8438, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 23 Loss: tensor(81944.7891, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 24 Loss: tensor(80767.0859, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 25 Loss: tensor(84943.9375, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 26 Loss: tensor(69934.5469, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 27 Loss: tensor(59656.0469, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 28 Loss: tensor(74513.3438, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 29 Loss: tensor(75508.5000, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 30 Loss: tensor(90012.6484, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 31 Loss: tensor(63975.8320, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 32 Loss: tensor(78644.0078, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 33 Loss: tensor(61489.2930, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 34 Loss: tensor(104292.7734, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 35 Loss: tensor(76862.8359, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 36 Loss: tensor(86853.2578, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 37 Loss: tensor(55384.7227, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 38 Loss: tensor(70033.0938, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 39 Loss: tensor(68698.7656, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 40 Loss: tensor(56596.3008, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 41 Loss: tensor(96299.6641, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 42 Loss: tensor(72552.2031, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 43 Loss: tensor(75781.8672, grad_fn=<Charbonnier_LossBackward>)\n",
      "Mean: 78213.59153\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(65766.8438, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 1 Loss: tensor(85485.5156, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 2 Loss: tensor(122166.2422, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 3 Loss: tensor(74060.3438, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 4 Loss: tensor(67109.7422, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 5 Loss: tensor(80271.3203, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 6 Loss: tensor(63530.4062, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 7 Loss: tensor(106594.6797, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 8 Loss: tensor(76624.8438, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 9 Loss: tensor(90385.5391, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 10 Loss: tensor(71890.0859, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 11 Loss: tensor(81124.8281, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 12 Loss: tensor(91781.3125, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 13 Loss: tensor(75500.5156, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 14 Loss: tensor(88155.9922, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 15 Loss: tensor(90669.4297, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 16 Loss: tensor(96892.0391, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 17 Loss: tensor(81949.7422, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 18 Loss: tensor(62438.2344, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 19 Loss: tensor(97147.5859, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 20 Loss: tensor(66529.9531, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 21 Loss: tensor(69678.1172, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 22 Loss: tensor(71350.8359, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 23 Loss: tensor(74629.9844, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 24 Loss: tensor(86661.4766, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 25 Loss: tensor(57712.6367, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 26 Loss: tensor(77580.3359, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 27 Loss: tensor(70229.6953, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 28 Loss: tensor(54823.6445, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 29 Loss: tensor(79968.6797, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 30 Loss: tensor(76230.6016, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 31 Loss: tensor(101168.5000, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 32 Loss: tensor(71222.6641, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 33 Loss: tensor(64952.2773, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 34 Loss: tensor(82782.5781, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 35 Loss: tensor(85678.3516, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 36 Loss: tensor(69167.9141, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 37 Loss: tensor(85348.4375, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 38 Loss: tensor(77287.6562, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 39 Loss: tensor(90169.6562, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 40 Loss: tensor(54265.8125, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 41 Loss: tensor(52661.9727, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 42 Loss: tensor(78663.9453, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 43 Loss: tensor(78628.4062, grad_fn=<Charbonnier_LossBackward>)\n",
      "Mean: 78339.53125\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net1 = CDNN(hist=4)\n",
    "optim = torch.optim.Adam(net1.parameters(), lr=1e-3)\n",
    "\n",
    "exp1 = Experiment(name=\"Bezenac_Charb_small_1\",                         # de Bezenac model, trained on Regularized Charb Loss\n",
    "                  trainset=training_loader, valset=None, testset=None,  # data loaders\n",
    "                  model=net1,                                           # model with 4 days of history\n",
    "                  loss_fn=Charbonnier_Loss.apply,                       # loss function for training\n",
    "                  regloss=False,                                        # whether to regularize the training loss \n",
    "                  test_loss=nn.MSELoss(reduction=\"mean\"),               # loss function for testing\n",
    "                  optimizer=optim,\n",
    "                  examples=None,\n",
    "                  outdir=path)\n",
    "\n",
    "exp1.run(epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a1ca72",
   "metadata": {},
   "source": [
    "### Training with (Regularized) Charbonnier Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09f43a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new directory to save model states and results: /projectnb/labci/Lucia/rainfall-pde-ml/experiments/2023-09-12/Bezenac_CharbReg_small_2\n",
      "Running experiment: Bezenac_CharbReg_small_2...\n",
      "Training over 5 epochs...\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(12684.2441, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 1 Loss: tensor(38680.3672, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 2 Loss: tensor(67944.5000, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 3 Loss: tensor(58888.1445, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 4 Loss: tensor(82364.1562, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 5 Loss: tensor(94407.7656, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 6 Loss: tensor(95368.1094, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 7 Loss: tensor(88148.5781, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 8 Loss: tensor(102624.1562, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 9 Loss: tensor(92678.7500, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 10 Loss: tensor(103349.8047, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 11 Loss: tensor(111783.1406, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 12 Loss: tensor(88508.8516, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 13 Loss: tensor(84256.6719, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 14 Loss: tensor(111502.5156, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 15 Loss: tensor(132135.5156, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 16 Loss: tensor(73290.6484, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 17 Loss: tensor(109341.8672, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 18 Loss: tensor(90574.9375, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 19 Loss: tensor(96279.4141, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 20 Loss: tensor(119853.3984, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 21 Loss: tensor(141705., grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 22 Loss: tensor(110809.2422, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 23 Loss: tensor(98088.5625, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 24 Loss: tensor(95823.8906, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 25 Loss: tensor(84496.9766, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 26 Loss: tensor(97464.1250, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 27 Loss: tensor(67367.3281, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 28 Loss: tensor(116949.8359, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 29 Loss: tensor(126894.9375, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 30 Loss: tensor(94912.7656, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 31 Loss: tensor(125653.1094, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 32 Loss: tensor(114505.6562, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 33 Loss: tensor(100070.5938, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 34 Loss: tensor(111188.8594, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 35 Loss: tensor(113937., grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 36 Loss: tensor(107026., grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 37 Loss: tensor(132521.0312, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 38 Loss: tensor(105967.5625, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 39 Loss: tensor(116228.3125, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 40 Loss: tensor(153034.0625, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 41 Loss: tensor(116339.1250, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 42 Loss: tensor(85643.7500, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 43 Loss: tensor(116965.8281, grad_fn=<Charbonnier_LossBackward>)\n",
      "Mean: 99733.16118\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(150195.3125, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 1 Loss: tensor(137561.5000, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 2 Loss: tensor(126643.1562, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 3 Loss: tensor(116674.6250, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 4 Loss: tensor(112115.1953, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 5 Loss: tensor(118773.4375, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 6 Loss: tensor(96584.6562, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 7 Loss: tensor(126864.1250, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 8 Loss: tensor(113708.8281, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 9 Loss: tensor(97125.3438, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 10 Loss: tensor(110585.7188, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 11 Loss: tensor(129444.0156, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 12 Loss: tensor(131908.5312, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 13 Loss: tensor(118195.3516, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 14 Loss: tensor(123436.9219, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 15 Loss: tensor(139755.8750, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 16 Loss: tensor(127833.5625, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 17 Loss: tensor(129725.1172, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 18 Loss: tensor(147318.9219, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 19 Loss: tensor(139111.2656, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 20 Loss: tensor(118315.8594, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 21 Loss: tensor(137592.4531, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 22 Loss: tensor(111005.1406, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 23 Loss: tensor(133188., grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 24 Loss: tensor(147847.9375, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 25 Loss: tensor(124917.6406, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 26 Loss: tensor(130141.8516, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 27 Loss: tensor(105909.1094, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 28 Loss: tensor(119934.1719, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 29 Loss: tensor(117853.3203, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 30 Loss: tensor(85980.2422, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 31 Loss: tensor(125420.4062, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 32 Loss: tensor(113931.0312, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 33 Loss: tensor(126256.1016, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 34 Loss: tensor(106049.1094, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 35 Loss: tensor(113394.3281, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 36 Loss: tensor(116205.5469, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 37 Loss: tensor(108605.7188, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 38 Loss: tensor(122262.5625, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 39 Loss: tensor(130911.6328, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 40 Loss: tensor(147049.3281, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 41 Loss: tensor(118997.3125, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 42 Loss: tensor(120420.3906, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 43 Loss: tensor(111042.6250, grad_fn=<Charbonnier_LossBackward>)\n",
      "Mean: 122427.12003\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(100040.1797, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 1 Loss: tensor(125320.9531, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 2 Loss: tensor(138179.0781, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 3 Loss: tensor(130791.7344, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 4 Loss: tensor(115878.4766, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 5 Loss: tensor(124534.4219, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 6 Loss: tensor(127153.5859, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 7 Loss: tensor(142103.3281, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 8 Loss: tensor(100621.8828, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 9 Loss: tensor(124826.3594, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 10 Loss: tensor(107681.9922, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 11 Loss: tensor(117491.4844, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 12 Loss: tensor(125981.2031, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 13 Loss: tensor(119821.8281, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 14 Loss: tensor(136388.0312, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 15 Loss: tensor(109987.9531, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 16 Loss: tensor(125411.9609, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 17 Loss: tensor(120041.8984, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 18 Loss: tensor(129713.7188, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 19 Loss: tensor(127484.2812, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 20 Loss: tensor(100574.8281, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 21 Loss: tensor(117202.1953, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 22 Loss: tensor(89294.9141, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 23 Loss: tensor(116656.6562, grad_fn=<Charbonnier_LossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 24 Loss: tensor(136644.8906, grad_fn=<Charbonnier_LossBackward>)\n",
      "Step: 25 Loss: tensor(135744.8281, grad_fn=<Charbonnier_LossBackward>)\n"
     ]
    }
   ],
   "source": [
    "net2 = CDNN(hist=4)\n",
    "optim = torch.optim.Adam(net2.parameters(), lr=1e-3)\n",
    "\n",
    "exp2 = Experiment(name=\"Bezenac_CharbReg_small_2\",                      # de Bezenac model, trained on Regularized Charb Loss\n",
    "                  trainset=training_loader, valset=None, testset=None,  # data loaders\n",
    "                  model=net2,                                           # model with 4 days of history\n",
    "                  loss_fn=Charbonnier_Loss.apply,                       # loss function for training\n",
    "                  regloss=True,                                         # whether to regularize the training loss \n",
    "                  test_loss=nn.MSELoss(reduction=\"mean\"),               # loss function for testing\n",
    "                  optimizer=optim,\n",
    "                  examples=None,\n",
    "                  outdir=path)\n",
    "\n",
    "exp2.run(epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff8b067",
   "metadata": {},
   "source": [
    "### Training with Difference Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8dbbcb5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new directory to save model states and results: /projectnb/labci/Lucia/rainfall-pde-ml/experiments/2023-09-13/Bezenac_Diff_small_0\n",
      "Running experiment: Bezenac_Diff_small_0...\n",
      "Training over 5 epochs...\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(28.6109, grad_fn=<SqrtBackward0>)\n",
      "Step: 1 Loss: tensor(43.5181, grad_fn=<SqrtBackward0>)\n",
      "Step: 2 Loss: tensor(23.1119, grad_fn=<SqrtBackward0>)\n",
      "Step: 3 Loss: tensor(18.1813, grad_fn=<SqrtBackward0>)\n",
      "Step: 4 Loss: tensor(12.0314, grad_fn=<SqrtBackward0>)\n",
      "Step: 5 Loss: tensor(7.5877, grad_fn=<SqrtBackward0>)\n",
      "Step: 6 Loss: tensor(3.2420, grad_fn=<SqrtBackward0>)\n",
      "Step: 7 Loss: tensor(3.6426, grad_fn=<SqrtBackward0>)\n",
      "Step: 8 Loss: tensor(3.2129, grad_fn=<SqrtBackward0>)\n",
      "Step: 9 Loss: tensor(2.8115, grad_fn=<SqrtBackward0>)\n",
      "Step: 10 Loss: tensor(3.0457, grad_fn=<SqrtBackward0>)\n",
      "Step: 11 Loss: tensor(2.2204, grad_fn=<SqrtBackward0>)\n",
      "Step: 12 Loss: tensor(2.7609, grad_fn=<SqrtBackward0>)\n",
      "Step: 13 Loss: tensor(2.0906, grad_fn=<SqrtBackward0>)\n",
      "Step: 14 Loss: tensor(2.4743, grad_fn=<SqrtBackward0>)\n",
      "Step: 15 Loss: tensor(2.4428, grad_fn=<SqrtBackward0>)\n",
      "Step: 16 Loss: tensor(1.8038, grad_fn=<SqrtBackward0>)\n",
      "Step: 17 Loss: tensor(2.3745, grad_fn=<SqrtBackward0>)\n",
      "Step: 18 Loss: tensor(2.2092, grad_fn=<SqrtBackward0>)\n",
      "Step: 19 Loss: tensor(1.6923, grad_fn=<SqrtBackward0>)\n",
      "Step: 20 Loss: tensor(1.6041, grad_fn=<SqrtBackward0>)\n",
      "Step: 21 Loss: tensor(1.9928, grad_fn=<SqrtBackward0>)\n",
      "Step: 22 Loss: tensor(2.0742, grad_fn=<SqrtBackward0>)\n",
      "Step: 23 Loss: tensor(2.6786, grad_fn=<SqrtBackward0>)\n",
      "Step: 24 Loss: tensor(1.7027, grad_fn=<SqrtBackward0>)\n",
      "Step: 25 Loss: tensor(1.3140, grad_fn=<SqrtBackward0>)\n",
      "Step: 26 Loss: tensor(2.0002, grad_fn=<SqrtBackward0>)\n",
      "Step: 27 Loss: tensor(1.6691, grad_fn=<SqrtBackward0>)\n",
      "Step: 28 Loss: tensor(2.0311, grad_fn=<SqrtBackward0>)\n",
      "Step: 29 Loss: tensor(2.4467, grad_fn=<SqrtBackward0>)\n",
      "Step: 30 Loss: tensor(1.3634, grad_fn=<SqrtBackward0>)\n",
      "Step: 31 Loss: tensor(1.9045, grad_fn=<SqrtBackward0>)\n",
      "Step: 32 Loss: tensor(2.1456, grad_fn=<SqrtBackward0>)\n",
      "Step: 33 Loss: tensor(2.5695, grad_fn=<SqrtBackward0>)\n",
      "Step: 34 Loss: tensor(2.4634, grad_fn=<SqrtBackward0>)\n",
      "Step: 35 Loss: tensor(2.3934, grad_fn=<SqrtBackward0>)\n",
      "Step: 36 Loss: tensor(2.1058, grad_fn=<SqrtBackward0>)\n",
      "Step: 37 Loss: tensor(2.4240, grad_fn=<SqrtBackward0>)\n",
      "Step: 38 Loss: tensor(1.6543, grad_fn=<SqrtBackward0>)\n",
      "Step: 39 Loss: tensor(1.3485, grad_fn=<SqrtBackward0>)\n",
      "Step: 40 Loss: tensor(2.2051, grad_fn=<SqrtBackward0>)\n",
      "Step: 41 Loss: tensor(1.8982, grad_fn=<SqrtBackward0>)\n",
      "Step: 42 Loss: tensor(1.7663, grad_fn=<SqrtBackward0>)\n",
      "Step: 43 Loss: tensor(2.0672, grad_fn=<SqrtBackward0>)\n",
      "Mean: 4.92926\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(1.6592, grad_fn=<SqrtBackward0>)\n",
      "Step: 1 Loss: tensor(1.4886, grad_fn=<SqrtBackward0>)\n",
      "Step: 2 Loss: tensor(3.0327, grad_fn=<SqrtBackward0>)\n",
      "Step: 3 Loss: tensor(1.5056, grad_fn=<SqrtBackward0>)\n",
      "Step: 4 Loss: tensor(1.2065, grad_fn=<SqrtBackward0>)\n",
      "Step: 5 Loss: tensor(1.4560, grad_fn=<SqrtBackward0>)\n",
      "Step: 6 Loss: tensor(2.0183, grad_fn=<SqrtBackward0>)\n",
      "Step: 7 Loss: tensor(1.8036, grad_fn=<SqrtBackward0>)\n",
      "Step: 8 Loss: tensor(2.6312, grad_fn=<SqrtBackward0>)\n",
      "Step: 9 Loss: tensor(1.8141, grad_fn=<SqrtBackward0>)\n",
      "Step: 10 Loss: tensor(2.3946, grad_fn=<SqrtBackward0>)\n",
      "Step: 11 Loss: tensor(1.4988, grad_fn=<SqrtBackward0>)\n",
      "Step: 12 Loss: tensor(1.9200, grad_fn=<SqrtBackward0>)\n",
      "Step: 13 Loss: tensor(1.9544, grad_fn=<SqrtBackward0>)\n",
      "Step: 14 Loss: tensor(2.3794, grad_fn=<SqrtBackward0>)\n",
      "Step: 15 Loss: tensor(1.7045, grad_fn=<SqrtBackward0>)\n",
      "Step: 16 Loss: tensor(1.9701, grad_fn=<SqrtBackward0>)\n",
      "Step: 17 Loss: tensor(2.1852, grad_fn=<SqrtBackward0>)\n",
      "Step: 18 Loss: tensor(2.3961, grad_fn=<SqrtBackward0>)\n",
      "Step: 19 Loss: tensor(2.4630, grad_fn=<SqrtBackward0>)\n",
      "Step: 20 Loss: tensor(2.5106, grad_fn=<SqrtBackward0>)\n",
      "Step: 21 Loss: tensor(1.8307, grad_fn=<SqrtBackward0>)\n",
      "Step: 22 Loss: tensor(1.8984, grad_fn=<SqrtBackward0>)\n",
      "Step: 23 Loss: tensor(2.2665, grad_fn=<SqrtBackward0>)\n",
      "Step: 24 Loss: tensor(2.0251, grad_fn=<SqrtBackward0>)\n",
      "Step: 25 Loss: tensor(1.2319, grad_fn=<SqrtBackward0>)\n",
      "Step: 26 Loss: tensor(2.5994, grad_fn=<SqrtBackward0>)\n",
      "Step: 27 Loss: tensor(1.9290, grad_fn=<SqrtBackward0>)\n",
      "Step: 28 Loss: tensor(1.8402, grad_fn=<SqrtBackward0>)\n",
      "Step: 29 Loss: tensor(1.7780, grad_fn=<SqrtBackward0>)\n",
      "Step: 30 Loss: tensor(2.4028, grad_fn=<SqrtBackward0>)\n",
      "Step: 31 Loss: tensor(2.4069, grad_fn=<SqrtBackward0>)\n",
      "Step: 32 Loss: tensor(2.1633, grad_fn=<SqrtBackward0>)\n",
      "Step: 33 Loss: tensor(2.8853, grad_fn=<SqrtBackward0>)\n",
      "Step: 34 Loss: tensor(2.1617, grad_fn=<SqrtBackward0>)\n",
      "Step: 35 Loss: tensor(1.3239, grad_fn=<SqrtBackward0>)\n",
      "Step: 36 Loss: tensor(2.3815, grad_fn=<SqrtBackward0>)\n",
      "Step: 37 Loss: tensor(1.3053, grad_fn=<SqrtBackward0>)\n",
      "Step: 38 Loss: tensor(1.6936, grad_fn=<SqrtBackward0>)\n",
      "Step: 39 Loss: tensor(1.8219, grad_fn=<SqrtBackward0>)\n",
      "Step: 40 Loss: tensor(1.8487, grad_fn=<SqrtBackward0>)\n",
      "Step: 41 Loss: tensor(1.8422, grad_fn=<SqrtBackward0>)\n",
      "Step: 42 Loss: tensor(2.0651, grad_fn=<SqrtBackward0>)\n",
      "Step: 43 Loss: tensor(2.8900, grad_fn=<SqrtBackward0>)\n",
      "Mean: 2.01327\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(1.9730, grad_fn=<SqrtBackward0>)\n",
      "Step: 1 Loss: tensor(2.0136, grad_fn=<SqrtBackward0>)\n",
      "Step: 2 Loss: tensor(2.5645, grad_fn=<SqrtBackward0>)\n",
      "Step: 3 Loss: tensor(2.8490, grad_fn=<SqrtBackward0>)\n",
      "Step: 4 Loss: tensor(2.3459, grad_fn=<SqrtBackward0>)\n",
      "Step: 5 Loss: tensor(2.0600, grad_fn=<SqrtBackward0>)\n",
      "Step: 6 Loss: tensor(2.8278, grad_fn=<SqrtBackward0>)\n",
      "Step: 7 Loss: tensor(2.6016, grad_fn=<SqrtBackward0>)\n",
      "Step: 8 Loss: tensor(1.2974, grad_fn=<SqrtBackward0>)\n",
      "Step: 9 Loss: tensor(2.2982, grad_fn=<SqrtBackward0>)\n",
      "Step: 10 Loss: tensor(2.1264, grad_fn=<SqrtBackward0>)\n",
      "Step: 11 Loss: tensor(2.0186, grad_fn=<SqrtBackward0>)\n",
      "Step: 12 Loss: tensor(1.7973, grad_fn=<SqrtBackward0>)\n",
      "Step: 13 Loss: tensor(1.8804, grad_fn=<SqrtBackward0>)\n",
      "Step: 14 Loss: tensor(1.8812, grad_fn=<SqrtBackward0>)\n",
      "Step: 15 Loss: tensor(1.8585, grad_fn=<SqrtBackward0>)\n",
      "Step: 16 Loss: tensor(2.2211, grad_fn=<SqrtBackward0>)\n",
      "Step: 17 Loss: tensor(2.1809, grad_fn=<SqrtBackward0>)\n",
      "Step: 18 Loss: tensor(1.3942, grad_fn=<SqrtBackward0>)\n",
      "Step: 19 Loss: tensor(1.6074, grad_fn=<SqrtBackward0>)\n",
      "Step: 20 Loss: tensor(1.7854, grad_fn=<SqrtBackward0>)\n",
      "Step: 21 Loss: tensor(2.0700, grad_fn=<SqrtBackward0>)\n",
      "Step: 22 Loss: tensor(1.7443, grad_fn=<SqrtBackward0>)\n",
      "Step: 23 Loss: tensor(2.8317, grad_fn=<SqrtBackward0>)\n",
      "Step: 24 Loss: tensor(1.8133, grad_fn=<SqrtBackward0>)\n",
      "Step: 25 Loss: tensor(1.7220, grad_fn=<SqrtBackward0>)\n",
      "Step: 26 Loss: tensor(1.6826, grad_fn=<SqrtBackward0>)\n",
      "Step: 27 Loss: tensor(2.3364, grad_fn=<SqrtBackward0>)\n",
      "Step: 28 Loss: tensor(1.8116, grad_fn=<SqrtBackward0>)\n",
      "Step: 29 Loss: tensor(1.6797, grad_fn=<SqrtBackward0>)\n",
      "Step: 30 Loss: tensor(1.3329, grad_fn=<SqrtBackward0>)\n",
      "Step: 31 Loss: tensor(2.5014, grad_fn=<SqrtBackward0>)\n",
      "Step: 32 Loss: tensor(1.7332, grad_fn=<SqrtBackward0>)\n",
      "Step: 33 Loss: tensor(2.5687, grad_fn=<SqrtBackward0>)\n",
      "Step: 34 Loss: tensor(1.9450, grad_fn=<SqrtBackward0>)\n",
      "Step: 35 Loss: tensor(1.8919, grad_fn=<SqrtBackward0>)\n",
      "Step: 36 Loss: tensor(2.1617, grad_fn=<SqrtBackward0>)\n",
      "Step: 37 Loss: tensor(1.9489, grad_fn=<SqrtBackward0>)\n",
      "Step: 38 Loss: tensor(1.5115, grad_fn=<SqrtBackward0>)\n",
      "Step: 39 Loss: tensor(1.8360, grad_fn=<SqrtBackward0>)\n",
      "Step: 40 Loss: tensor(2.5927, grad_fn=<SqrtBackward0>)\n",
      "Step: 41 Loss: tensor(2.2864, grad_fn=<SqrtBackward0>)\n",
      "Step: 42 Loss: tensor(1.4651, grad_fn=<SqrtBackward0>)\n",
      "Step: 43 Loss: tensor(1.4617, grad_fn=<SqrtBackward0>)\n",
      "Mean: 2.01162\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(1.8483, grad_fn=<SqrtBackward0>)\n",
      "Step: 1 Loss: tensor(2.2392, grad_fn=<SqrtBackward0>)\n",
      "Step: 2 Loss: tensor(1.8972, grad_fn=<SqrtBackward0>)\n",
      "Step: 3 Loss: tensor(1.8730, grad_fn=<SqrtBackward0>)\n",
      "Step: 4 Loss: tensor(1.7455, grad_fn=<SqrtBackward0>)\n",
      "Step: 5 Loss: tensor(2.2911, grad_fn=<SqrtBackward0>)\n",
      "Step: 6 Loss: tensor(2.1564, grad_fn=<SqrtBackward0>)\n",
      "Step: 7 Loss: tensor(1.9366, grad_fn=<SqrtBackward0>)\n",
      "Step: 8 Loss: tensor(1.5742, grad_fn=<SqrtBackward0>)\n",
      "Step: 9 Loss: tensor(2.3865, grad_fn=<SqrtBackward0>)\n",
      "Step: 10 Loss: tensor(2.1009, grad_fn=<SqrtBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 11 Loss: tensor(1.4305, grad_fn=<SqrtBackward0>)\n",
      "Step: 12 Loss: tensor(2.2118, grad_fn=<SqrtBackward0>)\n",
      "Step: 13 Loss: tensor(1.3050, grad_fn=<SqrtBackward0>)\n",
      "Step: 14 Loss: tensor(2.0616, grad_fn=<SqrtBackward0>)\n",
      "Step: 15 Loss: tensor(1.7985, grad_fn=<SqrtBackward0>)\n",
      "Step: 16 Loss: tensor(2.0833, grad_fn=<SqrtBackward0>)\n",
      "Step: 17 Loss: tensor(2.3660, grad_fn=<SqrtBackward0>)\n",
      "Step: 18 Loss: tensor(1.4103, grad_fn=<SqrtBackward0>)\n",
      "Step: 19 Loss: tensor(2.7582, grad_fn=<SqrtBackward0>)\n",
      "Step: 20 Loss: tensor(3.0532, grad_fn=<SqrtBackward0>)\n",
      "Step: 21 Loss: tensor(1.3273, grad_fn=<SqrtBackward0>)\n",
      "Step: 22 Loss: tensor(2.6468, grad_fn=<SqrtBackward0>)\n",
      "Step: 23 Loss: tensor(2.2362, grad_fn=<SqrtBackward0>)\n",
      "Step: 24 Loss: tensor(2.3405, grad_fn=<SqrtBackward0>)\n",
      "Step: 25 Loss: tensor(1.6849, grad_fn=<SqrtBackward0>)\n",
      "Step: 26 Loss: tensor(1.6516, grad_fn=<SqrtBackward0>)\n",
      "Step: 27 Loss: tensor(1.6961, grad_fn=<SqrtBackward0>)\n",
      "Step: 28 Loss: tensor(2.1291, grad_fn=<SqrtBackward0>)\n",
      "Step: 29 Loss: tensor(1.7747, grad_fn=<SqrtBackward0>)\n",
      "Step: 30 Loss: tensor(1.7728, grad_fn=<SqrtBackward0>)\n",
      "Step: 31 Loss: tensor(1.9372, grad_fn=<SqrtBackward0>)\n",
      "Step: 32 Loss: tensor(1.8065, grad_fn=<SqrtBackward0>)\n",
      "Step: 33 Loss: tensor(1.6331, grad_fn=<SqrtBackward0>)\n",
      "Step: 34 Loss: tensor(2.3980, grad_fn=<SqrtBackward0>)\n",
      "Step: 35 Loss: tensor(1.2269, grad_fn=<SqrtBackward0>)\n",
      "Step: 36 Loss: tensor(2.1369, grad_fn=<SqrtBackward0>)\n",
      "Step: 37 Loss: tensor(1.8615, grad_fn=<SqrtBackward0>)\n",
      "Step: 38 Loss: tensor(2.6706, grad_fn=<SqrtBackward0>)\n",
      "Step: 39 Loss: tensor(1.9746, grad_fn=<SqrtBackward0>)\n",
      "Step: 40 Loss: tensor(2.3400, grad_fn=<SqrtBackward0>)\n",
      "Step: 41 Loss: tensor(2.1447, grad_fn=<SqrtBackward0>)\n",
      "Step: 42 Loss: tensor(2.4762, grad_fn=<SqrtBackward0>)\n",
      "Step: 43 Loss: tensor(2.0308, grad_fn=<SqrtBackward0>)\n",
      "Mean: 2.00964\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(2.1078, grad_fn=<SqrtBackward0>)\n",
      "Step: 1 Loss: tensor(1.7059, grad_fn=<SqrtBackward0>)\n",
      "Step: 2 Loss: tensor(2.5079, grad_fn=<SqrtBackward0>)\n",
      "Step: 3 Loss: tensor(3.0551, grad_fn=<SqrtBackward0>)\n",
      "Step: 4 Loss: tensor(1.7151, grad_fn=<SqrtBackward0>)\n",
      "Step: 5 Loss: tensor(1.6120, grad_fn=<SqrtBackward0>)\n",
      "Step: 6 Loss: tensor(2.2523, grad_fn=<SqrtBackward0>)\n",
      "Step: 7 Loss: tensor(2.1295, grad_fn=<SqrtBackward0>)\n",
      "Step: 8 Loss: tensor(2.7804, grad_fn=<SqrtBackward0>)\n",
      "Step: 9 Loss: tensor(2.5722, grad_fn=<SqrtBackward0>)\n",
      "Step: 10 Loss: tensor(1.8701, grad_fn=<SqrtBackward0>)\n",
      "Step: 11 Loss: tensor(2.4444, grad_fn=<SqrtBackward0>)\n",
      "Step: 12 Loss: tensor(2.2577, grad_fn=<SqrtBackward0>)\n",
      "Step: 13 Loss: tensor(1.9386, grad_fn=<SqrtBackward0>)\n",
      "Step: 14 Loss: tensor(1.7425, grad_fn=<SqrtBackward0>)\n",
      "Step: 15 Loss: tensor(3.4644, grad_fn=<SqrtBackward0>)\n",
      "Step: 16 Loss: tensor(2.2810, grad_fn=<SqrtBackward0>)\n",
      "Step: 17 Loss: tensor(1.8303, grad_fn=<SqrtBackward0>)\n",
      "Step: 18 Loss: tensor(1.0347, grad_fn=<SqrtBackward0>)\n",
      "Step: 19 Loss: tensor(2.0442, grad_fn=<SqrtBackward0>)\n",
      "Step: 20 Loss: tensor(1.1274, grad_fn=<SqrtBackward0>)\n",
      "Step: 21 Loss: tensor(2.8172, grad_fn=<SqrtBackward0>)\n",
      "Step: 22 Loss: tensor(2.6103, grad_fn=<SqrtBackward0>)\n",
      "Step: 23 Loss: tensor(2.1817, grad_fn=<SqrtBackward0>)\n",
      "Step: 24 Loss: tensor(1.5066, grad_fn=<SqrtBackward0>)\n",
      "Step: 25 Loss: tensor(1.7345, grad_fn=<SqrtBackward0>)\n",
      "Step: 26 Loss: tensor(1.9484, grad_fn=<SqrtBackward0>)\n",
      "Step: 27 Loss: tensor(1.7723, grad_fn=<SqrtBackward0>)\n",
      "Step: 28 Loss: tensor(1.9580, grad_fn=<SqrtBackward0>)\n",
      "Step: 29 Loss: tensor(2.2408, grad_fn=<SqrtBackward0>)\n",
      "Step: 30 Loss: tensor(1.5121, grad_fn=<SqrtBackward0>)\n",
      "Step: 31 Loss: tensor(1.9126, grad_fn=<SqrtBackward0>)\n",
      "Step: 32 Loss: tensor(2.0731, grad_fn=<SqrtBackward0>)\n",
      "Step: 33 Loss: tensor(1.8915, grad_fn=<SqrtBackward0>)\n",
      "Step: 34 Loss: tensor(0.9881, grad_fn=<SqrtBackward0>)\n",
      "Step: 35 Loss: tensor(2.2317, grad_fn=<SqrtBackward0>)\n",
      "Step: 36 Loss: tensor(1.5315, grad_fn=<SqrtBackward0>)\n",
      "Step: 37 Loss: tensor(1.9082, grad_fn=<SqrtBackward0>)\n",
      "Step: 38 Loss: tensor(2.0549, grad_fn=<SqrtBackward0>)\n",
      "Step: 39 Loss: tensor(1.2744, grad_fn=<SqrtBackward0>)\n",
      "Step: 40 Loss: tensor(1.3029, grad_fn=<SqrtBackward0>)\n",
      "Step: 41 Loss: tensor(1.9261, grad_fn=<SqrtBackward0>)\n",
      "Step: 42 Loss: tensor(1.3877, grad_fn=<SqrtBackward0>)\n",
      "Step: 43 Loss: tensor(2.0411, grad_fn=<SqrtBackward0>)\n",
      "Mean: 1.98362\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net3 = CDNN(hist=4)\n",
    "optim = torch.optim.Adam(net3.parameters(), lr=1e-3)\n",
    "\n",
    "exp3 = Experiment(name=\"Bezenac_Diff_small_0\",                          # de Bezenac model, trained on Diff Loss\n",
    "                  trainset=training_loader, valset=None, testset=None,  # data loaders\n",
    "                  model=net3,                                           # model with 4 days of history\n",
    "                  loss_fn=difference_loss,                              # loss function for training\n",
    "                  regloss=False,                                        # whether to regularize the training loss \n",
    "                  test_loss=nn.MSELoss(reduction=\"mean\"),               # loss function for testing\n",
    "                  optimizer=optim,\n",
    "                  examples=None,\n",
    "                  outdir=path)\n",
    "\n",
    "exp3.run(epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "218.182px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
