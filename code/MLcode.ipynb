{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e51c2d6",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports-and-setup-functions\" data-toc-modified-id=\"Imports-and-setup-functions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports and setup functions</a></span></li><li><span><a href=\"#DataLoader-Module\" data-toc-modified-id=\"DataLoader-Module-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>DataLoader Module</a></span><ul class=\"toc-item\"><li><span><a href=\"#Image-regions\" data-toc-modified-id=\"Image-regions-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Image regions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Find-interesting-regions-to-test-on\" data-toc-modified-id=\"Find-interesting-regions-to-test-on-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Find interesting regions to test on</a></span></li><li><span><a href=\"#Cut-all-data-into-64x64-regions\" data-toc-modified-id=\"Cut-all-data-into-64x64-regions-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Cut all data into 64x64 regions</a></span></li><li><span><a href=\"#Save-to-.npy-files\" data-toc-modified-id=\"Save-to-.npy-files-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Save to .npy files</a></span></li></ul></li><li><span><a href=\"#Train-val-test-split\" data-toc-modified-id=\"Train-val-test-split-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Train-val-test split</a></span></li><li><span><a href=\"#Inputs-and-ends\" data-toc-modified-id=\"Inputs-and-ends-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Inputs and ends</a></span></li><li><span><a href=\"#Tensors,-DataLoader\" data-toc-modified-id=\"Tensors,-DataLoader-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Tensors, DataLoader</a></span></li><li><span><a href=\"#Create-DataLoader-for-training-data\" data-toc-modified-id=\"Create-DataLoader-for-training-data-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Create DataLoader for training data</a></span></li></ul></li><li><span><a href=\"#Model-Module\" data-toc-modified-id=\"Model-Module-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Model Module</a></span><ul class=\"toc-item\"><li><span><a href=\"#AR1:-linear-mapping\" data-toc-modified-id=\"AR1:-linear-mapping-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>AR1: linear mapping</a></span></li><li><span><a href=\"#de-Bézenac-et-al,-2019:-CNN-with-warp-mapping\" data-toc-modified-id=\"de-Bézenac-et-al,-2019:-CNN-with-warp-mapping-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>de Bézenac et al, 2019: CNN with warp mapping</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loss-Function\" data-toc-modified-id=\"Loss-Function-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Loss Function</a></span></li><li><span><a href=\"#Warp\" data-toc-modified-id=\"Warp-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Warp</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Model</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-3.2.4\"><span class=\"toc-item-num\">3.2.4&nbsp;&nbsp;</span>Training</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb70983",
   "metadata": {},
   "source": [
    "# Imports and setup functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6754139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Function, Variable\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2088495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datadir(x):\n",
    "    return \"/projectnb/labci/Lucia/data/\" + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "248f8717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename):\n",
    "    torch.save(state, filename)  \n",
    "    print(\"State saved: \" + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f15e4f",
   "metadata": {},
   "source": [
    "# DataLoader Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a8f21d",
   "metadata": {},
   "source": [
    "## Train-val-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715c5887",
   "metadata": {},
   "source": [
    "The authors trained on SST data from 2006-2015 and tested on data from 2016-2017. For the IBI reanalysis SST data, we only have from June 5, 2021 to June 23, 2023 (749 days). From these, we will use 80% for training, 10% for validation, and 10% for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7d16162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_days(files):\n",
    "    \"\"\"Helper method to take a list of filenames and return total the number \n",
    "    of days represented by the files in the list. \n",
    "    \n",
    "    This method assumes a particular file naming convention that has been used \n",
    "    for this project. \n",
    "    \n",
    "    File naming convention: sst_geo_yyyymmdd.nc_region_XX.npy\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    files : list : data file names\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    delta : int : the number of days represented by the inputted files\n",
    "    \"\"\"\n",
    "    \n",
    "    files.sort()\n",
    "    \n",
    "    first = datetime.datetime.strptime(files[0][8:16], \"%Y%m%d\").date()\n",
    "    last = datetime.datetime.strptime(files[len(files)-1][8:16], \"%Y%m%d\").date()\n",
    "    \n",
    "    delta = int((last - first) / datetime.timedelta(days=1))\n",
    "    \n",
    "    return delta\n",
    "\n",
    "def train_val_test_cutoffs(topdir, split):\n",
    "    \"\"\"Helper method to create lists of filenames for the train, val, and test\n",
    "    data splits. Uses the dates in the filenames to determine file order and \n",
    "    split cutoffs.\n",
    "    \n",
    "    This method assumes a particular file naming convention that has been used \n",
    "    for this project. \n",
    "    \n",
    "    File naming convention: sst_geo_yyyymmdd.nc_region_XX.npy\n",
    "       \n",
    "    Parameters\n",
    "    ----------\n",
    "    topdir : string : the path to the directory holding the data\n",
    "    split : list : the fractions for each split, eg. [0.8, 0.1, 0.1]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    cutoffs : list : date cutoffs for each split\n",
    "    \"\"\"\n",
    "    \n",
    "    all_files = os.listdir(topdir)\n",
    "    all_files.sort()\n",
    "    nfiles = len(all_files)\n",
    "    ndays = all_days(all_files)\n",
    "    \n",
    "    start_date = datetime.datetime.strptime(all_files[0][8:16], \"%Y%m%d\").date()\n",
    "    end_date = datetime.datetime.strptime(all_files[nfiles-1][8:16], \"%Y%m%d\").date()\n",
    "    \n",
    "    cutoffs = []\n",
    "    \n",
    "    for i in range(3):\n",
    "        delta = math.floor(ndays*split[i])\n",
    "        end = start_date + datetime.timedelta(days=delta)\n",
    "        cutoffs.append(end)\n",
    "        \n",
    "        start_date = end\n",
    "        \n",
    "    # Because of rounding, some files may have been missed\n",
    "    # Add these to the test split\n",
    "    if cutoffs[2] < end_date:\n",
    "        cutoffs[2] = end_date\n",
    "    \n",
    "    return cutoffs\n",
    "\n",
    "def train_val_test_split_files(topdir, split):\n",
    "    \"\"\"Method to split the data in a directory into training, validation, and\n",
    "    test sets. Uses the helper method train_val_test_cutoffs().\n",
    "    \n",
    "    This method assumes a particular file naming convention that has been used \n",
    "    for this project. \n",
    "    \n",
    "    File naming convention: sst_geo_yyyymmdd.nc_region_XX.npy\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    topdir : string : the path to the directory holding the data\n",
    "    split : list : the fractions for each split, eg. [0.8, 0.1, 0.1]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    train : list : list of filenames for the train set\n",
    "    val : list : list of filenames for the validation set\n",
    "    test : list : list of filenames for the test set\n",
    "    \"\"\"\n",
    "    \n",
    "    assert len(split) == 3, \"Please include a % split for train, validation, and test sets.\"\n",
    "    \n",
    "    cutoffs = train_val_test_cutoffs(topdir, split)\n",
    "    \n",
    "    all_files = os.listdir(topdir)\n",
    "    all_files.sort()\n",
    "    \n",
    "    train, val, test = [], [], []\n",
    "    \n",
    "    for f in all_files:\n",
    "        file_date = datetime.datetime.strptime(f[8:16], \"%Y%m%d\").date()\n",
    "        \n",
    "        if file_date <= cutoffs[0]:\n",
    "            train.append(f)\n",
    "        elif (file_date > cutoffs[0]) & (file_date <= cutoffs[1]):\n",
    "            val.append(f)\n",
    "        else:\n",
    "            test.append(f)\n",
    "            \n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38bda7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_file(filename):\n",
    "    \"\"\"Helper method to load a single .npy file.\"\"\"\n",
    "    return np.load(datadir(\"sst_npy/\" + filename))\n",
    "\n",
    "\n",
    "def load_data_from_files(files):\n",
    "    \"\"\"Method to load data from a list of .npy files.\"\"\"\n",
    "    data = []\n",
    "    for f in files:\n",
    "        data.append(load_data_from_file(f))\n",
    "        \n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2117c9",
   "metadata": {},
   "source": [
    "## Inputs and ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5a6a4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_by_region(files, region):\n",
    "    \"\"\"Helper method to search a list of files for only those corresponding to\n",
    "    a desired region. \n",
    "    \n",
    "    This method assumes a particular file naming convention that has been used \n",
    "    for this project. \n",
    "    \n",
    "    File naming convention: sst_geo_yyyymmdd.nc_region_XX.npy\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    files : list : list of filenames in which to search\n",
    "    region : int : desired region\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    region_files : list : sorted list of matching files\n",
    "    \"\"\"\n",
    "    \n",
    "    region_files = []\n",
    "    for fname in files:\n",
    "        if \"region_\" + str(region) + \".npy\" in fname:\n",
    "            region_files.append(fname)\n",
    "            \n",
    "    region_files.sort()\n",
    "    \n",
    "    return region_files\n",
    "\n",
    "def get_pairs_by_region(files, region, ndays=1):\n",
    "    \"\"\"Method to separate data into inputs (X) and ends (y), for example to\n",
    "    use 4 previous days (ndays=4) to predict the next day. The \"pairs\" are \n",
    "    pairs of (X,y) inputs and ends. This method works on one region at a time.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    files : list : list of files from which to get pairs\n",
    "    region : int : desired region\n",
    "    ndays : int : number of days to use as inputs\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    inps : np.ndarray : filenames for inputs\n",
    "    ends : list : filenames for ends\n",
    "    \"\"\"\n",
    "    \n",
    "    region_files = search_by_region(files, region)\n",
    "    \n",
    "    n = len(region_files)\n",
    "    \n",
    "    inps = []\n",
    "    ends = region_files[ndays:]\n",
    "    \n",
    "    for i in range(n - ndays):\n",
    "        inps.append(region_files[i:i+ndays])\n",
    "    \n",
    "    return np.array(inps), np.array(ends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43858887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_regions(files):\n",
    "    \"\"\"Helper method to take a list of filenames and return a list of the \n",
    "    unique region numbers. \n",
    "    \n",
    "    This method assumes a particular file naming convention that has been used \n",
    "    for this project. \n",
    "    \n",
    "    File naming convention: sst_geo_yyyymmdd.nc_region_XX.npy\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    files : list : data file names\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    regions : list : list of unique region numbers in the directory\n",
    "    \"\"\"\n",
    "    \n",
    "    files.sort()\n",
    "    regions = []\n",
    "    \n",
    "    for f in files:\n",
    "        if \"region_\" in f:\n",
    "            \n",
    "            start_ind = f.find(\"region_\") + len(\"region_\")\n",
    "            end_ind = f.find(\".npy\")\n",
    "            \n",
    "            reg = f[start_ind:end_ind]\n",
    "            \n",
    "            if int(reg) not in regions:\n",
    "                regions.append(int(reg))\n",
    "            \n",
    "        else:\n",
    "            print(\"Files in this directory do not match the naming convention.\")\n",
    "    \n",
    "    regions.sort()\n",
    "    \n",
    "    return regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8510e497",
   "metadata": {},
   "source": [
    "## Tensors, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa7d662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_dataloader(dtype, batchsize, files, ndays):\n",
    "    \"\"\"Method to create a PyTorch DataLoader object from a list of files and\n",
    "    additional parameters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dtype : torch.dtype : the data type for the DataLoader\n",
    "    batchsize : int : the desired batchsize for loading data\n",
    "    files : str : a list of files holding data to put into the DataLoader\n",
    "    ndays : int : the number of days to use as inputs to predict the next day\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    training : torch.utils.data.DataLoader : the DataLoader object\n",
    "    \"\"\"\n",
    "    \n",
    "    regions = all_regions(files)\n",
    "\n",
    "    train_data = []\n",
    "    train_ends = []\n",
    "\n",
    "    for reg in regions:\n",
    "        train_reg_pairs = get_pairs_by_region(files, reg, ndays)\n",
    "        \n",
    "        for i in range(len(train_reg_pairs[0])):\n",
    "            dat = load_data_from_files(train_reg_pairs[0][i])\n",
    "            end = load_data_from_file(train_reg_pairs[1][i])\n",
    "        \n",
    "            train_data.append(dat)\n",
    "            train_ends.append(end)\n",
    "        \n",
    "    train_data = torch.from_numpy(np.array(train_data)).type(dtype)\n",
    "    train_ends = torch.from_numpy(np.array(train_ends)).type(dtype)\n",
    "    \n",
    "    training = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_data, train_ends),\n",
    "                                           batch_size=batchsize, shuffle=False)\n",
    "    \n",
    "    return training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727f10c7",
   "metadata": {},
   "source": [
    "## Create DataLoader for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d36e3b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28752\n",
      "3552\n",
      "3648\n"
     ]
    }
   ],
   "source": [
    "split = train_val_test_split_files(datadir(\"sst_npy/\"), [0.8, 0.1, 0.1])\n",
    "\n",
    "train_split = split[0]\n",
    "val_split   = split[1]\n",
    "test_split  = split[2]\n",
    "\n",
    "print(len(train_split))\n",
    "print(len(val_split))\n",
    "print(len(test_split))\n",
    "\n",
    "training_loader = create_training_dataloader(dtype=torch.FloatTensor, \n",
    "                                             batchsize=12, files=split[0], \n",
    "                                             ndays=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "251b1547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGfCAYAAAD22G0fAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABJJElEQVR4nO29f4wd1X3+/8zMvXf2h9drIPGu/Y3jOMmSgA0EMHUwaUxK7IomqMhSmgSSElWqIIYEl1YkxlJZIrJLiGQ5FcSV3QqMUtf/AC1VE7CrBNPKonGcWDiQj0OKA5uEzRZidtf27v0xc75/ONyyO+9ns8e+m7m7fl7SleB9j8+cM3Pmvu/see7zDpxzDkIIIUQOhHkPQAghxNmLkpAQQojcUBISQgiRG0pCQgghckNJSAghRG4oCQkhhMgNJSEhhBC5oSQkhBAiN5SEhBBC5IaSkBBCiNwozFTH3/zmN/H1r38dr776KpYvX46tW7fiD//wD3/nv0vTFL/61a/Q0dGBIAhmanhCCCFmCOccRkdHsXjxYoTh73jWcTPA7t27XbFYdDt27HAvvPCCu/322117e7t7+eWXf+e/HRgYcAD00ksvvfSa5a+BgYHf+ZkfONd4A9NVq1bhsssuw7Zt2+qxCy64ANdffz36+/un/LfDw8NYsGAB1iz4NApBaeKbSWL+G1erZWNV0pb0EZbsh8Jg/vxssLPDbFs7p82MV+cX7Xh7ZMfnZb85VOfZT4W1VjOMlDzjOqOb0D4lKJy046URe8kUT6RmPKxl26dFez7VNvtbU2W+3b5iXB4AqM3LHjNpscfnCuQWYF/gjG6CxB4fi4dVFidDKWfbR+N226hM+jCuAwAE5Prbje0wu55sHabGLZGUsjEASEv2uNN4+u1dZPdBr33A4nYYqfGGvdy810pQY+2NmH1IOLKWE3JuXVu280KbvTjb27MLLjlZxv/7i7/DG2+8gc7OTjKq3/Y75bunQaVSwcGDB/HlL395QnzdunXYv39/pn25XEa5/H+TGB0dPTWwoJRNQuRucUH2DLsgm5hYWwAIAztRBKFxZ0Rk9Rda7GMW7L5d0U5CaSk7xrRkLy9HhhI0IAlFLE4WbqFCkpBxQ9MPLWPuABDFdnt2KdIW44OoNYckRD5AwojF7UNGxscL+VwF6QJhOHNJKCDXk9xWdpwkIcRkouTaw0pC5Bo3VRJiyWYGk5Aj59a1ZjsP2+yVFdnfvU+NZxpbKg0XJrz22mtIkgRdXV0T4l1dXRgcHMy07+/vR2dnZ/21ZMmSRg9JCCFEkzJj6rjJGdA5Z2bFTZs2YXh4uP4aGBiYqSEJIYRoMhr+57i3ve1tiKIo89QzNDSUeToCgDiOEcfGc3WSZJ432X6OGXf2s3AQ2Y+UQYv9bG/F0xby5zXypyRXIH968vg7esr+xsLw+CtDWLHbRuPkz25lOx4m5NE+zM4zIXNPyJ9YEvsvnUjYnxOsP7P4ii3Zn1OMP734/4nF7tva+wHsa8SuW1gl14cc01wrbKeYfG0NyLVnf46xwgFZ4yE5h2yfpxGqWsfuN5+uPfehXKvnnwAbIB4OCvYiL5ayi6W1hewJxdmFWKuRxWnQ8CehUqmEyy+/HHv37p0Q37t3L1avXt3owwkhhJjFzMjvhO644w589rOfxcqVK3HllVdi+/bteOWVV3DLLbfMxOGEEELMUmYkCX3yk5/E66+/jq985St49dVXsWLFCnz729/G0qVLZ+JwQgghZikz5piwYcMGbNiwYaa6F0IIMQeQd5wQQojcmLEnoTPF1WqZH5a6KpH3WEo48qNUqoJrta0HXFtWlpW22uq4pGgfMyGqOaYQM39l7vl1IaA/lMvG2C/sC+QX+Ux9xRRVzphPQn58m5AfpSbkR4+Oxa3z5akmCqxf9gLkx6p2U/ZDYF/HhMhSx5Hbgf74lK0JD88UIjrlyjsq08zOn/2gkkN/mpmJpKwtm7unOtBZJ5Gp9HxVbURNZynbCkX74kdEBVco2O2Lxi/V46J9keNCNh4ZMYaehIQQQuSGkpAQQojcUBISQgiRG0pCQgghcqNphQnp2DjSadr7WlY8QYm4YrcRAcI82wo2bcta+6Yxcb+O7Zzua3Nv2dxQ2L4v2UC2NripPQ+Js5IAjjhDWyIEas9D7fntON3MtoZCz5XfprVl0cNte+w+aMkGsuRNx2RmleNbnMXaU/d0kGEFYfi3XOMfECGI/3yM65OSchDk2pPm1HInMNa+KVaYCrYOK8S2yFhzNdYH7IUYRfYHRWQ4rkdkPgXrw4Z9ABnoSUgIIURuKAkJIYTIDSUhIYQQuaEkJIQQIjeUhIQQQuRG06rjTsltJqoxgqItkbKseMJ2W+3GVHCu3a6aZhWwS4g6jtnzUBUcK5zl8dWA2sUQVVZhLKtwKRqxU334SaRSUrzPVscRVRJTwbFCYIaKh+KrsvJQzXGbJKL48rBVYu2p+MqjoCGLe4ibpmzPbH5s6yOiPCPXgZ2r1IinpDAeU2Oy+aQsXvIoosjWbAMeCRyZZ9XyzgKQMmsqg4Jh5QMAgbGArBhDT0JCCCFyQ0lICCFEbigJCSGEyA0lISGEELmhJCSEECI3mlYdF7bECIOJUilWeM7yg7OK0QFcBZewQnWGEs7XC46pxryKeLFiYswjrmyrUyKjUF1UYaok4rfFPOJIgTlLgUQ94nyK1AHUb8wy/wqIXIl1QdVk1jn39PBrSHvfgmw+cTo+P4mhj3qTeSampIgiEXwhNYo0snuWFXRkRRdTVoyxJTvGJCbjZvEiufjUr86SGNpd+KjVAKBWy95w5ap9wi1VcOLx4aYnISGEELmhJCSEECI3lISEEELkhpKQEEKI3FASEkIIkRvNq47r7EQYTjISayWKt5as4ZiLbZlV2kI8lFi1VEv5QT3iiKKGecTRMpXZEK3ESfzdCoYKDgAKhmqOKZhcwFSA0/eIY3FvFRyBin4M4RBrSqbJseR0nr50M1r9tCHecUwxSfpgca95EtUYs/Aja8XyZGRtqaKVKj3P3B/RUtKdipPPlRb75Dqj/6Bkt2XxkMhrrXsiSe3xjVWzJ6tWVWVVIYQQswAlISGEELmhJCSEECI3lISEEELkRtMKE9z8eXDRRG8XV7SH6wxRgSsSoQETIDBRgRH3LVLnvdluFPcKiXiA2Y4w2x5LyBA4Ys/DzgnZtGUF6az29JywnWxvmxsP8YBPYTychqhgFuJlWQQgpAXpSD+kvU8ffA0ZbYn6hAsW2OcBERVY4htyP9RamGDBbp+02B8stVZDNNVun6yklag7Wu0PlkIhq4QKyaLwcZSy0JOQEEKI3FASEkIIkRtKQkIIIXJDSUgIIURuKAkJIYTIjaZVx6VtMdJJ6jgUmF1ONu6otQ6Js/aG6sWRom6sKBeDFvwyBC7MtocVpItIITDLjoWNOyGFwGjBL9LeLD5GLYvsN6iainrxeLQlx2R2Mb4WPV59Nwm00B9pT1VzrGCicT2pVdBMnm+mmiNKVy8VLbkfCiftvlmhx4So6WqG4q02Zg+8Os/+fEuM4nUAULY+g4iKNDVOrvNY4HoSEkIIkRtKQkIIIXJDSUgIIURuKAkJIYTIDSUhIYQQudG86rg4QlqYNDyi4nKmvxtRgzAVHFGymKoX5hFHBCHM942prCx/t4gVtfNQwZ16Ixui8/GN+3yl8fWCY7os4ntHZVwNwKtrz3E0u2qOQq8n8TC01HGkQCPzNmwEzFOOXbeQKGNTI85UtBFTnVZI3+NEATuWbV8wYgAQjdvx6jhR05WzN/PJZPo3eEKOZ6EnISGEELmhJCSEECI3lISEEELkhpKQEEKI3FASEkIIkRve6rhnnnkGX//613Hw4EG8+uqrePzxx3H99dfX33fO4Z577sH27dtx7NgxrFq1Cg8++CCWL1/udRxXCOEmKdyY2sT2bbLzq6WkO9Xer/KiBasuSVVwzDvOUAlZMYD7zzGsedLzSj3y/I5pzZ+q4DyVhMz7ywo7orKiPmlknlZ7WhCWepZ5xmfw66J5PelJaZAa0VDNMRUcVXo2gMDTCNCl9kQtb0d2/4RVomArk/uQeDVGleyFq1XMprwCM1GxWfFq2S4Ve6KaHUc6Nv0F6720T5w4gUsuuQQPPPCA+f7999+PLVu24IEHHsCBAwfQ3d2NtWvXYnR01PdQQggh5jjeT0LXXnstrr32WvM95xy2bt2KzZs3Y/369QCAnTt3oqurC7t27cLNN9+c+Tflchnl8v+l6ZGREd8hCSGEmKU09CH/6NGjGBwcxLp16+qxOI6xZs0a7N+/3/w3/f396OzsrL+WLFnSyCEJIYRoYhqahAYHBwEAXV1dE+JdXV319yazadMmDA8P118DAwONHJIQQogmZkZse4JJu8LOuUzsTeI4RhyTak5CCCHmNA1NQt3d3QBOPREtWrSoHh8aGso8Hf0uXCHIKNmY2sRSwnmr4DzUPd5ecEQ1RxVvNSPm6Z/FKkBaSihvBRetUEq6MZRwVB3ne0yfsRNlE7MPY/ioA7kXHunbYyy+1U+9+mGVRVkFVaYk9Kk27CuC8zm3DfqbD1XqGWOJyP3NxsLOVUo85cKi4TFJ2tYMJR0AhExNZ8QjouqrVLNpJB2ffmpp6J/jli1bhu7ubuzdu7ceq1Qq2LdvH1avXt3IQwkhhJgDeD8JHT9+HD/72c/q/3/06FEcOnQI5557Lt75zndi48aN6OvrQ09PD3p6etDX14e2tjbccMMNDR24EEKI2Y93EvrBD36Aj3zkI/X/v+OOOwAAN910Ex5++GHceeedGBsbw4YNG+o/Vt2zZw86OjoaN2ohhBBzAu8kdPXVV9NfngOnRAm9vb3o7e09k3EJIYQ4C2jaonZJKUQw2bbHq6hdYyxnAqv4FtucJQIES2jA+j7Vv+Vz0yALHR+Y0MCzIJ1lLcQscbztbDz2vdm4fTHPeQPGN1X7RhQMpNfT43hM2JOwe4JszptWUZ62Vz472rR4HaEhhfRYH0TYxO6fyKMwYEoKz7Hil5FhuXMqnj1fljXRqXi2bUIsiMx/P+2WQgghRINREhJCCJEbSkJCCCFyQ0lICCFEbigJCSGEyI2mVce5IMio4VjxtUbYqHDF15kXmONWH9NX4DAbImqL4qvKsrpgw6MqOHJejOvmbdvDrE5Ic7Nrz2tPbWGsgnm+aj9PTGsdz75p4b3pHg+AI3Y+AVPN1YjljGEvw9byTBa1o2pE8oaXao58XjG8LI4IAflsCsk5ZJ9ZluItYMo7Q/2bVKZ/nvQkJIQQIjeUhIQQQuSGkpAQQojcUBISQgiRG0pCQgghcqNp1XEIkU2RPj5hnmoQ3t7wjqOeb6RvoqhhflYz6gdn4KMMBIAwIeNmyinLO460bdTcrTnReXp6eZmqOU/PNxb38bfzKYB36h+QY3qMg13jpEj6JmvF8iZjbQNWjNBDNUdVbY0qpGcVi2RF6pjKt2AvCnpPeKxx5mMX1OwJhcbiMmronWprXLdadfoVB/UkJIQQIjeUhIQQQuSGkpAQQojcUBISQgiRG0pCQgghcqN51XEOGfWHl+LNV/HF/OCM9g3zsqJ+aIavVoOUULZRWAP6wBTqQOscMiWUb4XSmfwaRSvoGkHPJeGtmpu+2MjfU87j+tBxM9VcbPdTM3zIWPVPR/znuCejHW4I9LoZ1Z2LduOkZMfTElHTEd9IC9/Pt5B4vFkK4JAo3gLrw0nqOCGEELMBJSEhhBC5oSQkhBAiN5SEhBBC5EbTChOC1NiMZdYTln0Ftdbxi4P0Y8LsOJg9D9uFb0BxK4aXnY13AcDpx33aAoBj7e2wl5CDtaUiCastW28NEiz49E3nzuLGuQ3ZuicnJSW2PSxea8n2E9bI5D0ELwAQWCoRtk/uU6QOAIiFkGnb41kYMGGFAYlgwVorzOIoIqKPMLLjUdmjmKcRZ/eDOYZptxRCCCEajJKQEEKI3FASEkIIkRtKQkIIIXJDSUgIIURuNK86LkkRTJJK+RSN81W7zWgxMV+1ktWUjY9aCE3f6oSqjIjaj14HUhzOPmF+42ZhJnryUbZRGtAHPyeeh2yAas4HNu6QqsmYsstuncTZWIX7WNlHJPGonB28qZgDAHZ9GEyhaykMiZrMMaVagbQnarrUOueexRV9LIEYYc2KTr9fPQkJIYTIDSUhIYQQuaEkJIQQIjeUhIQQQuSGkpAQQojcaFp1XJg4hJPkLz5FrGhbpu6h/m4+bT2VJmwohoLPx4vJ+5hMUcPiBVKsixQwS+Js+xopmlbzVF+xc2ipgXx82abC9OzyvPRmYTzArzjezFkMUui4PdWOlqcc85mrzGOV/shIjHhUtnWUIdNX+t5vVhE41rdnsciQFPUzlW0zuCYcyRbWLcu8Hi30JCSEECI3lISEEELkhpKQEEKI3FASEkIIkRtKQkIIIXKjadVxcPBTCk3+59SvzbOMZiPSNFO9pERC4qP2Y75vid236bdFFGmOVHhl6rioZJtc1Vqz8SBlPmFEecdUc+RCp8bK9q5ESrDaU2Wkp5EbrWjaLKo5quCy45avI2BXAE1YdVbyKVVpt9dKangeFk+SiqNlOx5WyP1T87iviHdcmNgSw5Dcs2nZnqcz1HHW3AHA0bgZ9lpD1tr3UQrrSUgIIURuKAkJIYTIDSUhIYQQuaEkJIQQIje8klB/fz+uuOIKdHR0YOHChbj++utx5MiRCW2cc+jt7cXixYvR2tqKq6++Gs8//3xDBy2EEGJu4KWO27dvH2699VZcccUVqNVq2Lx5M9atW4cXXngB7e3tAID7778fW7ZswcMPP4zzzz8f9957L9auXYsjR46go6Nj2scKnKPKmgxmKvWTCPmoOajihyqbmEJo+nGqyiFxeCjvGAETsEW2pIYq+MzGpG+qamTfl6bvWUaVQJ5/D/ASvDF/QM/qtNyzzTikZ3XNhlSQZfNkqjlrjZM5UmUXmU+t1VCNEUVnYdzum8XDqt1PYCjh6P3N1KjkM4h+Dhrni94l7KOJ2dsRZayFWdl6up/d8ExCTz755IT/f+ihh7Bw4UIcPHgQH/7wh+Gcw9atW7F582asX78eALBz5050dXVh165duPnmm30OJ4QQYo5zRntCw8PDAIBzzz0XAHD06FEMDg5i3bp19TZxHGPNmjXYv3+/2Ue5XMbIyMiElxBCiLOD005Czjnccccd+NCHPoQVK1YAAAYHBwEAXV1dE9p2dXXV35tMf38/Ojs7668lS5ac7pCEEELMMk47Cd1222147rnn8M///M+Z94JJf9t0zmVib7Jp0yYMDw/XXwMDA6c7JCGEELOM07Lt+cIXvoAnnngCzzzzDN7xjnfU493d3QBOPREtWrSoHh8aGso8Hb1JHMeI4zgTT6MQaTQxR3ILkOlvgvkWnvPZYPMWIDCxgYcwAbQPtuNojIWdE7bDzXbVSfGtsJptH1aIjUqR2Yt4WgsZO+Upmw8TLBCsTXguMiF9EBFLVCVWL0ac9c027M0iaLA3/n2tjBg+54UKE/wcnryKF7JCjEx8ExIrHut6srZMHOQl7CFQ0QwVU7GxGF34rImZKmrnnMNtt92Gxx57DN/97nexbNmyCe8vW7YM3d3d2Lt3bz1WqVSwb98+rF692udQQgghzgK8noRuvfVW7Nq1C//6r/+Kjo6O+j5PZ2cnWltbEQQBNm7ciL6+PvT09KCnpwd9fX1oa2vDDTfcMCMTEEIIMXvxSkLbtm0DAFx99dUT4g899BA+97nPAQDuvPNOjI2NYcOGDTh27BhWrVqFPXv2eP1GSAghxNmBVxJy09gfCYIAvb296O3tPd0xCSGEOEuQd5wQQojcaNqidkkpRFCcpI6jNhhG0FetRH0trL5ZH3bcuzifNRambqHj9imCR9pG5DsKsycKp19gL6zZfYcVog4rMtWYPRRTNUcuUNoA3xrP2nUcdmoNdRxXXxElIbG/SYvZa5FSlaJ9SGoV5FHrj92brNAft3jyaMu68C2AaKw3ptILyEV2ZB024nOP3Jp0vTnrHxDrozNVUupJSAghRG4oCQkhhMgNJSEhhBC5oSQkhBAiN5SEhBBC5EbTquMQIKNyocWtLIUHaevvrTR9zy6qYmFqMg+lDfV3Y3Hi4xaYplC+xfjICSBKNYuQjDtiXnC0sJlfwTO7sef1sZoyHzemGmNKNXJHWmo16j9H4oHh4QcArpyNM585S0kHAGnJ87o1opCer9L19wxdg2TyAZGwMdWcpYQL2P3AfOl81H607TRjHv9cCCGE+L2gJCSEECI3lISEEELkhpKQEEKI3FASEkIIkRtNq45Li0FGEcTUMJb/EVPIUOEMkX5Y6qtGKOwAIEyYdMrow6MK65TtDR83WrWVqayIOo7GDT84WiXXO26bmQVp9vtVLSWqJHIdqE+a9dWNiY88PciYOi6JswelykCiSAsr9vWxvNkioqRjfnWuzNR0ZIyG+o4p8hpg7eft30g/a2bwmN7tGwGtTOzRh4cdpTkEj0MJIYQQDUVJSAghRG4oCQkhhMgNJSEhhBC5oSQkhBAiN5pWHWd5x1H1jPXPPSsJBgnrJ/sPHPOsIjIeprJKiTLF9ISKmAqMqMaIx1dgqZtYNUaimnNMBcc88qz2pI9wvObVtzkfAEGSXdoh8dNLSsQPjdwdljrOMQ8/gq+/mTUWdsyUVMAMW0jcqNpKz6unPyJV01mejOT6MBUg+wptnhcmRGV9sKqoDVDo0s8g2renJ+UMQZWe0w7a6ElICCFEbigJCSGEyA0lISGEELmhJCSEECI3mlaYUBqpoVCYuEnNNpBNCxBmF8KKbBHxgOVfwTdn7S7ohh4TOFgFpahtDbOiIQc15sk2UFNmiUPtfJgwIRtnogcmWGDxiAkZjGNGZXv9JLE9zyRmG//G9SEFyVjRQWqL4qNvoJvtRIBBvnKm5pog68qzoKOPEMhXrOErBmkEPsUSWTE6WgDR4zMIAIJoBoUJxiF9zrcjFlkWehISQgiRG0pCQgghckNJSAghRG4oCQkhhMgNJSEhhBC50bTquOhEFVEhmhSz27rIKPhFVHBpyZagpMy6xVDZMeUds3nhSiMPlZ1nHyDzN5V6VHlnd81sfhiWGsgZxfUATFFIz099ZSryyrZ8kVnUhBWyJoy1wiylHFEwUZUmtaIxgr7KO4bRjyMnlim4LEXnlFj3iqfajRb1M88V6cNTpeh9bmcQ+172aOuLR9+16vSfb/QkJIQQIjeUhIQQQuSGkpAQQojcUBISQgiRG0pCQgghcqNp1XEIg1Ovt0A9ywz/sKBKlFBECUbVSqXsKUpj+7QlLcSDjCnvSkRlR9R3NkzGQ1pbBfMSpqRjXnCeBdyMY7oCq/TH1HHT7xsgY/csAhYSBV9Q9ijIRgrMUdUcU3wZp8tLSQf4+dLNMObYmdrPs/CcFU991Yhkefoc078Ynx33wVsF51H8M6SFJbOxpCLvOCGEELMAJSEhhBC5oSQkhBAiN5SEhBBC5IaSkBBCiNxoWnVc0lpAUJg4vKBK1EqGAilk6ZX5h50sm/Hw2PFMLCJVPotE8eXikh1vi8140lbMxlqJIi+evucdYKsAmecdk1N5K9UM9Z2v8o6qfpjvnaHkCZi3n6cXnlVhko6PVZBlUii2bq32rLImU2U1wg+tQQo763zRcXgouKaMW009lXfUI9BYW94KO9aeVtC14yae59a6PkxFG1aysaQsdZwQQohZgJKQEEKI3FASEkIIkRtKQkIIIXLDS5iwbds2bNu2DT//+c8BAMuXL8ff/u3f4tprrwUAOOdwzz33YPv27Th27BhWrVqFBx98EMuXL/ceWLmziKQ4cYO+MGZv8oaGYCGN7V2+oI0UMKva4oFwrJrtY8zYiQMQVLJtASAok/ZjRAzxRva7QYHZ3JSyIgYASNvs+SStluiBFPqjxfumL3o4FbeiZ279A0xhOWS1Z4IKX9GDz8Y3tdDxnL81FmafRAbomNDEapuHxQ8732ytkOtpwSxn2HXgp5acW48TRoUGvgIEo71P26mOaYmP6JK1lqbPtZl+U+Ad73gH7rvvPvzgBz/AD37wA/zRH/0R/vRP/xTPP/88AOD+++/Hli1b8MADD+DAgQPo7u7G2rVrMTo66nMYIYQQZwleSei6667Dn/zJn+D888/H+eefj69+9auYN28enn32WTjnsHXrVmzevBnr16/HihUrsHPnTpw8eRK7du2aqfELIYSYxZz2nlCSJNi9ezdOnDiBK6+8EkePHsXg4CDWrVtXbxPHMdasWYP9+/fTfsrlMkZGRia8hBBCnB14J6HDhw9j3rx5iOMYt9xyCx5//HFceOGFGBwcBAB0dXVNaN/V1VV/z6K/vx+dnZ3115IlS3yHJIQQYpbinYTe97734dChQ3j22Wfx+c9/HjfddBNeeOGF+vvBpN0r51wm9lY2bdqE4eHh+mtgYMB3SEIIIWYp3rY9pVIJ733vewEAK1euxIEDB/CNb3wDX/rSlwAAg4ODWLRoUb390NBQ5unorcRxjDjO2teUO0PUJhWDKxG1VmHMsFGpMTWMHXahrTIDWjIRS40HAFGF2AoxuyFWJMoopmbFpuzDKPQHAAUjXjhmNgWY2o0UauPF/ozCgKzQH1XemWEaT60x+iq+qKWJ5Tnj1zWzPqL9+CihcqAhajpW1K4RRfrYtbRdvE5jnyJ7gJSpEdm4qWUTCedRBM/sZJoxwhkvY+ccyuUyli1bhu7ubuzdu7f+XqVSwb59+7B69eozPYwQQog5iNeT0F133YVrr70WS5YswejoKHbv3o2nn34aTz75JIIgwMaNG9HX14eenh709PSgr68PbW1tuOGGG2Zq/EIIIWYxXkno17/+NT772c/i1VdfRWdnJy6++GI8+eSTWLt2LQDgzjvvxNjYGDZs2FD/seqePXvQ0dExI4MXQggxuwmcY576+TAyMoLOzk5c8pmvIipN3I8pnbCHajkp+O8JeViPz4I9IVpCwIdZsCfEfwluvHG27An5nBPWt+c+TDPtCVnteckGv/XGyp6kxpYyW8tWW8AuBwH4lZvwXRMUs5SD3TQ0tp+T8jiOfOMuDA8PY/78+VMeqom2NoUQQpxtNG1Ru/G3BYjiiembfYMoGd/MozJ5ymA1xlgRK0ORl0aNyd3cs2z6bUPyxEfjlWw8JE9wEXuCI+3Div1VKRyzlXp2YzvsyDlnT2WumI0nRmyqPnyeyqhvnudS8XmiaIiyyXccnp53M1kwrxGqOe/iisx/0Fj69MHTs5Cel2quQWvC9I7zKSLoMQ49CQkhhMgNJSEhhBC5oSQkhBAiN5SEhBBC5IaSkBBCiNxoWnXcycUJwtaJkpMaqQBaeyMrQykeJ78pGieqMaKBtxQrVP9vFzNF6vkbF3sgpAsiEaK/QzHibO5MYcd/L2C3j6qGIo+oF9lvsOhYyO+hLAVfkaj0fCurWrIn06sOgCO/h6q1sGq2RKlXslSa9vDob9481pvv734aodTLpZorwbf6qUkO8/FSsE2FpdAlnynW54cjnxHmv59+UyGEEKKxKAkJIYTIDSUhIYQQuaEkJIQQIjeUhIQQQuRG06rjigvHELZNlGiMz7PlZ5UF2WkUR+z8WjxhS1aiMXscoaHs8lUC+Tr1NqJiJhujpXBJqf+cPe6wavdN/fcMNWGQLaZ7Kp7anVDPLlox01DkUYUdUfWViVLPUPAx37xgzD5ZhTemr7wDgLSUXSzMtbzWZi+spMU+t4mhvANbs76+Z02Oj7P4lDS5ao6ra0nc8o4jFpBWnLW1mKVLRwghxFxASUgIIURuKAkJIYTIDSUhIYQQudG0woRquYAwnDi8qIXsdhnxyjn25mx5zI5HJ+18HI1ndxHDit+GPbO5ofFGWKB4vBGQgmysF99xW4IAZhXEypX7WggFqdHeioGPmxWqSyJDJEDseYKqvd5oAUASj46Xs7HRcbNtwRgfALiYCBZas9UikzZSqp2VZbfEDfCzFppJcQPVAhBrJtcIDyHfonuNECw0QIAA2MICq4z3qXi2c0fuY/PfT7ulEEII0WCUhIQQQuSGkpAQQojcUBISQgiRG0pCQgghcqNp1XEYLQK1iaqdJCY2Kq1Z2UaxlUjVSDzttPNxtZqNu7It+QnKdh/hOFHeZQVPp9ob6jumTKHF6whme1bAKyHWLYaVke8xLTskgFvosGJ3EYkHlrUOaYuU9OGh8GFKOmbDQ62cikTZZvQTVIlVUMVe4+FJW00XGhZXhdi2yHItRDVH4ilT5MXZY6ZFZm/laSFkNKeF/ggB6ZsqKb16byI87LCoks5Yhky1aqEnISGEELmhJCSEECI3lISEEELkhpKQEEKI3FASEkIIkRtNq45zoYMLp6c5cen0lS+FAlEUFe245YlVLZJiYkTZlDDFU4Go5ozuXZn41bHiUUzJYtUvY4of9hWFqeka4IlF/eeIUi2oENWcUUwuGKuQPoiSskpObmKslZCcLBYna8iROArEhM2CFWojPmnBePa8WDEAwHGiAC1l/ecAwLXaKrukLRtnSjrmy2cVSwRsNV1qDw8JO1czCftY8/R3s+4r6jvp27cV91HSecgF9SQkhBAiN5SEhBBC5IaSkBBCiNxQEhJCCJEbSkJCCCFyo2nVcQgx/RRpqONqpKJlmpAKmETOkRqSr9TwkwMAEK81pirxgSkFmSdWQ6qzMpEV8+xifmhG+5SsPOYdR9U9CTm5tWw8YGo3oo5zZWLuZ7R3lmJuCgKmgotju32LEScVVJkKjnnkoZY9L461JbBzG9SIGtW4PqlR4RUA0pj40hHVXGKo7JiSzhevgqueSjVWbdh5KF19K6uyzyZrLGa1YnZMqeOEEELMBpSEhBBC5IaSkBBCiNxQEhJCCJEbTSxMcFk/GbYvVsvu0LmECBPYxiLduDP+AREgBMY4ACCoEssdErc2Cxtlx2HFaVt2TDZsspps7QA5V+QCpewcRuR7lGHd4kjbwNO6xRkb/87Y3AdgW/wAcEQMwYUW2f6DIvGiYYIFNhbrmGw3nECXCrMtMq4Fuw6hZ2FAWNoOT6spLwECYJ4AVhQxZJ03wPbKG/o5kR07E074fKZY6ElICCFEbigJCSGEyA0lISGEELmhJCSEECI3lISEEELkxhmp4/r7+3HXXXfh9ttvx9atWwGcUg7dc8892L59O44dO4ZVq1bhwQcfxPLly736DuIEQTxRjuGI5Y6XbQSz1qHqM6O9pw0Ps7lJC0Q9Y8hhmKqP2Q2xwmbWUJjLCxNIUQsU1pExH2r9ExAFG1Hm0GJ3SXZpR4ZVDGCr3QAgoPOZPq5CisMxpdo4sQoy2lOFHVMMNgJyfWicnVtLkUesgtj1YV+hrVvWu+CipyLNWp+s4CS1v2E0wILLW2HnUajOnE9l+oM+7dV64MABbN++HRdffPGE+P33348tW7bggQcewIEDB9Dd3Y21a9didHT0dA8lhBBijnJaSej48eO48cYbsWPHDpxzzjn1uHMOW7duxebNm7F+/XqsWLECO3fuxMmTJ7Fr166GDVoIIcTc4LSS0K233oqPfexj+OhHPzohfvToUQwODmLdunX1WBzHWLNmDfbv32/2VS6XMTIyMuElhBDi7MB7T2j37t344Q9/iAMHDmTeGxwcBAB0dXVNiHd1deHll182++vv78c999zjOwwhhBBzAK8noYGBAdx+++341re+hZaWFtpusv2Gc45acmzatAnDw8P118DAgM+QhBBCzGK8noQOHjyIoaEhXH755fVYkiR45pln8MADD+DIkSMATj0RLVq0qN5maGgo83T0JnEcIzYKecVtFURtE3MkLVTnIYdhii9HTaSsGOvbr6gda59acebxxPzqSNzyq2MqnrBC+iCCL+aFFxoirqhMigjS4mNENefsNWEpdpgqydc7zvJDCwr2reRKtr8bU7ahSgrsWUXjSCE5bzGV4cEWMP85Eg+Yjxsr9ueM8+XpEUfjlm+gh5Lu1Bt2mPmnWe1DUqCRerAxpaePDyRREjrPNW4ej8pos6FadfoSYq8noWuuuQaHDx/GoUOH6q+VK1fixhtvxKFDh/Dud78b3d3d2Lt3b/3fVCoV7Nu3D6tXr/Y5lBBCiLMAryehjo4OrFixYkKsvb0d5513Xj2+ceNG9PX1oaenBz09Pejr60NbWxtuuOGGxo1aCCHEnKDhpRzuvPNOjI2NYcOGDfUfq+7ZswcdHR2NPpQQQohZzhknoaeffnrC/wdBgN7eXvT29p5p10IIIeY48o4TQgiRG01bWXVB+xgK7RMVFpWaPdya4SlnKuYaBC3Cmto5nYlKWHtLHUeVdGSeac3uu2bFiaotqBJFGlHNRSw+no1bMQCIxswwiAgOAHnDOudEsBMx5ZChsgIAFI11WLVVcAFRsAU14h1HKrQGlsqMtDUrpQLUm82EVERlKkB4xp1xDl2RqF9LdjwpkfvNOCStwtoATzVgiirEVhdUAOpb9tmAfE74KNsYPtVSVVlVCCHErEBJSAghRG4oCQkhhMgNJSEhhBC5oSQkhBAiN5pWHTevWEGhOFHpEcXjZltLIZYwsyhCSGQitHKpAfOfq5GxVBNb9VM1VHMJUdJZysCp2lvxhPTBvPoSopqrlu32tXK2fXTS7qMQEz8w5ilH1U3GWJhAiKjgwoI9RisekHOFmq2aA1HH8TK3HpUqiUceVYhZMMUgixeYss3+iLEUb2lst01ipoKbvqccrQrKKvaSxeLlwcbsKJmPHStaSz5XTAUarX7K+p5+ezo+Y735fPzqSUgIIURuKAkJIYTIDSUhIYQQuaEkJIQQIjeaVpiQIkA6aWevPbILfrVEWfuSAq0+ZRORHTprgzL08egAt9apkt278SS7mW3FAGCMbHyXicWRJXqoEYFEQkQCTFBRqRBbpUq2fY1sQjOLFlbsjokKrFPrQrtv1kdEjhkZdjFBxd75Dav2OgxqZKeYxE3blQYVMDPbs6+nxM6HHpOIO1xkXSByD5LicMyHKTDa83XiJ3ihG+5mXU3PYome1jo+woSG4HtOpomehIQQQuSGkpAQQojcUBISQgiRG0pCQgghckNJSAghRG40rTpurFpEYVKhsNaCrY4Lg2y8lSjp4tAuBFYk/h2FMCtBYW0jn0pOUzCeZhVvY0QdN1prMePDFTt+slbKxMoJUdIRFVwttedfjOx41VC8lYt221rJnmfVKiQHwBVJYUBDDZUWbXlPUrLjpROsSF9WghRRdZx9DkPSPiAF6Uw1Ha2WaIep+soDqvhiX2fJMe15kkJ6jp2r6Y/Fy7JoivasIJ2lvvNX3jEFqN3eWs9MqcbUpSmrCWndPyRbWPHEUMQy9CQkhBAiN5SEhBBC5IaSkBBCiNxQEhJCCJEbSkJCCCFyo2nVcdU0QjpJnXWimlV2AUDBUKuFRKlWpNWdiOLLiLeEtvKOqeZYnNEZjWVi45GtGptfsAv9dRRsddwb1dZMbKSSjQFT+NIRNR0rAFiIsuec+e9VC/b1KZM4U82lxaw6J2khxftaiUfeCVvhUzyZHXthzO47qtjz5Go64p9Wzba3PNIAu8jYlJi+dHbTRijsAKKyY6oxD0Uai7O2looSAP167qNgo22Zgo2NkanSDHVcYn9EUmVoStsbMaakM+aTlKevRtSTkBBCiNxQEhJCCJEbSkJCCCFyQ0lICCFEbigJCSGEyI2mVcdFQYpokm8bq1DKqo5apESa0k4qQPoQhrZyyFc1Zyn7YqLIa0lJ3EPBxxSDxwJbNTe54u2b1IyqrQBgzXLyta33TRRCpdj2/KsSEU4SZa8Fq9qaxPa4C21knmPZeDQ+fZ85AIjKnmo6QzXHlHRMjBkk01e20eLBzAuOqenIMS0FH1X1eXrhOWN9clWbn18bxRgKn7tn38SvzxojvW5MrEavWzZmFLCmbcMyOZ6BnoSEEELkhpKQEEKI3FASEkIIkRtKQkIIIXKjaYUJzgVwk4QIVoG5qeIW48RyhokeaoZXRdXZu27UAoQQGnY2gP3NICK7s0ywwGyLLBLyXaRM/EIqJM6K4FWMeEJEDGlK7EVInFkFhXF2t5QcErWi3UfChAnj2Y7YRmxE7Euiit0+rNjtQ6O9JVYAgIBsIIdMsOBr82NBumDHDA3LISriYBZHLG4WALTHEZB15VsEzxJsMJEAsyEKmW0PsdwJDVVORNZPalhNAXyelujDx/GsZthMMfQkJIQQIjeUhIQQQuSGkpAQQojcUBISQgiRG0pCQgghcqNp1XFvHG9FmE4szMaUUEVDgsMsdJgHSIVVbMqBjihbqC4i0pSWwFbHMTVdNczOs82SXgFoL9iSL3auWLG7oiFLqyXE4odI2Ni1p3FjiCHxs3FEpehKpAhei9E+ISqjit0HETUirE1fHWepowB/dRwMhZivtQy3+SFjMebP1HGlE/Y5LJ6wBxmNGZ8HrAAgsUnyLUhnFtLzKIAHAGmByOaYms6wBWK2T+w6UIxjsnFb83REuWmhJyEhhBC5oSQkhBAiN5SEhBBC5IaSkBBCiNxQEhJCCJEbXuq43t5e3HPPPRNiXV1dGBwcBAA453DPPfdg+/btOHbsGFatWoUHH3wQy5cv9x5YbbANYctEddz/1ogqqyM7jXmxrfiKC7Z0KCTyEas9K+oWEolQHNrHZP0kRjwmfTPVHMMqasfG1xrZEq4xEm8vEEM0A+bMFRFVY8VQ9QFcTZcY6jvmP+fYXUBMvkyfQdaWqOYSzzhq2fkEtC1RzdFid9NXx/mq4Fg/pu8ZKQyYtBIPv9iOx6PZeOEEKSDpoeI69Q/YGsrGE6KuJNaLvMCeh40duz5UHejhJ8jUfpaqj3lxmmObdsvfsnz5crz66qv11+HDh+vv3X///diyZQseeOABHDhwAN3d3Vi7di1GR0d9DyOEEOIswPt3QoVCAd3d3Zm4cw5bt27F5s2bsX79egDAzp070dXVhV27duHmm282+yuXyyiX/+/3KCMjI75DEkIIMUvxfhJ68cUXsXjxYixbtgyf+tSn8NJLLwEAjh49isHBQaxbt67eNo5jrFmzBvv376f99ff3o7Ozs/5asmTJaUxDCCHEbMQrCa1atQqPPPIInnrqKezYsQODg4NYvXo1Xn/99fq+UFdX14R/89Y9I4tNmzZheHi4/hoYGDiNaQghhJiNeP057tprr63/90UXXYQrr7wS73nPe7Bz50588IMfBAAEwcQNKedcJvZW4jhGHMc+wxBCCDFHOCPvuPb2dlx00UV48cUXcf311wMABgcHsWjRonqboaGhzNPRdGj7RYgonvigNj7eYrY9dm52GiMdtoIrju14gfiHlQpZ+Uhr0e5jQcuYGWdKEa6my/ZP1SaeBSAtdVwLMTJjqrl5RAVnVaFlMDUirZ4bkaqtRDFZM9R0Davm6qP88bUkJH1PrjIMcDswR1Rzjs3T8vHzVMFZ/nMAuKeepY4bI9eHVBbllYyn/weewkl7vbFqs9xTzvKOs4/JVHDs9qGqOeuy0aVJrgNTQRpxWoHX6NpHs3tGvxMql8v4yU9+gkWLFmHZsmXo7u7G3r176+9XKhXs27cPq1evPpPDCCGEmKN4PQn9zd/8Da677jq8853vxNDQEO69916MjIzgpptuQhAE2LhxI/r6+tDT04Oenh709fWhra0NN9xww0yNXwghxCzGKwn94he/wKc//Wm89tprePvb344PfvCDePbZZ7F06VIAwJ133omxsTFs2LCh/mPVPXv2oKOjY0YGL4QQYnbjlYR279495ftBEKC3txe9vb1nMiYhhBBnCfKOE0IIkRtNW1m1NOoQlSeqMQKiwInGi5lYtcOWmpxsK9kHLBLlRyGr8wiLtvbjf+N5Znyo3Y53t9t2RifaspL17njYbDvPqMIK2Co4BmvLKq7WQvu7Szmyl1PNkPFYsaniEVG2FVlVVEMmxP2spq9IA2yVmY9XFj+iXwVZ1gergImIKL7IerYbs3NCmpMKui7KxpkVXkDWREA88iKjIHBUIQpVUp2WVb71vMykEzvMfN+oUNGn+imtisr6NvwEPWz2EnK+LfQkJIQQIjeUhIQQQuSGkpAQQojcUBISQgiRG00rTHBRdjON7JOjZFR/CCuk2NkJYg0S27tuacEo7kTO2ngpK5AAgPHjthjijfZWM/7rjqyQoattgdm2q9UufXFe8YQZb4uyJ5EJE1jBPN8ieGWjitc42eVkVka+WMXxEmI7knoe0xIh+FrlUDzEENQbhe2e+1jxNGQH3vOYrCnbPCf3oWXz45gog23Y20ucb84baytk2iByalmRSyZWCY32RAfClwSzEDLOLbcsysYSo9AdQ09CQgghckNJSAghRG4oCQkhhMgNJSEhhBC5oSQkhBAiN5pWHRfUgGBSiowSYmliqYSIKokpVhJiAZIYdfRSqkoiFiVEmlKu2e3/t5q9LMfH7eqzv2lrM+Nvaz1uxt/eko0vKNrF+FixuyI5iVYxvlPxrGqwRBR2zBIoJWqbMLHlTYlRHI+pjNhtUCMF8ywlXFohMquqn+WMVewNACIjHhAFFzm11PbKVKqxpobqELDVVMBUNjJGP8y2h95vJG41JdWdWZx27shnkLEmWOFGb8UgGaOl6mTXmH7usccQYyzsWlrXnn5GGuhJSAghRG4oCQkhhMgNJSEhhBC5oSQkhBAiN5SEhBBC5EbTquPahhIUihMlHVydYXgoxbZKpDLPjlc7iHrG8FZKYlv6kZI4SnY8YMXEDNULU2odL5MifbAL6aVWgbnU7ntB8aQZZx5xBUORBgBxlJVrtaREwkVgfcO260PNKIJXTuzlzvzqElJIr1Y1zhfxjgtIca9onBTvG2PtszFWeI2p46hYy1I3kfPKVIpcTEY828yKbHYfbJ6sbiNV05mNPdoCCIhC15aTEaUa64F4s/mo6XwL4wXET9FS2dHzag3b47zqSUgIIURuKAkJIYTIDSUhIYQQuaEkJIQQIjeUhIQQQuRG06rjWl4fR2HS6GhlvyibS5PYzq+lEVsJVplvtx8vZ+Nusqndb2HVWUFUcMUWW8ZULGZlP6UCqWZaIn5tpL1FlXjeVYkcseB85Ee2T1x7oWy2ZVVbWdVJRmIokyrE4CyODIPAqfo2DLfGiUcc846jhUuJvCkw/gFVx7E4UXalhgKU9UFVc2S5+VTjpOo4ooKzFIMAEFYtTzXPir3s+jAFm2//DcA6t8zDLylNv4Iq4KmYNOIpqyproCchIYQQuaEkJIQQIjeUhIQQQuSGkpAQQojcUBISQgiRG02rjouOVxBNUu24Iql0acQDUjIwqtrKrtDyAwNQGM/GCyeJku6E3Uf5XLt9Zb59+qvzslKjtM1Wt5QKtgwlIkZPLYWs7Clm8iNCyjyxiLLLUrxFsMeXGErHqaD9GN+vmEce88IrkfNi+dgdI952Y6FdETcJya1HKstaQkXm4xbZwkOExMfOEiRaCrNTcbtvWqG0AV9zmV8bG0tUMdr6WRVSVR9ZQoChMLR8JwEgLZIqzkTBVmshcaOocq11+hWiT43FjluVb1nbpMVoOz59Ba2ehIQQQuSGkpAQQojcUBISQgiRG0pCQgghcqNphQlw7tTrrSGy+Wnuk7O2ZMORbX4WTmY32NoqZAN+hBTSG7JzfbnTPv2VBdl4udMuXvfrBfaO4/EF9oZ4ucM4prHBCXALHSZAKLIqY1bbyG7LRA8MNhYTsqnMLITarR1uAG2FbLy1aO+Sv160T+7xkn3dqrG9+5sY9lGhETsV9xMsROOGbQ8rxmefEipkCEh7UzfjadvDiqyZ9zJz22GFMskGvyPCEcv+hhXWZOIBS2gwdTw7z6TFPimOFNZEyE66ESvYfURx9gIFJ4mn0jQPJYQQQvxeUBISQgiRG0pCQgghckNJSAghRG4oCQkhhMiNplXH1Ra0AoWJCqK0SHKmITahSjrSRVoiqhfLYoM5lBCFUDxMVCVExVQw1ErROLH+KdtqqhMVUqjOsCeqJkQi1GGHQyJLKhILIUs1x2yFGAm7cASf/ltgK9vaQlvaZanpOoq2GqijOM+Mvxbb8eExWzU3NpZVR9Yq9nWrkUJ6tZodDwyVnaWYmzJO1jItsGcJL/2WBMdQwNL7nnwC+ljUsHjSbt8PQSu5T1rtk9US2/FOo6ClZSnVKFjfltK1dqKMl6fZr56EhBBC5IaSkBBCiNxQEhJCCJEbSkJCCCFywzsJ/fKXv8RnPvMZnHfeeWhra8MHPvABHDx4sP6+cw69vb1YvHgxWltbcfXVV+P5559v6KCFEELMDbzUcceOHcNVV12Fj3zkI/jOd76DhQsX4n/+53+wYMGCepv7778fW7ZswcMPP4zzzz8f9957L9auXYsjR46go4PIrQyOL2lBVCSVmCZhCaEiVpSL+L5ZRcMAoNaSzdPME4oKuIg9U2rbwaHanu0/abXbJjHp3ChKBQAuzfY9VrWXwRtl+6Al4inHvOMiw3OqyE4KIWR9e6jgmKov8hxLm2HC1hHZ6rgFxTEzfl580oy/3mobhf1mvD0TGxkn/oDkelrKSABIDXVkwhR2RHWJhHkyEimpccqtQmoA6FpGkdzjxexaKZTs9RMT5dk8Q3kGAB2xbcDXWcpe546i3bajYK8VVlyR3lfGeg4913JKpL6WGtXH17FcquKZabb1SkJf+9rXsGTJEjz00EP12Lve9a76fzvnsHXrVmzevBnr168HAOzcuRNdXV3YtWsXbr75Zp/DCSGEmON4/TnuiSeewMqVK/GJT3wCCxcuxKWXXoodO3bU3z969CgGBwexbt26eiyOY6xZswb79+83+yyXyxgZGZnwEkIIcXbglYReeuklbNu2DT09PXjqqadwyy234Itf/CIeeeQRAMDg4CAAoKura8K/6+rqqr83mf7+fnR2dtZfS5YsOZ15CCGEmIV4JaE0TXHZZZehr68Pl156KW6++Wb85V/+JbZt2zahXTDJrcA5l4m9yaZNmzA8PFx/DQwMeE5BCCHEbMUrCS1atAgXXnjhhNgFF1yAV155BQDQ3d0NAJmnnqGhoczT0ZvEcYz58+dPeAkhhDg78BImXHXVVThy5MiE2E9/+lMsXboUALBs2TJ0d3dj7969uPTSSwEAlUoF+/btw9e+9jWvgZ1cGCKKJ+VIIoSKDMVb4aT95FUcIxUgSWVVy1uqRpRqps8cpqjeSNRxVv9WFUUASNuI4qvdVtq0t2UVO/NbbBWPVUEUACJSzTQh32lMpQ15MmZKIKZsY1iKN+p5x9RHZMFZ1VzT0FY8zSOquXMLJ8z420v24hppzcZ/U7GVdCNVUm23QtR0hjquRvwEE0NdORUBq8IbZc9tS8FWXbYVp1/hFrBVaUyRNp/EOwu2epH6CYbZY7YE9j3YKJVms5AYCruT6fSrLHslob/6q7/C6tWr0dfXhz/7sz/D97//fWzfvh3bt28HcOrPcBs3bkRfXx96enrQ09ODvr4+tLW14YYbbvA5lBBCiLMAryR0xRVX4PHHH8emTZvwla98BcuWLcPWrVtx44031tvceeedGBsbw4YNG3Ds2DGsWrUKe/bs8fqNkBBCiLMD71IOH//4x/Hxj3+cvh8EAXp7e9Hb23sm4xJCCHEWIO84IYQQudG8Re1aADdpH5XsccIVrKp2xNLD3vukziAWdI+cxFmdKVbwq2A4vSQn7A3h6nFi0XLC/n4xfF52w5ltHp9DrGXYJm+nNXDYG/8xmTwXCZDrSTd5DasgT+ufkFzQEunHgok1qsQn6hwiWCgbVdZOttjKltHEFiaM1Oz4iVpWsDCW2FXdmM0Ls4sphMQux4i3RvamP7OzYSIBy0KpMyJrObLX7HwiNGkzBAgA0B5kx1L0FNMwqsQPzBIEsHXF8LmvfIQTx4sedlrTbimEEEI0GCUhIYQQuaEkJIQQIjeUhIQQQuSGkpAQQojcaFp1XOC4Gm4ylnjEVMyBF68LiJquUM7G2bgK5A2rDwCIxpmCLxtn466222+U59vzL5+bVUKNLLSVUM8tti1kTnTZ9i8XLLCd0v+/+FgmxpRNzOqkGNiyRmYhZKnjmJKOqd2YOs6nkB7DsjICgJR8L6x4qJ6qjigmSR8n0uz1PEk8pSyV3lR9M0WiFfe1VWLxjjCreJvPig6GtmruXKKmO5fIaxeE2XMeB/a5KgZ+Craqs+d5PM0q9U44W71HPoJQoZU4s/B7zbBNY5JgAz0JCSGEyA0lISGEELmhJCSEECI3lISEEELkRtMJE9xvBQJJ2d5ItLD2Jw0XjVP9GrWHACCoTn8jjdXCoTqKqv2OI3FTmECGV6uSui8Ve4xJORtPx0nnJ+1rUDthb35WCraoYLya3cwNyAavIwKEmqcwwbKRYUKDWi7CBFIfiqwismxNiDMVquSYY0bBq/HU/n5aZuuQLNCEnFsrbtVpmqoPdt0Kxtpi9kFFEi8Z9Y5OtScWT0Y8pkILv5pMVXJuT6TZ+AnSlq0fn3XlI0w4fvzUOBxZc28lcNNp9XvkF7/4BZYsWZL3MIQQQpwhAwMDeMc73jFlm6ZLQmma4le/+hU6OjowOjqKJUuWYGBgYE6X/R4ZGdE85xBnwzzPhjkCmufp4pzD6OgoFi9ejDCceten6f4cF4ZhPXMGv31snT9//pxeAG+iec4tzoZ5ng1zBDTP06Gzs3Na7SRMEEIIkRtKQkIIIXKjqZNQHMe4++67Ece2TcxcQfOcW5wN8zwb5ghonr8Pmk6YIIQQ4uyhqZ+EhBBCzG2UhIQQQuSGkpAQQojcUBISQgiRG0pCQgghcqOpk9A3v/lNLFu2DC0tLbj88svxn//5n3kP6Yx45plncN1112Hx4sUIggD/8i//MuF95xx6e3uxePFitLa24uqrr8bzzz+fz2BPk/7+flxxxRXo6OjAwoULcf311+PIkSMT2syFeW7btg0XX3xx/RfmV155Jb7zne/U358Lc5xMf38/giDAxo0b67G5MM/e3l4EQTDh1d3dXX9/LszxTX75y1/iM5/5DM477zy0tbXhAx/4AA4ePFh/P5e5uiZl9+7drlgsuh07drgXXnjB3X777a69vd29/PLLeQ/ttPn2t7/tNm/e7B599FEHwD3++OMT3r/vvvtcR0eHe/TRR93hw4fdJz/5Sbdo0SI3MjKSz4BPgz/+4z92Dz30kPvxj3/sDh065D72sY+5d77zne748eP1NnNhnk888YT793//d3fkyBF35MgRd9ddd7liseh+/OMfO+fmxhzfyve//333rne9y1188cXu9ttvr8fnwjzvvvtut3z5cvfqq6/WX0NDQ/X358IcnXPuN7/5jVu6dKn73Oc+5/77v//bHT161P3Hf/yH+9nPflZvk8dcmzYJ/cEf/IG75ZZbJsTe//73uy9/+cs5jaixTE5CaZq67u5ud99999Vj4+PjrrOz0/393/99DiNsDENDQw6A27dvn3Nu7s7TOefOOecc9w//8A9zbo6jo6Oup6fH7d27161Zs6aehObKPO+++253ySWXmO/NlTk659yXvvQl96EPfYi+n9dcm/LPcZVKBQcPHsS6desmxNetW4f9+/fnNKqZ5ejRoxgcHJww5ziOsWbNmlk95+HhYQDAueeeC2BuzjNJEuzevRsnTpzAlVdeOefmeOutt+JjH/sYPvrRj06Iz6V5vvjii1i8eDGWLVuGT33qU3jppZcAzK05PvHEE1i5ciU+8YlPYOHChbj00kuxY8eO+vt5zbUpk9Brr72GJEnQ1dU1Id7V1YXBwcGcRjWzvDmvuTRn5xzuuOMOfOhDH8KKFSsAzK15Hj58GPPmzUMcx7jlllvw+OOP48ILL5xTc9y9ezd++MMfor+/P/PeXJnnqlWr8Mgjj+Cpp57Cjh07MDg4iNWrV+P111+fM3MEgJdeegnbtm1DT08PnnrqKdxyyy344he/iEceeQRAftez6Uo5vJVgUgVC51wmNteYS3O+7bbb8Nxzz+G//uu/Mu/NhXm+733vw6FDh/DGG2/g0UcfxU033YR9+/bV35/tcxwYGMDtt9+OPXv2oKWlhbab7fO89tpr6/990UUX4corr8R73vMe7Ny5Ex/84AcBzP45Aqdqta1cuRJ9fX0AgEsvvRTPP/88tm3bhj//8z+vt/t9z7Upn4Te9ra3IYqiTPYdGhrKZOm5wptqnLky5y984Qt44okn8L3vfW9CZcW5NM9SqYT3vve9WLlyJfr7+3HJJZfgG9/4xpyZ48GDBzE0NITLL78chUIBhUIB+/btw9/93d+hUCjU5zLb5zmZ9vZ2XHTRRXjxxRfnzLUEgEWLFuHCCy+cELvgggvwyiuvAMjv3mzKJFQqlXD55Zdj7969E+J79+7F6tWrcxrVzLJs2TJ0d3dPmHOlUsG+fftm1Zydc7jtttvw2GOP4bvf/S6WLVs24f25Mk8L5xzK5fKcmeM111yDw4cP49ChQ/XXypUrceONN+LQoUN497vfPSfmOZlyuYyf/OQnWLRo0Zy5lgBw1VVXZX4u8dOf/hRLly4FkOO9OWOShzPkTYn2P/7jP7oXXnjBbdy40bW3t7uf//zneQ/ttBkdHXU/+tGP3I9+9CMHwG3ZssX96Ec/qsvO77vvPtfZ2ekee+wxd/jwYffpT3961klBP//5z7vOzk739NNPT5C8njx5st5mLsxz06ZN7plnnnFHjx51zz33nLvrrrtcGIZuz549zrm5MUeLt6rjnJsb8/zrv/5r9/TTT7uXXnrJPfvss+7jH/+46+joqH/WzIU5OndKZl8oFNxXv/pV9+KLL7p/+qd/cm1tbe5b3/pWvU0ec23aJOSccw8++KBbunSpK5VK7rLLLqvLfGcr3/ve9xyAzOumm25yzp2SSN59992uu7vbxXHsPvzhD7vDhw/nO2hPrPkBcA899FC9zVyY51/8xV/U1+bb3/52d80119QTkHNzY44Wk5PQXJjnm7+FKRaLbvHixW79+vXu+eefr78/F+b4Jv/2b//mVqxY4eI4du9///vd9u3bJ7yfx1xVT0gIIURuNOWekBBCiLMDJSEhhBC5oSQkhBAiN5SEhBBC5IaSkBBCiNxQEhJCCJEbSkJCCCFyQ0lICCFEbigJCSGEyA0lISGEELmhJCSEECI3/n8z2B+U9eFMNQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_first, train_next = next(iter(training_loader)) \n",
    "plt.imshow(train_first[0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06015e1",
   "metadata": {},
   "source": [
    "# Model Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ade1fba",
   "metadata": {},
   "source": [
    "## de Bézenac et al, 2019: CNN with warp mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e569ea",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2632738",
   "metadata": {},
   "source": [
    "The authors used a Charbonnier penality to measure the discrepancy between the predicted next image and the target: \n",
    "\n",
    "$\\rho(x) = (x + \\epsilon)^\\frac{1}{\\alpha}$\n",
    "\n",
    "Note that with $\\epsilon=0$ and $\\alpha=\\frac{1}{2}$, we recover the $\\textit{l}_2$ norm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a26ac1",
   "metadata": {},
   "source": [
    "The gradient wrt $x$:\n",
    "\n",
    "$\\frac{d \\rho(x)}{dx} = \\frac{1}{\\alpha}(x+\\epsilon)^{\\frac{1}{\\alpha}-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc041ab",
   "metadata": {},
   "source": [
    "Additional penalty terms were added to the loss function, specifically to regulate the divergence of the displacement $\\omega$ between the prediction and the target, its magnitude, and its smoothness:\n",
    "\n",
    "$L_t = \\underset{x \\in \\Omega}\\Sigma \\rho(\\hat{I}_{t+1}(x) - I_{t+1}(x)) + \\lambda_{div}(\\nabla.\\omega_t(x))^2 + \\lambda_{magn}||\\omega_t(x)||^2 + \\lambda_{grad}||\\nabla \\omega_t(x)||^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29f28761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_regloss(F):\n",
    "    gradient = reduce(np.add, np.gradient(F))\n",
    "    \n",
    "    divergence = np.array([np.mean(gradient.sum(0)**2)])                         # 1st reg term above\n",
    "    magnitude  = np.array([np.mean(np.linalg.norm(F, axis=0, ord=2)**2)])        # 2nd reg term above\n",
    "    smoothness = np.array([np.mean(np.linalg.norm(gradient, axis=0, ord=2)**2)]) # 3rd reg term above\n",
    "    \n",
    "    return torch.from_numpy(divergence).type(torch.FloatTensor), torch.from_numpy(magnitude).type(torch.FloatTensor), torch.from_numpy(smoothness).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "741a61d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_norm(first, other):\n",
    "    \n",
    "    batchsize = first.shape[0]\n",
    "        \n",
    "    diff = torch.norm(first - other, p=2)  # Euclidean distance\n",
    "    res = diff.sum() / batchsize\n",
    "\n",
    "    return res\n",
    "\n",
    "def grad_norm(first, other):\n",
    "    \n",
    "    return 2*(first - other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "108d33db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctl, y_pred, y, w):\n",
    "        #lambda_div, lambda_magn, lambda_grad = 1, -0.1, 0.4\n",
    "        ctl.save_for_backward(y_pred, y) # saves Tensor ctl for future call to backward()\n",
    "        \n",
    "        #divergence, magnitude, smoothness = compute_regloss(w[0,:,:,:].numpy())\n",
    "        \n",
    "        #loss = ((y_pred - y)**2).sum() + lambda_div*divergence + lambda_magn*magnitude + lambda_grad*smoothness\n",
    "        loss = compute_norm(y_pred, y) #+ lambda_div*divergence + lambda_magn*magnitude + lambda_grad*smoothness\n",
    "        return loss\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctl, somegradient):\n",
    "        y_pred, y = ctl.saved_tensors\n",
    "        \n",
    "        # return grad_charbonnier(y_pred, y), None, None\n",
    "        return grad_norm(y_pred, y), None, None #grad_charbonnier(y_pred - y), None, None #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b406bf74",
   "metadata": {},
   "source": [
    "### Warp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e686d5",
   "metadata": {},
   "source": [
    "The future image is calculated based on a \"warp\" of the motion field estimate, $\\hat{\\omega}$, which can be thought of in this application as the wind vector field:\n",
    "\n",
    "$\\hat{I}_{t+1}(x) = \\underset{y \\in \\Omega} \\Sigma k(x - \\hat{\\omega}(x), y) I_t (y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5484aec7",
   "metadata": {},
   "source": [
    "where $k(u, v)$ is a radial basis function kernel, or equivalent a 2D Gaussian probability distribution:\n",
    "\n",
    "$k(x - \\hat{\\omega}(x), y) = \\frac{1}{4 \\pi D\\Delta t}e^{\\frac{-1}{4D \\Delta t} ||x - \\hat{\\omega}(x) - y||^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad59f08",
   "metadata": {},
   "source": [
    "for diffusion coefficient D and time step value $\\Delta t$ between $t$ and $t+1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "917ddf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel(distsq, D, dt):\n",
    "    \"\"\"Method to implement the k() function or radial basis function kernel \n",
    "    described above.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    distsq : float or torch.FloatTensor : the value of the squared norm of \n",
    "                 the distance\n",
    "    D : float : the diffusion coefficient\n",
    "    dt : float : the timestep\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    res : float or torch.FloatTensor: the result of the function\n",
    "    \"\"\"\n",
    "    \n",
    "    res = torch.exp(-distsq/(4*D*dt))/(4*np.pi*D*dt)\n",
    "    return res\n",
    "\n",
    "def kernel_gradient(self, dist, D, dt):\n",
    "    \"\"\"Method to implement the gradient of the k() function with respect to \n",
    "    the distance.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dist : float : the distance\n",
    "    D : float : the diffusion coefficient\n",
    "    dt : float : the timestep\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    res : float : the gradient of the function with respect to the distance\n",
    "    \"\"\"\n",
    "    \n",
    "    res = dist*torch.exp(-(dist**2).sum(1)/(4*D*dt))/(8*np.pi*D**2*dt**2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56d65cd",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b915e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(*models):\n",
    "    for model in models:\n",
    "        for module in model.modules():\n",
    "            \n",
    "            if isinstance(module, nn.Conv2d) or isinstance(module, nn.ConvTranspose2d) or isinstance(module, nn.Linear):\n",
    "                \n",
    "                # He initialization, from He, K. et al, 2015\n",
    "                nn.init.kaiming_normal_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    module.bias.data.zero_()\n",
    "                    \n",
    "            elif isinstance(module, nn.BatchNorm2d):\n",
    "                module.weight.data.fill_(1)\n",
    "                module.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71dfa15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(_EncoderBlock, self).__init__()\n",
    "        self.cv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.lr1 = nn.LeakyReLU(0.1)\n",
    "        self.cv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.lr2 = nn.LeakyReLU(0.1)\n",
    "        self.maxp = nn.MaxPool2d(kernel_size=3, stride=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual=x\n",
    "        #print(\"residual\",residual.shape)\n",
    "        out=self.cv1(x)\n",
    "        #print(\"cv1\",out.shape)\n",
    "        out=self.bn1(out)\n",
    "        #print(\"bn1\",out.shape)\n",
    "        out=self.lr1(out)\n",
    "        #print(\"lr1\",out.shape)\n",
    "        out+=residual\n",
    "        out=self.cv2(out)\n",
    "        out=self.bn2(out)\n",
    "        out=self.lr2(out)\n",
    "        out=self.maxp(out)\n",
    "        return out\n",
    "\n",
    "class _DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels):\n",
    "        super(_DecoderBlock, self).__init__()\n",
    "        self.cv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.lr1 = nn.LeakyReLU(0.1)\n",
    "        self.cv2 = nn.Conv2d(in_channels, middle_channels, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(middle_channels) \n",
    "        self.lr2 = nn.LeakyReLU(0.1)\n",
    "        self.tcv = nn.ConvTranspose2d(middle_channels, out_channels, kernel_size=3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual=x\n",
    "        #print(\"residual\",residual.shape)\n",
    "        out=self.cv1(x)\n",
    "        #print(\"cv1\",out.shape)\n",
    "        out=self.bn1(out)\n",
    "        #print(\"bn1\",out.shape)\n",
    "        out=self.lr1(out)\n",
    "        #print(\"lr1\",out.shape)\n",
    "        out+=residual\n",
    "        out=self.cv2(out)\n",
    "        out=self.bn2(out)\n",
    "        out=self.lr2(out)\n",
    "        out=self.tcv(out)\n",
    "        return out\n",
    "\n",
    "class _CenterBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(_CenterBlock, self).__init__()\n",
    "        self.cv1 = nn.Conv2d(in_channels,in_channels , kernel_size=3,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)  \n",
    "        self.lr1 = nn.LeakyReLU(0.1)\n",
    "        self.cv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels) \n",
    "        self.lr2 = nn.LeakyReLU(0.1)\n",
    "        self.tcv = nn.ConvTranspose2d(out_channels, out_channels, kernel_size=3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual=x\n",
    "        out=self.cv1(x)\n",
    "        out=self.bn1(out)\n",
    "        out=self.lr1(out)\n",
    "        out+=residual\n",
    "        out=self.cv2(out)\n",
    "        out=self.bn2(out)\n",
    "        out=self.lr2(out)\n",
    "        out=self.tcv(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0dc45117",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDNN(nn.Module):\n",
    "    \"\"\"Class to implement a physics-driven Convolution-Deconvolution Neural \n",
    "    Network (CDNN) as described in (de Bezenac et al, 2019). This model \n",
    "    takes as input historical image(s) of Sea Surface Temperature (SST)\n",
    "    data, X, and uses a convolutional neural network (CNN) to estimate the \n",
    "    wind vector field W that drives the motion of X. From there, the next \n",
    "    image is predicted using a \"warping\" of the most recent input image and W,\n",
    "    as if to see how the SST variable evolves with the wind. \n",
    "    \n",
    "    The \"warping\" in this paper is a radial basis function kernel, or a \n",
    "    Gaussian centered in X-W. Other models we will implement later may use a\n",
    "    different warping scheme. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hist=1):\n",
    "        \"\"\"Function to construct the model. \n",
    "           \n",
    "           Parameters\n",
    "           ----------\n",
    "           hist : int : the number of days of \"history\" to use for prediction, \n",
    "                        default = 1.\n",
    "        \"\"\"\n",
    "        \n",
    "        super(CDNN, self).__init__()\n",
    "        \n",
    "        self.enc1 = _EncoderBlock(hist, 64)  \n",
    "        self.enc2 = _EncoderBlock(64, 128)\n",
    "        self.enc3 = _EncoderBlock(128, 256)\n",
    "        self.enc4 = _EncoderBlock(256, 512)\n",
    "        self.dec4 = _CenterBlock(512, 386)\n",
    "        self.dec3 = _DecoderBlock(386+256, 256, 194)\n",
    "        self.dec2 = _DecoderBlock(194+128, 128, 98)\n",
    "        self.dec1 = _DecoderBlock(98+64, 64, 2)\n",
    "        \n",
    "        self.final = nn.Sequential(nn.Conv2d(2, 2, kernel_size=3),) \n",
    "        initialize_weights(self)\n",
    "\n",
    "        self.hist = hist\n",
    "\n",
    "    def wind(self, x):\n",
    "        \"\"\"Function to estimate the wind vector field from historical input images.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.FloatTensor : the historical input images\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        wind : torch.FloatTensor : the estimated wind vector field\n",
    "        \"\"\"\n",
    "        \n",
    "        enc1 = self.enc1(x)\n",
    "        #print(\"x\",x.shape)\n",
    "        #print(\"enc1\",enc1.shape)\n",
    "        enc2 = self.enc2(enc1)\n",
    "        #print(\"enc2\",enc2.shape)\n",
    "        enc3 = self.enc3(enc2)\n",
    "        #print(\"enc3\",enc3.shape)\n",
    "        enc4 = self.enc4(enc3)\n",
    "        #print(\"enc4\",enc4.shape)\n",
    "        dec4 = self.dec4(enc4)\n",
    "        #print(\"dec4\",dec4.shape)\n",
    "        \n",
    "        dec3 = self.dec3(torch.cat([dec4, F.interpolate(enc3, dec4.size()[2:], mode='bilinear')], 1))\n",
    "        dec2 = self.dec2(torch.cat([dec3, F.interpolate(enc2, dec3.size()[2:], mode='bilinear')], 1))\n",
    "        dec1 = self.dec1(torch.cat([dec2, F.interpolate(enc1, dec2.size()[2:], mode='bilinear')], 1))\n",
    "        final = self.final(dec1)\n",
    "        \n",
    "        wind = F.interpolate(final, x.size()[2:], mode='bilinear')\n",
    "\n",
    "        return wind\n",
    "    \n",
    "    @staticmethod\n",
    "    def warp(I, W, hist):\n",
    "        \"\"\"Function to compute the warping of the input data and an estimated \n",
    "        wind vector field, in order to produce an output predicted image. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        I : torch.FloatTensor : the most recent input image to warp\n",
    "        W : torch.FloatTensor : the estimated wind vector field\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        warped : torch.FloatTensor : the warped prediction image\n",
    "        \"\"\"\n",
    "        \n",
    "        D = 0.45\n",
    "        dt = 1\n",
    "        \n",
    "        interval=torch.arange(I.size()[-1]).type(torch.FloatTensor)\n",
    "        \n",
    "        x1 = interval[None,:,None,None,None]\n",
    "        x2 = interval[None,None,:,None,None]\n",
    "        y1 = interval[None,None,None,:,None]\n",
    "        y2 = interval[None,None,None,None,:]\n",
    "        \n",
    "        # x - wind - y\n",
    "        distsq = (x1-y1-W[:,0,:,:,None,None])**2+(x2-y2-W[:,1,:,:,None,None])**2         \n",
    "        mult = I[:, hist-1, None,None,:,:] * kernel(distsq, D, dt)\n",
    "        warped = mult.sum(4).sum(3)\n",
    "        \n",
    "        return warped\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Function to execute the forward pass of the model. All of the \n",
    "        computations are done in the methods above, so this function \n",
    "        simply returns their outputs.\n",
    "        \n",
    "        Note: the wind vector field W is returned for use in the \n",
    "        regularized loss function later. For simple difference loss \n",
    "        functions, returning y_pred is sufficient. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.FloatTensor : the historical input images\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        W : torch.FloatTensor : the estimated wind vector field\n",
    "        y_pred : torch.FloatTensor : the predicted next image\n",
    "        \"\"\"\n",
    "        \n",
    "        W = self.wind(x)\n",
    "        y_pred = self.warp(x, W, self.hist) \n",
    "        \n",
    "        return W, y_pred "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd072838",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6550149",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62d8b2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    learning_rate = 1e-3\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        #X = X.to(device) \n",
    "        #y = y.to(device)\n",
    "        outputs = model(X)\n",
    "        wind = outputs[0]\n",
    "        y_pred = outputs[1]\n",
    "            \n",
    "        #loss = loss_fn(y_pred, y, wind)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        print(\"Step:\", batch, \"Loss:\", loss)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    return losses\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            #X = X.to(device) \n",
    "            #y = y.to(device)\n",
    "            outputs = model(X)\n",
    "            y_pred = outputs[1]\n",
    "            test_loss += loss_fn(y_pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cbe793",
   "metadata": {},
   "source": [
    "### Training with MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab5d588f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Step: 0 Loss: tensor(13.3844, grad_fn=<MseLossBackward0>)\n",
      "Step: 1 Loss: tensor(9.7442, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m     epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(epoch_loss))\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(epoch_loss)\n",
      "Cell \u001b[0;32mIn[28], line 25\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep:\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/projectnb/labci/luciav/.conda/envs/bez-torch/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/projectnb/labci/luciav/.conda/envs/bez-torch/lib/python3.9/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#torch.autograd.set_detect_anomaly(True)\n",
    "learning_rate = 1e-3\n",
    "epochs = 10\n",
    "\n",
    "model = CDNN(4) \n",
    "loss_fn = nn.MSELoss(reduction=\"mean\") #Loss().apply #nn.L1Loss(size_average=True, reduction=\"mean\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    epoch_loss = train_loop(training_loader, model, loss_fn, optimizer)\n",
    "    train_losses.append(epoch_loss)\n",
    "    \n",
    "    #test_loop(test_dataloader, model, loss_fn)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332f1a62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "218.182px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
